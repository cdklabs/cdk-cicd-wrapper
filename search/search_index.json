{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"cli/index.html","title":"Index","text":"<p>TBD</p>"},{"location":"cli/cli_check_dependencies.html","title":"Check Dependencies","text":"<p>The <code>npx @cdklabs/cdk-cicd-wrapper-cli check-dependencies</code> audits dependencies.</p>"},{"location":"cli/cli_configure.html","title":"Configure","text":"<p>The <code>npx @cdklabs/cdk-cicd-wrapper-cli configure</code> script uses a series of prompts and user input to build a bash script that can be used to <code>source</code> your environment variables into your active shell/terminal. Additionally, the configure script sets values in the config section of the <code>package.json</code> file. The created <code>.env</code> can be modified or duplicated to assist developers moving between potentially different test environments.</p>"},{"location":"cli/cli_configure.html#cdk-cicd-wrapper-variables","title":"CDK CI/CD Wrapper Variables","text":"ENV Variable Package.json config Default Value Description AWS_REGION deployment region ACCOUNT_RES account id for resources account where pipeline will run ACCOUNT_DEV account id for DEV environment account ACCOUNT_INT account id for INT environment account RES_ACCOUNT_AWS_PROFILE sets the named profile to use for the RES account. this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> DEV_ACCOUNT_AWS_PROFILE sets the named profile to use for the DEV account. this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> INT_ACCOUNT_AWS_PROFILE sets the named profile to use for the INT account. this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> AWS_PROFILE sets the default named profile to use for aws cli or cdk commands when no <code>--profile</code> is provided. set to the same value as <code>RES_ACCOUNT_AWS_PROFILE</code> this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> applicationName Wrapper sets the name of the Application CDK_QUALIFIER cdkQualifier wrapper used to distinguish between multiple deployments of a VP project in the same account. Good practice to customize per deployment. GIT_REPOSITORY repositoryName sets the name of the Git repository in the format org/name repositoryType sets the type of the repository, <code>GITHUB</code> or <code>CODECOMMIT</code> CODESTAR_CONNECTION_ARN sets the codestar connection required for GITHUB type CICD_VPC_TYPE cicdVpcType NO_VPC sets the type of the VPC: <code>NO_VPC</code>, <code>VPC</code>, or <code>VPC_FROM_LOOK_UP</code>. CICD_VPC_ID cicdVpcId for use with <code>VPC_FROM_LOOK_UP</code> to set the vpc ID CICD_VPC_CIDR cicdVpcCidr 172.31.0.0/20 for use with <code>VPC</code> to set the CIDR block of the VPC CICD_VPC_CIDR_MASK cicdVpcCidrMask 24 for use with <code>VPC</code> to set the Subnet size PROXY_SECRET_ARN used to set the ARN for the proxy secrets to enable proxy WORKBENCH_STAGE used to test the CDK Stacks in a given stage, by default is DEV"},{"location":"cli/cli_license.html","title":"License Management","text":"<p>The <code>npx @cdklabs/cdk-cicd-wrapper-cli license</code> can validate and generate a NOTICE file for the project.</p> <p>The NOTICE file consistency is tested by the <code>npx @cdklabs/cdk-cicd-wrapper-cli license</code>, this script is included into the CodePipeline Build step to ensure the NOTICE file is always up-to-date.</p> <p>The script checks dependencies in <code>package.json</code> for NPM, <code>Pipfile.lock</code>, and <code>requirements.txt</code> for Python projects. In case, you are using other package managers, you need to manage those dependencies by yourself as long as that is not supported by CDK CI/CD Wrapper.</p> <p>The used dependencies can be dependent on the Operating System and the runtime environment so for this reason the generated NOTICE file could be different based on which environment is generated. Our tool persists the state of the project files which hold information about 3rd party dependencies in the <code>package-verification.json</code> file. If those files are not modified or a new file hasn't been added or previously existing files haven't been removed the tool considers the NOTICE file as up to date. In this situation you want to forcefully regenerate the NOTICE file you can do that with the <code>--force</code> parameter.</p> <p>To update the NOTICE file you need to run the following command:</p> <pre><code>npx @cdklabs/cdk-cicd-wrapper-cli license --fix\n</code></pre>"},{"location":"cli/cli_license.html#configuration-options","title":"Configuration options","text":"<p>The script configuration can be specified in the <code>licensecheck.json</code> file.</p> <p>Example configuration:</p> <pre><code>{\n  \"failOnLicenses\": [\"MIT License\"],\n  \"npm\": {\n    \"excluded\": [],\n    \"excludedSubProjects\": [\"./example/package.json\"]\n  },\n  \"python\": {\n    \"excluded\": [],\n    \"excludedSubProjects\": [\"./example/Pipfile\"]\n  }\n}\n</code></pre> <ul> <li>Banned licenses can be listed on the <code>failOnLicenses</code> attribute. The license name match is case sensitive.</li> <li>Sub folder which <code>Pipfile</code> or <code>package.json</code> file should not be included into the License check should be listen under the <code>npm.excludedSubProjects</code> or <code>python.excludedSubProjects</code> attributes.</li> <li>For NPM packages the subfolder also needs to contain a package-lock.json file to ensure the right dependencies will be installed and checked.</li> <li>Dependencies can be excluded from the license verification for NPM and Python as well.</li> </ul>"},{"location":"cli/cli_security_scan.html","title":"Security Scanning","text":"<p>The <code>npx @cdklabs/cdk-cicd-wrapper-cli security-scan</code> scans the codebase for security vulnerabilities.</p> <p>You can read more about the built-in Security functionalities.</p>"},{"location":"cli/cli_validate.html","title":"Validate","text":"<p>The <code>npx @cdklabs/cdk-cicd-wrapper-cli validate</code> ensures the package-lock.json file is not tempered with.</p>"},{"location":"contributing/index.html","title":"Contributing Guidelines","text":"<p>Thank you for your interest in contributing to the CDK CI/CD Wrapper. Whether it's a bug report, new feature, correction, or additional documentation, we greatly value feedback and contributions from our community.</p> <p>Please read through this document before submitting any issues or pull requests to ensure we have all the necessary information to effectively respond to your bug report or contribution.</p>"},{"location":"contributing/index.html#project-structure","title":"Project Structure","text":"<p>The structure of this project is as follows:</p> <pre><code>\u251c\u2500\u2500 docs                                  # Documentation \n\u251c\u2500\u2500 packages                              # Packages\n\u2502   \u2514\u2500\u2500 @cdklabs\n\u2502       \u251c\u2500\u2500 cdk-cicd-wrapper              # CDK CI/CD Wrapper Blueprint\n\u2502       \u2514\u2500\u2500 cdk-cicd-wrapper-cli          # CLI tools to support the Blueprint\n\u251c\u2500\u2500 projenrc                              # Projen source\n\u251c\u2500\u2500 samples                               # Samples folder for demonstrating various aspects of the tool\n\u251c\u2500\u2500 .projenrc.ts                          # Projen file to manage project structure\n\u251c\u2500\u2500 CHANGELOG.md\n\u251c\u2500\u2500 CODE_OF_CONDUCT.md\n\u251c\u2500\u2500 CONFIGVARS.md\n\u251c\u2500\u2500 CONTRIBUTING.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 NOTICE\n\u251c\u2500\u2500 OSS_License_Summary.csv\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 Taskfile.yml                          # Contains helpful tasks that are useful during development\n\u251c\u2500\u2500 bandit.yaml\n\u251c\u2500\u2500 licensecheck.json\n\u251c\u2500\u2500 package-verification.json\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 tsconfig.dev.json\n\u251c\u2500\u2500 tsconfig.json\n\u2514\u2500\u2500 yarn.lock\n</code></pre>"},{"location":"contributing/index.html#docs","title":"docs","text":"<p>This is where the documentation site is defined and built.</p>"},{"location":"contributing/index.html#packages","title":"packages","text":"<p>This folder the sources are located</p>"},{"location":"contributing/index.html#reporting-bugsfeature-requests","title":"Reporting Bugs/Feature Requests","text":"<p>We welcome you to use the GitHub issue tracker to report bugs or suggest features.</p> <p>When filing an issue, please check existing open, or recently closed, issues to make sure somebody else hasn't already reported the issue. Please try to include as much information as you can. Details like these are incredibly useful:</p> <ul> <li>A reproducible test case or series of steps</li> <li>The version of our code being used (semver)</li> <li>Any modifications you've made relevant to the bug</li> <li>Anything unusual about your environment or deployment</li> </ul>"},{"location":"contributing/index.html#contributing-via-pull-requests","title":"Contributing via Pull Requests","text":"<p>Contributions via pull requests are much appreciated. Before sending us a pull request, please ensure that:</p> <ol> <li>You are working against the latest source on the main branch.</li> <li>You check existing open, and recently merged, pull requests to make sure someone else hasn't addressed the problem already.</li> <li>You open an issue to discuss any significant work - we would hate for your time to be wasted.</li> </ol> <p>To send us a pull request, please:</p> <ol> <li>Fork the repository.</li> <li>Modify the source; please focus on the specific change you are contributing. If you also reformat all the code, it will be hard for us to focus on your change.</li> <li>Run <code>task build</code> to ensure everything builds and tests correctly. <p>This will execute all necessary verification <code>verification</code>, <code>build</code>, <code>test</code>, <code>audit</code>.</p> </li> <li>Commit to your fork on a new branch using conventional commit messages.</li> <li>Send us a pull request, answering any default questions in the pull request template.</li> <li>Pay attention to any automated CI failures reported in the pull request, and stay involved in the conversation.</li> </ol> <p>GitHub provides additional documentation on forking a repository and creating a pull request.</p>"},{"location":"contributing/index.html#commit-messages","title":"Commit Messages","text":"<p>By default we have enabled the commit-msg hook via husky which comes installed by default when you first run <code>npm ci</code>. We are enforcing the convention described in conventionalcommits by default for the commit messages to help make the collaboration between team members transparent and consistent. If your commit messages do not follow this convention, you won't be able to commit your changes from your local machine. Check the example below: WRONG COMMIT MESSAGE</p> <pre><code>&gt; git commit -m \"foo: this will fail\"\n\n&gt; cdk-cicd-wrapper@1.2.3 commitlint\n&gt; commitlint --edit\n\n\u29d7   input: foo: this will fail\n\u2716   type must be one of [build, chore, ci, docs, feat, fix, perf, refactor, revert, style, test] [type-enum]\n\n\u2716   found 1 problems, 0 warnings\n\u24d8   Get help: https://github.com/conventional-changelog/commitlint/#what-is-commitlint\n\nhusky - commit-msg hook exited with code 1 (error)\n</code></pre> <p>CORRECT COMMIT MESSAGE</p> <pre><code>&gt; git commit -m \"docs: updated README.md with better instructions for the commit-msg hook\"\n\n&gt; cdk-cicd-wrapper@1.2.3 commitlint\n&gt; commitlint --edit .git/COMMIT_EDITMSG\n\n[feat/developer-tools 24192d7] docs: updated README.md with better instructions for the commit-msg hook\n 1 file changed, 1 insertion(+), 1 deletion(-)\n</code></pre>"},{"location":"contributing/index.html#commits","title":"Commits","text":"<p>This package utilizes conventional commits and as such all commit messages will need to adopt this format. A <code>commit-msg</code> hook is installed as part of this package to enforce correct commit message structure and will be run anytime a <code>git commit ...</code> is executed.</p> <p>Commitizen has been installed for your convenience which provides a guided UI for committing changes. To commit your changes run the following commands:</p> <pre><code>git add -A # stage your changes\nnpx cz # launch commitizen\n</code></pre> <p>An interactive UI will be displayed which you can follow to get your change committed.</p> <p>Package versioning is determined based on the semantic commit and as such it is very important this format is followed. A PR checker will also run to ensure the format of your commit message is compliant.</p>"},{"location":"contributing/index.html#finding-contributions-to-work-on","title":"Finding contributions to work on","text":"<p>Looking at the existing issues is a great way to find something to contribute on. As our projects, by default, use the default GitHub issue labels (enhancement/bug/duplicate/help wanted/invalid/question/wontfix), looking at any 'help wanted' issues is a great place to start.</p>"},{"location":"contributing/index.html#code-of-conduct","title":"Code of Conduct","text":"<p>This project has adopted the Amazon Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opensource-codeofconduct@amazon.com with any additional questions or comments.</p>"},{"location":"contributing/index.html#security-issue-notifications","title":"Security issue notifications","text":"<p>If you discover a potential security issue in this project we ask that you notify AWS/Amazon Security via our vulnerability reporting page. Please do not create a public github issue.</p>"},{"location":"contributing/index.html#licensing","title":"Licensing","text":"<p>See the LICENSE file for our project's licensing. We will ask you to confirm the licensing of your contribution.</p> <p>We may ask you to sign a Contributor License Agreement (CLA) for larger changes.</p>"},{"location":"contributing/index.html#working-with-documentation","title":"Working with documentation","text":"<p>The documentation for the CDK CI/CD Wrapper Core is stored under the docs/ (index file: index.md) and is designed to be viewed as an MkDocs html site. Before heading to the documentation we highly recommend you:</p> <p>test</p> <ul> <li>Run the build docs script <code>task docs</code> using you UNIX cli</li> <li>Start the local mkdocs webserver to view locally the ConfigBuilder documentation site with the <code>task docs:local</code> command; the documentation will then be available at http://localhost:8000</li> </ul>"},{"location":"contributing/index.html#testing-packages-locally","title":"Testing Packages locally","text":"<p>This section explains how you can run local versions of the CDK CI/CD Wrapper packages that you have made changes to. You would typically do this when testing new features or fixes that you are trying to contribute to this project.</p>"},{"location":"contributing/index.html#prerequisite","title":"Prerequisite","text":"<ul> <li>An AWS account available for testing with Administrator access.</li> <li>Mac OS / Cloud9 with Ubuntu Server 22.04 LTS Platform</li> <li>Bash/ZSH terminal</li> <li>Task installed using the installation guide</li> <li>Maven installed depending on your OS:<ul> <li>Linux</li> <li>macOs via Homebrew</li> </ul> </li> <li>aws-cli v2 here</li> <li>AWS credentials and profiles for each environment under ~/.aws/config here</li> </ul>"},{"location":"contributing/index.html#first-steps","title":"First steps","text":"<p>Configure the following environment variables.</p> Name Description Required Default Example CreateIfNotExisting AWS_PROFILE AWS Profile to use for interacting with the AWS account. This profile is used to create an AWS CodeArtifact to host the CDK CI/CD Wrapper packages, while the version is not publicly available. true 123456789012 false DOMAIN AWS CodeArtifact Domain name to use true cdk-cicd-wrapper true REPOSITORY AWS CodeArtifact repository name to use true cdk-cicd-wrapper true SECRET_ID AWS SecretManager Secret name to publish to login token. This token will be used by the CDK CI/CD Wrapper pipeline to be able to pull the packages at the Synth stage. true cdk-cicd-wrapper true <p>The values can be placed into a <code>.env</code> file in the root of the project as well, e.g:</p> <pre><code>AWS_PROFILE=my-aws-profile\nDOMAIN=cdk-cicd-wrapper\nREPOSITORY=cdk-cicd-wrapper\nSECRET_ID=codeartifact-secret-id\n</code></pre>"},{"location":"contributing/index.html#checkout-and-initialize-the-code-repository","title":"Checkout and initialize the code repository","text":"<p>You can clone the repository from GitHub.</p> <p>Execute the <code>task init</code> command.</p>"},{"location":"contributing/index.html#publish-the-cdk-cicd-packages-into-aws-codeartifact","title":"Publish the CDK CI/CD packages into AWS CodeArtifact","text":""},{"location":"contributing/index.html#login-to-codeartifact","title":"Login to CodeArtifact","text":"<p>It is highly recommended to set up a separate AWS CodeArtifact for testing and developing the CDK CI/CD Wrapper. With a single <code>task codeartifact:login</code> command you can login to the AWS CodeArtifact. In case the AWS CodeArtifact Domain or Repository are not existing, then it creates it based on the provided DOMAIN, REPOSITORY.</p> <p>The created AWS CodeArtifact Domain and Repository can be deleted with the <code>task codeartifact:repository:delete</code> command.</p> <p>Note The command might fail with message like <code>exit status 255</code> or similar. This means your AWS Session has expired.</p>"},{"location":"contributing/index.html#publish","title":"Publish","text":"<p>The CDK CI/CD Wrapper packages can be publish with the <code>task codeartifact:publish</code> command.</p> <p>This command unpublish the previous package in cases where the package version has not been changed.</p>"},{"location":"contributing/index.html#use-the-packages-from-aws-codeartifact","title":"Use the packages from AWS CodeArtifact","text":"<p>The CDK CI/CD Wrapper packages can be added to any CDK project from the AWS CodeArtifact with the <code>npm install --save @cdklabs/cdk-cicd-wrapper @cdklabs/cdk-cicd-wrapper-cli</code>. Then you can follow the Getting Started Guide.</p>"},{"location":"contributing/index.html#use-a-sample-app-for-development","title":"Use a sample app for development","text":"<p>The repository comes with a <code>samples</code> folder that host example projects to understand the benefit of the CDK CI/CD Wrapper.</p> <p>The available samples can be listed, with the <code>task samples:list</code> command. Set the <code>SAMPLE_APP</code> environment variable name as the folder is called inside the sample folder. Once you've selected a sample, that you'd like to use as baseline you need to then go ahead and initialize a project based on that running the following commands:</p> <pre><code>export SAMPLE_APP=cdk-ts-example;\ntask samples:dev:init\n</code></pre> <p>The last command creates the <code>development/project</code> temporarily folder and initialize the project with Projen.</p>"},{"location":"contributing/index.html#configure-environment-variables-for-the-sample-application","title":"Configure environment variables for the sample application","text":"<p>The environment variables listed on the Variables page. These variables can be included into the <code>.env</code> file in either the root or in the <code>development/project</code> folder.</p> <p>The requirements for the samples projects can be different, so check the README.md file of the sample application for more details.</p> <p>You can verify the detected configuration with the <code>task samples:dev:info</code>. This is recommended if you are managing multiple AWS accounts.</p>"},{"location":"contributing/index.html#bootstrap-the-accounts","title":"Bootstrap the accounts","text":"<p>The accounts must be bootstrapped prior to the first deployment. You can execute it with the <code>task samples:dev:bootstrap</code>.</p>"},{"location":"contributing/index.html#update-the-cdk-cicd-wrapper-libraries-in-the-development","title":"Update the cdk-cicd-wrapper libraries in the development","text":"<p>You can update the packages with the <code>task samples:dev:update</code> command that ensures the latest CDK CI/CD Wrapper is used.</p>"},{"location":"contributing/index.html#deploy-the-pipeline-to-the-account","title":"Deploy the pipeline to the account","text":"<p>You can deploy the pipelines from the development folder with the <code>task samples:dev:deploy</code> command.</p>"},{"location":"contributing/index.html#push-the-sources-of-the-sample-application-up-to-the-generated-repository-aws-codecommit","title":"Push the sources of the sample application up to the generated repository AWS CodeCommit","text":"<p>You can push the changes made into the sample from the folder with the <code>task samples:dev:git:push</code></p>"},{"location":"contributing/index.html#deploy-workbench-stacks","title":"Deploy workbench stacks","text":"<p>The workbench stacks can be deployed with the <code>task samples:dev:workbench:deploy</code>.</p>"},{"location":"contributing/index.html#do-development-iteration","title":"Do development iteration","text":"<p>You can test your changes in the CDK CI/CD Wrapper simply with calling the <code>task samples:dev:loop</code>.</p>"},{"location":"contributing/index.html#faq","title":"FAQ","text":""},{"location":"developer_guides/index.html","title":"Developer Guide","text":"<p>This section provides a conceptual overview and practical examples to help you understand the features provided by the CDK CI/CD Wrapper and how to use them in detail.</p>"},{"location":"developer_guides/audit.html","title":"Audit project dependencies","text":"<p>From the package.json you get the following commands which you can run via the cli like this:</p> <pre><code>npm run audit ### check below the list of sub-scripts\n</code></pre> <pre><code>{\n    ...\n    \"scripts\":\n    {\n        ...\n        \"audit\": \"npx concurrently 'npm:audit:*(!fix)'\",\n        \"audit:deps:nodejs\": \"npx @cdklabs/cdk-cicd-wrapper-cli check-dependencies --npm\",\n        \"audit:deps:python\": \"npx @cdklabs/cdk-cicd-wrapper-cli check-dependencies --python\",\n        \"audit:scan:security\": \"npx @cdklabs/cdk-cicd-wrapper-cli security-scan --bandit --semgrep --shellcheck --ci\",\n        \"audit:license\": \"npm run license\",\n        \"audit:fix:license\": \"npm run license:fix\",\n        \"license\": \"npx @cdklabs/cdk-cicd-wrapper-cli license\",\n        \"license:fix\": \"npx @cdklabs/cdk-cicd-wrapper-cli license --fix\",\n        ...\n    },\n    ...\n}\n</code></pre>"},{"location":"developer_guides/cd.html","title":"Continuous Deployment","text":"<p>CD (Continuous Deployment) is a continuous method of software delivery, where you continuously deploy iterative code changes through out various stages.</p> <p>This iterative process helps reduce the chance that you develop new code based on buggy or failed previous versions. The CDK CI/CD Wrapper can catch bugs early in the development cycle, and help ensure that all the code deployed to production complies with your established code standards.</p>"},{"location":"developer_guides/cd.html#common-terms","title":"Common terms","text":""},{"location":"developer_guides/cd.html#stage","title":"Stage","text":"<p>Stage is a representation of a deployment environment where the solution is deployed. The CDK CI/CD Wrapper requires the RES stage to be defined, because that is the stage where all the CI/CD infrastructure elements will be placed. We recommend to use the DEV, INT, and PROD stages, in this order, but you can define your own Stages.</p>"},{"location":"developer_guides/cd.html#stack","title":"Stack","text":"<p>The unit of deployment in the AWS CDK is called a stack. See more details in the CDK documentation.</p>"},{"location":"developer_guides/cd.html#how-to-define-stacks-to-deploy-on-a-stage","title":"How to define Stacks to deploy on a Stage?","text":"<p>Stacks can be added to all of the stages or can be added only to specific stages. Any correct CDK Stacks can be added to a stage and can be deployed with the CDK CI/CD Wrapper.</p>"},{"location":"developer_guides/cd.html#add-stacks-to-all-stages","title":"Add stacks to all stages","text":"<p>Open your <code>bin/&lt;your-main-file&gt;.ts</code> file and include a stack into the Delivery Pipeline. Here we are using two of our example stacks.</p> <pre><code>PipelineBlueprint.builder().addStack({\n  provide: (context) =&gt; {\n    new example.LambdaStack(context.scope, `${context.blueprintProps.applicationName}LambdaStack`, {\n        applicationName: context.blueprintProps.applicationName,\n        stageName: context.stage,\n    });\n    new example.S3BucketStack(context.scope, `${context.blueprintProps.applicationName}S3Stack`, {\n        bucketName: 'test-bucket',\n        stageName: context.stage,\n        applicationQualifier: context.blueprintProps.applicationQualifier,\n        encryptionKey: context.get(GlobalResources.ENCRYPTION)!.kmsKey,\n    });\n}}).synth(app);\n</code></pre> <p>You can add stacks one by one as well.</p> <pre><code>PipelineBlueprint.builder().addStack({\n  provide: (context) =&gt; {\n    new example.LambdaStack(context.scope, `${context.blueprintProps.applicationName}LambdaStack`, {\n        applicationName: context.blueprintProps.applicationName,\n        stageName: context.stage,\n    });\n}}).addStack({\n  provide: (context) =&gt; {\n    new example.S3BucketStack(context.scope, `${context.blueprintProps.applicationName}S3Stack`, {\n        bucketName: 'test-bucket',\n        stageName: context.stage,\n        applicationQualifier: context.blueprintProps.applicationQualifier,\n        encryptionKey: context.get(GlobalResources.ENCRYPTION)!.kmsKey,\n    });\n}}).synth(app);\n</code></pre>"},{"location":"developer_guides/cd.html#highlights","title":"Highlights","text":"<ol> <li>Your stack's scope must be the one that comes from the <code>context</code> -&gt; <code>context.scope</code> or any other stack you defined in the same addStack block.</li> <li>It is recommended to use the prefixing with on the resources you are creating in your Stack otherwise your resource name can be conflicting. As best practice we use the stageName and the applicationQualifier both as that allows us to deploy multi stage CI/CD pipelines on a single AWS account.</li> <li>You can access GlobalResources through the context <code>context.get(GlobalResources.ENCRYPTION)!.kmsKey</code>, you can read about the GlobalResources</li> <li>You can access the parameters of the blueprint <code>context.blueprintProps</code></li> </ol>"},{"location":"developer_guides/cd.html#add-stack-to-a-specific-stage","title":"Add stack to a specific stage","text":"<pre><code>PipelineBlueprint.builder().addStack({\n  provide: (context) =&gt; {\n    new example.LambdaStack(context.scope, `${context.blueprintProps.applicationName}LambdaStack`, {\n        applicationName: context.blueprintProps.applicationName,\n        stageName: context.stage,\n    });\n}}, Stage.DEV).addStack({\n  provide: (context) =&gt; {\n    new example.S3BucketStack(context.scope, `${context.blueprintProps.applicationName}S3Stack`, {\n        bucketName: 'test-bucket',\n        stageName: context.stage,\n        applicationQualifier: context.blueprintProps.applicationQualifier,\n        encryptionKey: context.get(GlobalResources.ENCRYPTION)!.kmsKey,\n    });\n}}, Stage.INT, Stage.PROD).synth(app);\n</code></pre> <p>With this configuration the <code>LambdaStack</code> will be deployed in the DEV stage only and not in the INT and PROD stages where as the <code>S3BucketStack</code> will be deployed in the INT and PROD stages.</p> <p>Note The deployed stacks can be different for each Stage, although the recommendation is to have similar identical deployments. This is to ensure faulty operation of the setup can be intercepted as early as possible.</p>"},{"location":"developer_guides/cd.html#how-to-define-custom-stages","title":"How to define custom Stages","text":"<p>You can define custom stages through the VanillaPipelineBuilder, so that you can adjust the CD process to your environment setup.</p> <pre><code>PipelineBlueprint.builder()\n    .defineStages([\n        Stage.RES,\n        { stage: 'EXP', account: '1234567891012', region: 'eu-west-1'},\n        { stage: Stage.DEV, account: '2345678910123', region: 'eu-west-1'},\n        { stage: Stage.INT}\n    ])\n    .addStack({\n  provide: (context) =&gt; {\n        new example.LambdaStack(context.scope, `${context.blueprintProps.applicationName}LambdaStack`, {\n            applicationName: context.blueprintProps.applicationName,\n            stageName: context.stage,\n        });\n    }, 'EXP').addStack({\n  provide: (context) =&gt; {\n        new example.S3BucketStack(context.scope, `${context.blueprintProps.applicationName}S3Stack`, {\n            bucketName: 'test-bucket',\n            stageName: context.stage,\n            applicationQualifier: context.blueprintProps.applicationQualifier,\n            encryptionKey: context.get(GlobalResources.ENCRYPTION)!.kmsKey,\n        });\n    }}, Stage.INT, Stage.PROD).synth(app);\n</code></pre> <p>With this example you can see the options of how the Stages can be defined.</p> <ol> <li>Define only the stage name to be a string or any of the COMMONSTAGES. This means you must* create an environment variable called <code>ACCOUNT*&lt;STAGE_NAME&gt;</code>which needs to provide the AWS account id. The targeted region is determined by the<code>AWS_REGION</code> environment variable.</li> <li>You can define an object with the <code>stage</code> property. This means you must create an environment variable called <code>ACCOUNT_&lt;STAGE_NAME&gt;</code> which needs to provide the AWS account id. The targeted region is determined by the <code>AWS_REGION</code> environment variable.</li> <li>You can directly input the <code>account</code> and <code>region</code> in case you want to be explicit.</li> </ol> <p>The order of the stage execution will follow the definition order except for the <code>RES</code> stage because that is always deployed first.</p> <p>Note If the <code>ACCOUNT_&lt;STAGE_NAME&gt;</code> environment variable or the <code>account</code> value is only a <code>-</code>, then that stage is considered disabled.</p> <p>Note The CDK CI/CD Wrapper - CLI Configuration command only asks for the the RES, DEV and INT stages' account information, this means if you add a new stage, it is your responsibility to either define your <code>ACCOUNT_&lt;STAGE_NAME&gt;</code> environment variable and add it to the <code>exports_vars.sh</code> or explicitly add the account numbers in the command.</p>"},{"location":"developer_guides/cdk_context.html","title":"Add/remove cdk.context.json to git remote","text":"<p>When you use a construct's <code>.fromLookup()</code> method, the result of the call is cached in cdk.context.json. You should commit this to the version control along with the rest of your code to make sure that future executions of your CDK app (in the pipeline) use the same value. The CDK Toolkit includes commands to manage the context cache, so you can refresh specific entries when need be. For more information, see Runtime context. In case you decide to put the cdk.context.json into .gitignore to avoid committing your test account ids then you need to:</p> <pre><code>### 1. Remove cdk.context.json from .gitignore\nvi .gitignore ### remove cdk.context.json\n### 2. Generate the cdk.context.json\nnpx dotenv-cli -- npm run cdk synth ### this command generates the cdk.context.json\n### 3. Add the cdk.context.json to git remote\ngit add cdk.context.json ### re-add cdk.context.json\ngit commit -am \"feat: re-added cdk.context.json\"\ngit push -u origin ### Push changes to remote\n</code></pre>"},{"location":"developer_guides/ci.html","title":"Continuous Integration","text":"<p>CI (Continuous Integration) is a continuous method of software development, where you continuously build and test iterative code changes.</p> <p>This iterative process helps reduce the chance that you develop new code based on buggy or failed previous versions. The CDK CI/CD Wrapper can catch bugs early in the development cycle, and help ensure that all the code deployed to production complies with your established code standards.</p> <p>The CI functionality of the CDK CI/CD Wrapper can be utilized in any software development process, it is not bound to infrastructure development or AWS CDK projects.</p>"},{"location":"developer_guides/ci.html#common-terms","title":"Common terms","text":""},{"location":"developer_guides/ci.html#phasecommand","title":"PhaseCommand","text":"<p>PhaseCommand represent a single step that is executed by the CI/CD pipeline.</p> <p>These are the available PhaseCommands types:</p> <ul> <li>NPMPhaseCommand - defines an NPM script execution</li> <li>ShellScriptPhaseCommand - defines a shell script execution</li> <li>ShellCommandPhaseCommand - defines a shell command for execution</li> <li>PythonPhaseCommand - defines a python script execution</li> <li>InlineShellPhaseCommand - internal move the given script file content to the build as is. This PhaseCommand is useful in situations where the CDK CI/CD Wrapper sources are not available, for example before network access or NPM registry setups.</li> </ul>"},{"location":"developer_guides/ci.html#phases","title":"Phases","text":"<p>The CDK CI/CD Wrapper has 7 phases which covers every CI/CD project lifecycle. Some of the stages like <code>preDeploy</code> and <code>postDeploy</code> are executed multiple times, while others are only executed once. When a phase is executed it needs to execute all the PhaseCommands defined for the phase in order until completion otherwise the step fails.</p> <p>The following phases are available:</p> <ul> <li>initialize - initializes CI environment before the actual build process can be started. In this phase the networking and the NPM registry connection is established.</li> <li>preBuild - verifies the project is ready for the build</li> <li>build - builds the source code</li> <li>testing - runs testing activities to verify the quality of the product</li> <li>preDeploy - CD phase - prepares and verifies the environment for the deploy</li> <li>deploy - CD phase - deploys the CDK stacks to the stage. This phase can not be modified</li> <li>postDeploy - CD phase - verifies the environment after the deployment and finalize the environment setup</li> </ul>"},{"location":"developer_guides/ci.html#what-are-the-default-set-of-phasecommands-for-the-cdk-cicd-wrapper","title":"What are the default set of PhaseCommands for the CDK CI/CD Wrapper?","text":"<p>The CDK CI/CD Wrapper comes with a pre-set list of PhaseCommand definitions for each stage that provides a good starting point for any AWS CDK projects.</p>"},{"location":"developer_guides/ci.html#initialize-phase","title":"Initialize Phase","text":"Type PhaseCommand Description InlineShellPhaseCommand CONFIGURE_HTTP_PROXY This step configures the HTTP proxy in case it is needed for accessing external resources. You can read more about this in the networking guide. InlineShellPhaseCommand ENVIRONMENT_PREPARATION Populates the environment variables from ParameterStore. InlineShellPhaseCommand NPM_LOGIN Configures the private NPM registry in case it is needed."},{"location":"developer_guides/ci.html#prebuild-phase","title":"PreBuild Phase","text":"Type PhaseCommand Description NPMPhaseCommand VALIDATE Executes the <code>npm run validate</code> command. You can define the command by yourself or you can use CDK CI/CD Wrapper - CLI Validate command NPMPhaseCommand CHECK_AUDIT Executes the <code>npm run audit</code> command. You can define the command by yourself or you can our recommended audit definition. NPMPhaseCommand NPM_CI Runs the <code>npm ci</code> command and downloads all dependencies NPMPhaseCommand CHECK_LINT Executes the <code>npm run lint</code> command. You can define the command by yourself"},{"location":"developer_guides/ci.html#build-phase","title":"Build Phase","text":"Type PhaseCommand Description NPMPhaseCommand BUILD Executes the <code>npm run build</code> command."},{"location":"developer_guides/ci.html#testing-phase","title":"Testing Phase","text":"Type PhaseCommand Description NPMPhaseCommand TEST Executes the <code>npm run test</code> command. InlineShellPhaseCommand CDK_SYNTH_WITH_LOOK_UP Executes the <code>cdk synth</code> command to synthesize the CDK project code and runs the CDK NAG. This version allows the CDK to perform lookups."},{"location":"developer_guides/ci.html#what-are-the-available-phasecommands","title":"What are the available PhaseCommands?","text":"Type PhaseCommand Description InlineShellPhaseCommand CONFIGURE_HTTP_PROXY This step configures the HTTP proxy in case it is needed for accessing external resources. You can read more about this in the networking guide. InlineShellPhaseCommand ENVIRONMENT_PREPARATION Populates the environment variables from ParameterStore. InlineShellPhaseCommand NPM_LOGIN Configures the private NPM registry in case it is needed. NPMPhaseCommand VALIDATE Executes the <code>npm run validate</code> command. You can define the command by yourself or you can use CDK CI/CD Wrapper - CLI Validate command NPMPhaseCommand CHECK_AUDIT Executes the <code>npm run audit</code> command. You can define the command by yourself or you can our recommended audit definition. NPMPhaseCommand NPM_CI Runs the <code>npm ci</code> command and downloads all dependencies NPMPhaseCommand CHECK_LINT Executes the <code>npm run lint</code> command. You can define the command by yourself NPMPhaseCommand BUILD Executes the <code>npm run build</code> command. NPMPhaseCommand TEST Executes the <code>npm run test</code> command. InlineShellPhaseCommand CDK_SYNTH_WITH_LOOK_UP Executes the <code>cdk synth</code> command to synthesize the CDK project code and runs the CDK NAG. This version allows the CDK to perform lookups. InlineShellPhaseCommand CDK_SYNTH_WITHOUT_LOOK_UP Executes the <code>cdk synth</code> command to synthesize the CDK project code and runs the CDK NAG. This version does not allow the CDK to perform lookups."},{"location":"developer_guides/ci.html#how-to-define-a-new-phasecommand","title":"How to define a new PhaseCommand?","text":"<p>There are cases when a new command needs to be added to the CI/CD pipeline. As a first step you need to determine the type of the command. See the list of available PhaseCommand types, if none of those types seems to fit, you always have an option to define your own type.</p> <p>Let's see the two most common cases you could encounter.</p>"},{"location":"developer_guides/ci.html#define-npm-script-based-phasecommand","title":"Define NPM script based PhaseCommand","text":"<p>First ensure the <code>script</code> is defined in your package.json file and the scripts execution result the expected outcome. So your package.json might look like this:</p> <pre><code>{\n    ...\n    \"scripts\":\n    {\n        ...\n        \"my-script\": \"ls\"\n        ...\n    },\n    ...\n}\n</code></pre> <p>Then you can create an NPMPhaseCommand with:</p> <pre><code>const myScriptPhaseCommand = new NPMPhaseCommand('my-script');\n</code></pre> <p>Now the command is ready, we need to include it into our desired phase. Once a default phase has been modified we require you to explicitly define the PhaseCommands for that phase.</p> <p>The phase can be defined with the <code>definePhase</code> method that is available on the VanillaPipelineBuilder.</p> <pre><code>const myScriptPhaseCommand = new NPMPhaseCommand('my-script');\n\nPipelineBlueprint.builder()\n  .addStack((context) =&gt; {\n    new DemoStack(context.scope, 'DemoStack');\n  })\n  .definePhase(PipelinePhases.PRE_BUILD, [\n    PhaseCommands.VALIDATE,\n    myScriptPhaseCommand,\n    PhaseCommands.CHECK_AUDIT,\n    PhaseCommands.NPM_CI,\n    PhaseCommands.CHECK_LINT\n  ])\n  .synth(app);\n</code></pre> <p>Here, you can see how to define the order of the commands, for the phase.</p>"},{"location":"developer_guides/ci.html#define-shell-command-based-phasecommand","title":"Define Shell command based PhaseCommand","text":"<p>You can create a ShellCommandPhaseCommand with:</p> <pre><code>const myScriptPhaseCommand = new sh('ls');\n</code></pre> <p>Now, the command is ready, we need to include into our desired phase. Once a default phase has been modified we require you to explicitly define the PhaseCommands for that phase.</p> <p>The phase can be defined with the <code>definePhase</code> method that is available on the VanillaPipelineBuilder.</p> <pre><code>PipelineBlueprint.builder()\n  .addStack((context) =&gt; {\n    new DemoStack(context.scope, 'DemoStack');\n  })\n  .definePhase(PipelinePhases.PRE_BUILD, [\n    PhaseCommands.VALIDATE,\n    sh('ls'),\n    PhaseCommands.CHECK_AUDIT,\n    PhaseCommands.NPM_CI,\n    PhaseCommands.CHECK_LINT\n  ])\n  .synth(app);\n</code></pre>"},{"location":"developer_guides/ci.html#how-to-define-a-new-phasecommand-type","title":"How to define a new PhaseCommand Type?","text":"<p>Every PhaseCommand must implement the PhaseCommand interface that has only one required command property. This command property must contain an executable command that the <code>sh</code> shell engine can execute, as this command will be added to the underlining AWS CodeBuild project <code>buildSpec.yaml</code> as part of the commands list.</p>"},{"location":"developer_guides/ci.html#how-to-define-the-order-of-the-phasecommands","title":"How to define the order of the PhaseCommands?","text":"<p>The execution order of the PhaseCommands follows the PhaseCommand position in the definition array.</p> <pre><code>const myScriptPhaseCommand = new NPMPhaseCommand('my-script');\n\nPipelineBlueprint.builder()\n  .addStack((context) =&gt; {\n    new DemoStack(context.scope, 'DemoStack');\n  })\n  .definePhase(PipelinePhases.PRE_BUILD, [\n    PhaseCommands.VALIDATE,\n    myScriptPhaseCommand,\n    PhaseCommands.CHECK_AUDIT,\n    PhaseCommands.NPM_CI,\n    PhaseCommands.CHECK_LINT\n  ])\n  .synth(app);\n</code></pre> <p>The <code>npm run validation</code> will be executed before the <code>npm run my-script</code> command.</p>"},{"location":"developer_guides/ci.html#using-buildspec-files","title":"Using BuildSpec files","text":"<p>The CDK CI/CD Wrapper allows to use the <code>buildSpec.yaml</code> file to define the build process instead of the PhaseCommands.</p> <p>To use the <code>buildSpec.yaml</code> file you need configure it with the <code>buildSpecFromFile()</code> method of the <code>PipelineBlueprint</code> builder..</p> <pre><code>PipelineBlueprint.builder()\n  .buildSpecFromFile('path/to/buildSpec.yaml')\n  .addStack((context) =&gt; {\n    new DemoStack(context.scope, 'DemoStack');\n  })\n  .synth(app);\n</code></pre> <p>The <code>buildSpec.yaml</code> file should be placed in the root of the project and should contain the build process definition. It has to contain the commands to generate the build artifacts, run the tests and synthesize the CDK stacks.</p> <pre><code>version: 0.2\n\nphases:\n  install:\n    runtime-versions:\n      nodejs: 20\n    commands:\n      - npm ci\n  build:\n    commands:\n      - npm run build\n  post_build:\n    commands:\n      - npm run test\n      - cdk synth\n</code></pre> <p>Note: The changes in the <code>buildSpec.yaml</code> will be applied after the next pipeline self-mutation.</p>"},{"location":"developer_guides/ci.html#inline-buildspec-definition","title":"Inline BuildSpec definition","text":"<p>The <code>buildSpec.yaml</code> file can be defined inline as well.</p> <pre><code>PipelineBlueprint.builder()\n  .buildSpec(cdk.BuildSpec.fromObject({\n    version: '0.2',\n    phases: {\n      install: {\n        runtime-versions: {\n          nodejs: 20\n        },\n        commands: [\n          'npm ci'\n        ]\n      },\n      build: {\n        commands: [\n          'npm run build'\n        ]\n      },\n      post_build: {\n        commands: [\n          'npm run test',\n          'cdk synth'\n        ]\n      }\n    }\n  }))\n  .addStack((context) =&gt; {\n    new DemoStack(context.scope, 'DemoStack');\n  })\n  .synth(app);\n</code></pre>"},{"location":"developer_guides/codeartifact.html","title":"Using CodeArtifact","text":"<p>AWS CodeArtifact is a fully managed artifact repository service that makes it easy for organizations of any size to securely store, publish, and share software packages used in their development process. AWS CodeArtifact supports popular package formats and works with commonly used build tools and package managers.</p>"},{"location":"developer_guides/codeartifact.html#prerequisites","title":"Prerequisites","text":"<ul> <li>If you do not have an existing AWS CodeArtifact repository please create one using the AWS Management Console or AWS CLI. For more information, see Creating a repository. Ensure the repository is configured to upstream the desired package sources, you must be able to fetch 'aws-cdk-lib' and 'cdklabs' packages from the repository.</li> </ul>"},{"location":"developer_guides/codeartifact.html#configuring-the-cicd-pipeline","title":"Configuring the CI/CD pipeline","text":"<p>To use AWS CodeArtifact in your pipeline, you need to configure the <code>CodeArtifactPlugin</code> plugin. This plugin is responsible for setting up the necessary commands to authenticate with the AWS CodeArtifact repository and manage the required IAM permissions for the pipeline.</p> <pre><code>import { PipelineBlueprint, CodeArtifactPlugin } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n  .plugin(new CodeArtifactPlugin({\n    domain: 'my-domain',\n    repositoryName: 'my-repo',\n  }))\n  .synth(app);\n</code></pre> <p>The above snippet configures the pipeline to authenticate with the AWS CodeArtifact repository <code>my-domain/my-repo</code>. The plugin will automatically set up the necessary IAM permissions for the pipeline to access the repository.</p>"},{"location":"developer_guides/codeartifact.html#using-aws-codeartifact-for-pythonswiftdotnet-packages","title":"Using AWS CodeArtifact for Python/Swift/dotnet packages","text":"<p>To use AWS CodeArtifact for Python, Swift, or dotnet packages, you need to configure the plugin for those package types. The <code>CodeArtifactPlugin</code> accepts an optional <code>repositoryTypes</code> parameter that allows you to specify the package types you want to use with AWS CodeArtifact.</p> <pre><code>import { PipelineBlueprint, CodeArtifactPlugin, CodeArtifactRepositoryTypes} from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n  .plugin(new CodeArtifactPlugin({\n    domain: 'my-domain',\n    repositoryName: 'my-repo',\n    repositoryTypes: [CodeArtifactRepositoryTypes.NPM, CodeArtifactRepositoryTypes.PIP, CodeArtifactRepositoryTypes.SWIFT, CodeArtifactRepositoryTypes.NUGET],\n  }))\n  .addStack(new MyStack())\n  .synth(app);\n</code></pre>"},{"location":"developer_guides/gitbranchingstrategies.html","title":"Git Branching Strategies","text":"<p>The CDK CI/CD Wrapper can be used with git branching strategies as described below.</p>"},{"location":"developer_guides/gitbranchingstrategies.html#trunk-based-development","title":"Trunk-Based Development","text":"<p>Trunk-based development has no branches, and changes are committed directly to the main trunk.  The PipelineBlueprint is used with default options and has the following parameters:</p> <pre><code>PipelineBlueprint.builder()\n    .defineStages([\n        Stage.RES,\n        Stage.DEV,\n        Stage.INT,]\n    )\n    .addStack({\n        provide: (context) =&gt; {\n            new MyStack(context.scope, `${context.blueprintProps.applicationName}Stack`, {\n        });\n        },\n    })\n    .synth(app);\n</code></pre> <p></p>"},{"location":"developer_guides/gitbranchingstrategies.html#gitxflow-feature-branches","title":"Git(x)Flow Feature Branches","text":"<p>GitFlow, GitHub Flow and GitLab Flow are development methodologies where work is done on branches that are merged into the main trunk when they are ready to be deployed into production.  There are three ways that the CDK CI/CD Wrapper can be used with these types of methodologies.</p>"},{"location":"developer_guides/gitbranchingstrategies.html#workbench-deployments","title":"Workbench Deployments","text":"<p>Workbench deployments are deployed directly from the developer's environment.  An additional <code>.workbench()</code> section is added to the pipeline builder that includes the stacks that the developer is working on in their feature branch.  The <code>.workbench()</code> section should not be committed to the trunk because it is specific to a branch and is no longer necassary when the branch is merged.</p> <pre><code>PipelineBlueprint.builder()\n    .defineStages([\n        Stage.RES,\n        Stage.DEV,\n        Stage.INT,]\n    )\n    .workbench({\n        provide: (context) =&gt; {\n        // This is a duplicate of the stack below\n            new MyStack(context.scope, `${context.blueprintProps.applicationName}Stack`, {\n        });\n        },\n    })\n    .addStack({\n        provide: (context) =&gt; {\n            new MyStack(context.scope, `${context.blueprintProps.applicationName}Stack`, {\n        });\n        },\n    })\n    .synth(app);\n</code></pre> <p>Changes are deployed to the workbench account with the <code>npm run workbench deploy</code> command.  They can be removed with <code>npm run workbench destroy</code>.</p> <p></p> <p>Note</p> <ul> <li>Workbench resources are a copy of the stack in the <code>.addStack()</code> section, not the exact same stack.</li> <li>The resources that are deployed will be prefixed with the username of the currently logged in user so that multiple users can deploy into the same development or sandbox account</li> <li>No pipeline is created for the workbench deployment and the developer must manually deploy all changes</li> <li>Compliance and encryption stacks are created for every workbench</li> <li>Resources must be manually cleaned up either with <code>workbench destroy</code> or by deleting the associated Cloudformation stacks</li> <li>If the workbench stack builds containers they will be compiled for the architecture of the developer's device (eg. ARM64), not the CodeBuild environment used by the pipeline</li> </ul>"},{"location":"developer_guides/gitbranchingstrategies.html#feature-pipelines","title":"Feature Pipelines","text":"<p>Feature pipelines can be created to automatically deploy from a code branch to a set of accounts.  This is a separate pipeline that exists for the lifetime of the feature and can deploy into multiple accounts.</p> <p>It is not possible to have both a <code>.workbench()</code> section and a second pipeline.</p> <pre><code>// Main branch pipline\nPipelineBlueprint.builder()\n    .defineStages([\n        Stage.RES,\n        Stage.DEV,\n        Stage.INT,]\n    )\n    .addStack({\n        provide: (context) =&gt; {\n            new MyStack(context.scope, `${context.blueprintProps.applicationName}Stack`, {\n        });\n        },\n    })\n    .synth(app);\n\n// Feature branch pipeline\nPipelineBlueprint.builder()\n    .repository(RepositorySource.github({\n        codeStarConnectionArn: 'arn:aws:codeconnections:us-east-1:111111111:connection/aaaaaaa',\n        repositoryName: 'repoowner/project',\n        branch: 'feature1'\n    }))\n    .defineStages([\n        Stage.RES,\n        { stage: 'feature1stagedev', account: '2222222222', region: 'us-east-1', manualApprovalRequired: false },\n        { stage: 'feature1stageint', account: '3333333333', region: 'us-east-1', manualApprovalRequired: true },\n        ]\n    )\n    .addStack({\n        provide: (context) =&gt; {\n            new MyStack(context.scope, `${context.blueprintProps.applicationName}Stack`, {\n        });\n        },\n    })\n    .applicationName('feature1app')\n    .applicationQualifier('f1')\n    .synth(app);\n</code></pre> <p></p> <p>Note</p> <ul> <li>Each pipeline will have a copy of the <code>.addStack()</code> section, not the exact same stack.</li> <li>A repository section must be added to the pipeline builder that identifies the branch to use</li> <li>Stages other than RES must have a full stage definition because names such as <code>Stage.Dev</code> cannot be re-used in a second pipeline</li> <li>Application name and qualifier must be supplied to prevent duplicate resources being created</li> <li>Resources in stacks should use naming conventions that prevent name clashes when multiple versions are deployed into the same account</li> <li>Resources must be manually cleaned up by deleting Cloudformation stacks in the accounts where they are created when the feature branch is merged into trunk</li> </ul>"},{"location":"developer_guides/gitbranchingstrategies.html#developer-sandbox-pipelines","title":"Developer Sandbox Pipelines","text":"<p>Pipelines for individual developers can be created to automatically deploy from a code branch to a personal sandbox account.  This differs from the feature branch approach above because the Code Pipeline is in the sandbox account, not the RES account.</p> <p>It is not possible to have both a <code>.workbench()</code> section and a second pipeline.</p> <pre><code>// Main branch pipline\nPipelineBlueprint.builder()\n    .defineStages([\n        Stage.RES,\n        Stage.DEV,\n        Stage.INT,]\n    )\n    .addStack({\n        provide: (context) =&gt; {\n            new MyStack(context.scope, `${context.blueprintProps.applicationName}Stack`, {\n        });\n        },\n    })\n    .synth(app);\n\n// Feature branch pipeline\nPipelineBlueprint.builder()\n    .repository(RepositorySource.github({\n        codeStarConnectionArn: 'arn:aws:codeconnections:us-east-1:111111111:connection/aaaaaaa',\n        repositoryName: 'repoowner/project',\n        branch: 'feature1'\n    }))\n    .defineStages([ // Two stages are required even though RES and DEV are the same\n        { stage: 'RES', account: '111111111', region: 'us-east-1', manualApprovalRequired: false },\n        { stage: 'feature1stagedev', account: '111111111', region: 'us-east-1', manualApprovalRequired: true },\n        ]\n    )\n    .disable(GlobalResources.COMPLIANCE_BUCKET)\n    .addStack({\n        provide: (context) =&gt; {\n            new MyStack(context.scope, `${context.blueprintProps.applicationName}Stack`, {\n        });\n        },\n    })\n    .applicationName('feature1app')\n    .applicationQualifier('f1')\n    .synth(app);\n</code></pre> <p></p> <p>Note</p> <ul> <li>The pipeline will have a copy of the <code>.addStack()</code> section, not the exact same stack.</li> <li>A repository section must be added to the pipeline builder that identifies the branch to use</li> <li>It is not currently possible to have compliance bucket support when a pipeline and deployment are in the same account, so this must be disabled</li> <li>Both a RES and deployment environments must have full stage definitions even though they are the same account</li> <li>Application name and qualifier must be supplied to prevent duplicate resources being created</li> <li>Resources must be manually cleaned up by deleting Cloudformation stacks in the accounts where they are created</li> </ul>"},{"location":"developer_guides/global_resource.html","title":"Global Resources","text":"<p>CDK CI/CD Wrapper uses a simple Dependency Injection system to ease the complexity of the cross-cutting resource generation. On this page you can read more about how it is been used in the CDK CI/CD Wrapper and how can you use for your benefit as well.</p>"},{"location":"developer_guides/global_resource.html#dependency-injection-and-resource-providers","title":"Dependency Injection and Resource Providers","text":"<p>The benefit of the dependency injection is that the stack dependency implementations are decoupled from the stack and the CDK CI/CD Wrapper manages the creation of those resources.</p> <p>Let's see an example:</p> <pre><code>new S3BucketStack(context.scope, `${context.blueprintProps.applicationName}S3Stack`, {\n    bucketName: 'test-bucket',\n    stageName: context.stage,\n    applicationQualifier: context.blueprintProps.applicationQualifier,\n    encryptionKey: context.get(GlobalResources.Encryption)!.kmsKey,\n}\n</code></pre> <p>You can see here the S3BucketStack requires a KMS key to perform server-side encryption. Here, we can leverage one of our built-in providers that allows you to access a KMS Key that is dedicated to your pipeline for the particular stage in which your stack is deployed. You don't need to manage the key creation, it is managed for you and will be available whenever you need it.</p> <p>All the Resource Providers accessible through the <code>resourceContext</code> parameter.</p>"},{"location":"developer_guides/global_resource.html#existing-resource-providers","title":"Existing Resource Providers","text":""},{"location":"developer_guides/global_resource.html#compliance-bucket-resource-provider","title":"Compliance Bucket Resource Provider","text":""},{"location":"developer_guides/global_resource.html#parameterstore","title":"ParameterStore","text":""},{"location":"developer_guides/global_resource.html#how-to-define-you-resource-provider","title":"How to define you Resource Provider","text":""},{"location":"developer_guides/modularizing_stacks.html","title":"Modularizing Stacks with BaseStackProvider and DefaultStackProvider","text":"<p>In complex CDK projects, managing inlined stacks within <code>PipelineBlueprint.builder()</code> can become cumbersome. To enhance organization and reusability, the <code>BaseStackProvider</code> and <code>DefaultStackProvider</code> abstraction offers a powerful solution.</p> <p>The <code>DefaultStackProvider</code> serves as an abstract base class that you can extend to define your stack provisioning logic. The core implementation lies within the mandatory <code>stacks()</code> function.</p>"},{"location":"developer_guides/modularizing_stacks.html#creating-a-custom-stack-provider-with-defaultstackprovider","title":"Creating a Custom Stack Provider with DefaultStackProvider","text":"<pre><code>import { Stage, DefaultStackProvider } from '@cdklabs/cdk-cicd-wrapper';\nimport * as cdk from 'aws-cdk-lib';\n\nexport class ExampleProvider extends DefaultStackProvider {\n\n  stacks(): void {\n    new cdk.Stack(this.scope, 'ExampleStack', {\n      env: this.env,\n      // ... other stack properties\n    });\n  }\n}\n</code></pre>"},{"location":"developer_guides/modularizing_stacks.html#creating-a-custom-stack-provider-with-basestackprovider","title":"Creating a Custom Stack Provider with BaseStackProvider","text":"<p>The <code>BaseStackProvider</code> serves as an abstract base class that you can extend to define your stack provisioning logic. The core implementation lies within the mandatory <code>stacks()</code> function.</p> <pre><code>import { Stage, BaseStackProvider } from '@cdklabs/cdk-cicd-wrapper';\nimport * as cdk from 'aws-cdk-lib';\n\nexport class ExampleProvider extends BaseStackProvider {\n\n  stacks(): void {\n    // Define your stack configuration here\n    new cdk.Stack(this.scope, 'ExampleStack', {\n      env: this.env,\n      // ... other stack properties\n    });\n  }\n}\n</code></pre>"},{"location":"developer_guides/modularizing_stacks.html#leveraging-the-custom-provider","title":"Leveraging the Custom Provider","text":"<p>Once you've created your custom provider, integrate it seamlessly within your pipeline blueprint:</p> <pre><code>import { PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\nimport { ExampleProvider } from './example-provider'; // Assuming your provider is in a separate file\n\nconst pipeline = PipelineBlueprint.builder()\n  .addStack(new ExampleProvider())\n  .synth(app);\n</code></pre>"},{"location":"developer_guides/modularizing_stacks.html#sharing-resources-across-defaultstackproviders","title":"Sharing resources across DefaultStackProviders","text":"<p>It is common to share resources across multiple stack provider. To achieve this, you can create the resource in one of the DefaultStackProvider and register it with the <code>register(key: string, value: any)</code> method. You can then retrieve the resource in another DefaultStackProvider using the <code>get(key: string)</code> method. The following example demonstrates how to share a DynamoDB table across two DefaultStackProviders.</p> <pre><code>import { DefaultStackProvider } from '@cdklabs/cdk-cicd-wrapper';\nimport * as cdk from 'aws-cdk-lib';\n\nexport class DynamoDBProvider extends DefaultStackProvider {\n  stacks(): void {\n    const table = new cdk.Table(this.scope, 'ExampleTable', {\n      partitionKey: { name: 'id', type: cdk.AttributeType.STRING },\n      billingMode: cdk.BillingMode.PAY_PER_REQUEST,\n      removalPolicy: cdk.RemovalPolicy.DESTROY,\n    });\n\n    this.register('exampleTable', table);\n  }\n}\n</code></pre> <pre><code>import { DefaultStackProvider } from '@cdklabs/cdk-cicd-wrapper';\nimport * as cdk from 'aws-cdk-lib';\n\nexport class LambdaProvider extends DefaultStackProvider {\n  stacks(): void {\n    const table = this.get('exampleTable') as cdk.Table;\n\n    // Use the DynamoDB table in your stack\n    // ...\n  }\n}\n</code></pre>"},{"location":"developer_guides/modularizing_stacks.html#best-practices","title":"Best Practices","text":"<ul> <li>Modular Organization: For optimal maintainability, create separate providers for distinct logical units within your application. This promotes code clarity and simplifies future modifications.</li> <li>Extensibility with Hooks: The DefaultStackProvider provides optional preHooks and postHooks methods that you can override to execute custom logic before and after stack creation, respectively. This empowers you to inject additional processing steps into your pipeline as needed.</li> <li>Secure Key Management: Utilize a dedicated AWS Key Management Service (KMS) key for encryption purposes. This key can be retrieved using the this.encryptionKey property within your custom provider class.</li> <li>Centralized Configuration Management: Access and leverage SSM Parameters to store and retrieve configuration values securely. You can utilize the resolve(ssmParameterName: string) function provided by the DefaultStackProvider to retrieve these parameters within your stacks</li> <li>Resource Sharing: To share resources across multiple DefaultStackProviders, create the resource in one provider and register it using the register(key: string, value: any) method. You can then retrieve the resource in another provider using the get(key: string) method.</li> <li>SSM Parameter Caching: To minimize the number of SSM Parameter retrievals, the DefaultStackProvider caches parameter values for the duration of the pipeline execution. This ensures optimal performance and reduces unnecessary API calls.</li> <li>Namespace Isolation: To prevent naming conflicts, each DefaultStackProvider operates within its own namespace. This ensures that stack names, resource identifiers, and other naming conventions remain unique across the pipeline.</li> </ul>"},{"location":"developer_guides/networking.html","title":"Networking","text":""},{"location":"developer_guides/networking.html#determine-vpc-and-proxy-settings-for-your-pipeline","title":"Determine VPC and Proxy settings for your pipeline","text":"<p>By default, the Pipeline is configured to run without a VPC. To have it run inside a VPC, there are two options: <code>VPC</code> and <code>VPC_FROM_LOOK_UP</code>. These options are configured using <code>npx @cdklabs/cdk-cicd-wrapper-cli configure</code> described in the next section.</p> <p>Use <code>VPC</code> if you want a single, self-contained pipeline running in a VPC. This is not recommended for use with multiple code pipelines in the same account. The VPC is created using defaulted settings.</p> <p>Use <code>VPC_FROM_LOOK_UP</code> to look up an existing VPC based on its vpc ID. It is recommended to create this VPC prior to deploying the pipeline. Multiple deployments of the pipeline can share the same VPC.</p> <p>Note: Switching between VPC options may require a complete tear down and redeploy of the pipeline</p> <p>Proxy Configuration requires proxy information to be stored in Secrets manager. Make note of the secret arn is needed in the next step.</p>"},{"location":"developer_guides/pipeline_options.html","title":"Advanced Pipeline Configuration Options","text":"<p>These new options allow you to configure the AWS CDK CodePipeline values.</p> <p>In this guide, we'll explore new properties for configuring your CI/CD pipeline using the CDK CI/CD Wrapper, along with their benefits, use cases, and code examples.</p>"},{"location":"developer_guides/pipeline_options.html#self-mutation","title":"Self-Mutation","text":"<p>Ideal for projects that require infrequent updates to the pipeline configuration, ensuring the pipeline remains the same.</p> <p>Property: <code>selfMutation</code> - Description: Allows the pipeline to update itself. - Type: <code>boolean</code> - Default: <code>true</code></p> <p>Code Example: <pre><code>import { PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n   .pipelineOptions({\n       selfMutation: false,\n    }).synth(app);\n</code></pre></p>"},{"location":"developer_guides/pipeline_options.html#publish-assets-in-parallel","title":"Publish Assets in Parallel","text":"<p>Beneficial for large projects with multiple assets, where improving concurrency and reducing publishing latency can significantly speed up the CI/CD process, but may also increase overall provisioning time of the CodeBuild projects.</p> <p>Property: <code>publishAssetsInParallel</code> - Description: Publishes assets using multiple CodeBuild projects. - Type: <code>boolean</code> - Default: true</p> <p>Code Example: <pre><code>import { PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n   .pipelineOptions({\n       publishAssetsInParallel: false,\n    }).synth(app);\n</code></pre></p>"},{"location":"developer_guides/pipeline_options.html#docker-credentials","title":"Docker Credentials","text":"<p>Necessary for projects that involve building, synthesizing, updating, or publishing Docker images, ensuring secure and efficient access to Docker registries.</p> <p>Property: <code>dockerCredentials</code> - Description: List of credentials for authenticating to Docker registries. - Type: <code>pipelines.DockerCredential[]</code> - Default: <code>[]</code></p> <p>Code Example: <pre><code>import { PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\nimport { DockerCredential } from 'aws-cdk-lib/pipelines';\n\nconst dockerCreds: DockerCredential[] = [\n    DockerCredential.ecr('arn:aws:iam::123456789012:role/MyECRRole'),\n];\n\nconst pipeline = PipelineBlueprint.builder()\n   .pipelineOptions({\n       dockerCredentials: dockerCreds,\n    }).synth(app);\n</code></pre></p>"},{"location":"developer_guides/pipeline_options.html#use-change-sets","title":"Use Change Sets","text":"<p>Recommended for projects that require thorough review before deployment, as it allows for safe execution and rollback if needed. However, this option may increase deployment time due to the additional change set creation and execution steps.</p> <p>Property: <code>useChangeSets</code> - Description: Deploys stacks by creating and executing change sets. - Type: <code>boolean</code> - Default: <code>true</code></p> <p>Code Example: <pre><code>import { PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n   .pipelineOptions({\n       useChangeSets: false,\n    }).synth(app);\n</code></pre></p>"},{"location":"developer_guides/private_npm_registry.html","title":"Using private NPM registry","text":"<p>A private npm registry is a custom repository for hosting Node.js packages, which are not available to the general public. The private NPM registry has to be configured in both local and on the CI/CD environment.</p>"},{"location":"developer_guides/private_npm_registry.html#local-setup","title":"Local setup","text":"<p>Configuring a private npm registry using the .npmrc file involves specifying the registry URL and authentication credentials. Here's a step-by-step guide:</p> <ol> <li> <p>Obtain Authorization Token:    To access private packages from a registry, you need an authorization token. This token grants you permission to download and publish packages to the private registry. You can generate a token from your private registry's administrative dashboard or using the registry's authentication mechanism.</p> </li> <li> <p>Create a .npmrc File:    Create a file named <code>.npmrc</code> in the root directory of your project. This file will store your registry URL and authentication credentials.</p> </li> <li> <p>Specify Registry URL:</p> </li> </ol> <p>In the .npmrc file, add the URL of your private registry. For instance, if your registry URL is https://private-registry.example.com, add the following line:</p> <pre><code>registry=https://private-registry.example.com\n</code></pre> <p>3.1 Specify scope In case you want to use the registry only for scoped dependencies, add the scope definition before the registry.</p> <pre><code>@cdklabs:registry=https://private-registry.example.com\n</code></pre> <ol> <li>Add Authentication Credentials:</li> </ol> <p>To authenticate with the private registry, you need to specify your authorization token. There are two ways to do this:</p> <p>Basic Authentication:</p> <p>Add the following lines to your `.npmrc`` file:</p> <pre><code>//private-registry.example.com/:_authToken=your-token\n</code></pre> <p>API Token:</p> <p>If your registry supports API tokens, you can use the <code>//registry.npmjs.org/:_authToken=${NPM_TOKEN}</code> format. Set the <code>NPM_TOKEN</code> environment variable to your API token value.</p>"},{"location":"developer_guides/private_npm_registry.html#example","title":"Example:","text":"<pre><code># Content of .npmrc\n@cdklabs:registry=https://jfrog.com/artifactory/api/npm/cdklabs-npm-release/\n//jfrog.com/artifactory/api/npm/cdklabs-npm-release/:_authToken=eya......\n</code></pre> <p>Anytime you modify the <code>.npmrc</code> file it is highly recommended to verify the new configuration. It can be done with an <code>npm ci</code> call.</p> <p>Note Never share your authentication tokens or commit the .npmrc file.</p> <p>Note .npmrc file must be placed into the project root folder as it is used by the various audit processes as well to interact with the repository</p>"},{"location":"developer_guides/private_npm_registry.html#cicd-environment-setup","title":"CI/CD environment setup","text":"<p>The private npm registry information must to be configured for the CI CD pipeline as well.</p> <p>The <code>CDK CI/CD WrapperBuilder</code> has a configuration method which accepts:</p> <ul> <li>url: NPM registry url</li> <li>basicAuthSecretArn: AWS SecretManager Secret arn, will be detailed soon</li> <li>scope: NPM Registry scope if it is used</li> </ul> <p>To set this configuration you must add the following to your code where you have defined CDK CI/CD WrapperBuilder <pre><code>import * as vp from '@cdklabs/cdk-cicd-wrapper';\n\nconst npmRegistryConfig: vp.NPMRegistryConfig = {\n  url: \"https://&lt;your-domain&gt;-&lt;your-aws-account-id&gt;.d.codeartifact.&lt;region&gt;.amazonaws.com/npm/&lt;your-repository&gt;/\", \n  basicAuthSecretArn: \"&lt;your-secret-arn&gt;\", \n  scope: \"&lt;scope&gt;\" \n};\n\nvp.CDK CI/CD WrapperBlueprint.builder().npmRegistry(npmRegistryConfig).synth(app);\n</code></pre></p> <p>The NPM Authentication Token needs to remain secret that is why the CDK CI/CD Wrapper uses AWS SecretManager to store it.</p> <p>Create a secret in AWS Secrets Manager and store the authentication token as plaintext. This is viable for long living tokens. The value of the secret needs to be only the token. Provide the arn of this secret as <code>basicAuthSecretArn</code> either as a hardcoded string  in your npmRegistryConfig or through an environment variable but in this case the environment variable name must be <code>NPM_BASIC_AUTH_SECRET_ID</code>.</p> <p>Note It is recommended to use technical users and token dedicated to them, rather than personal tokens.</p>"},{"location":"developer_guides/python_dependencies.html","title":"Working with Python dependencies","text":"<p>The project utilizes the Pipenv. Pipenv automatically creates and manages a virtual enviornment for your projects, as well as adds/removes packages from your <code>Pipfile</code> as you install/uninstall packages. It also generates a project <code>Pipfile.lock</code>, which is used to produce deterministic builds.</p> <p>The Python dependencies are maintained in <code>Pipfile</code> instead of the <code>requirements.txt</code> file and requirements.txt files should not be committed into Git.</p>"},{"location":"developer_guides/python_dependencies.html#how-to-install-pipenv","title":"How to install Pipenv","text":"<p>The recommended approach is to use <code>pip install pipenv -U</code> command. More information can be found here.</p> <p>The <code>pipenv</code> command is not added to the $PATH by default that need to be done manually. The <code>pipenv</code> command location can be determined by executing:</p> <pre><code>python3 -m site --user-base\n</code></pre> <p>This will return a value like <code>/Users/user/Library/Python/3.11</code>. Then the $PATH needs to be extended with the <code>/Users/user/Library/Python/3.11/bin</code>.</p> <pre><code>export PATH=\"${PATH}:/Users/user/Library/Python/3.11/bin\";\n</code></pre> <p>You can add this your <code>$HOME/.zshrc</code> or <code>$HOME/.bashrc</code> to have this folder permanently.</p>"},{"location":"developer_guides/python_dependencies.html#migrating-existing-requirementstxt","title":"Migrating existing <code>requirements.txt</code>","text":"<p>Existing <code>requirements.txt</code> can be transformed into a <code>Pipfile</code> with the <code>pipenv install</code> command:</p> <pre><code>cd path-to-the-module\npipenv install -r requirements.txt &amp;&amp; pipenv lock\n</code></pre> <p><code>Pipfile</code> has to be created where the <code>requirements.txt</code> would be created. That folder will be considered as a Python module.</p>"},{"location":"developer_guides/python_dependencies.html#installing-a-new-dependency","title":"Installing a new dependency","text":"<p>The <code>pipenv</code> command install api is identical as the <code>pip</code> commands.</p> <pre><code>pipenv install &lt;dependency&gt;\n</code></pre>"},{"location":"developer_guides/python_dependencies.html#updating-lock-file","title":"Updating lock file","text":"<p>The <code>Pipfile.lock</code> can be updated with the <code>pipenv lock</code> command.</p>"},{"location":"developer_guides/python_dependencies.html#installing-dependencies-based-on-the-pipfilelock","title":"Installing dependencies based on the <code>Pipfile.lock</code>","text":"<p>The locked dependencies can be installed with the locked version with the <code>pipenv sync</code> command.</p>"},{"location":"developer_guides/security.html","title":"Security on CDK CI/CD Wrapper","text":"<p>CDK CI/CD Wrapper brings the IaaC security to a new level with its built-in toolsets based on AWS best practices and industry wide standards. It includes Static Application Security Testing (SAST), Dependency Vulnerability Scanning, and AI based vulnerability scanning.</p>"},{"location":"developer_guides/security.html#reference-sheet-of-security-controls","title":"Reference sheet of Security controls","text":"Security Tool Type Status Limitations Description AWS CDK NAG Static Application Security Testing Enabled cdk-nag integrates directly into AWS Cloud Development Kit (AWS CDK) applications to provide identification and reporting mechanisms similar to SAST tooling. [] Amazon CodeGuru Reviewer Static Application Security Testing Enabled Supported with AWS CodeCommit repository only. Verify Pull Requests only and users can by pass Amazon CodeGuru Reviewer detect vulnerabilities and automate code reviews with machine-learning powered recommendations. Amazon CodeGuru Security Static Application Security Testing Disabled Amazon CodeGuru Security is in preview release and is subject to change. Amazon CodeGuru Security is a static application security testing (SAST) tool that combines machine learning (ML) and automated reasoning to identify vulnerabilities in your code, provide recommendations on how to fix the identified vulnerabilities, and track the status of the vulnerabilities until closure. Better-NPM-Audit Dependency Scanning for Vulnerabilities Enabled Verifies NPM dependencies Scans the dependencies for known vulnerabilities CVEs. pip-audit Dependency Scanning for Vulnerabilities Enabled Verifies Python dependencies based on the provided Pipfiles. Scans the dependencies for known vulnerabilities CVEs. semgrep Static Security Code Scanner Enabled Scans the codebase for vulnerabilities. shellcheck Static Security Code Scanner Enabled Analyses Shell Scripts Scans the codebase for vulnerabilities. Bandit Static Security Code Scanner Enabled Analyses Python source codes Scans the codebase for vulnerabilities."},{"location":"developer_guides/security.html#tools-description","title":"Tools description","text":""},{"location":"developer_guides/security.html#aws-cdk-nag","title":"AWS CDK Nag","text":"<p>cdk-nag integrates directly into AWS Cloud Development Kit (AWS CDK) applications to provide identification and reporting mechanisms similar to SAST tooling.</p> <p>CDK Nag is applied as a CDK Aspect and it looks for patterns in the CDK Application that may indicate insecure infrastructure. Roughly speaking, it will look for:</p> <ul> <li>IAM rules that are too permissive (wildcards)</li> <li>Security group rules that are too permissive (wildcards)</li> <li>Access logs that aren't enabled</li> <li>Encryption that isn't enabled</li> <li>Password literals</li> <li>and many more</li> </ul> <p>The CDK Nag verification is executed to during the <code>cdk synth</code> phase. &lt;&lt;!\u2014did mean \u201calso\u201d with the \u201cto\u201d -&gt;&gt;</p> <p>If you have assessed the risk of new finding and want to suppress these CDK Nag rules to prevent them from failing the CDK Deploymen then you should do so in their own dedicated stacks rather than doing it centrally.</p> <p>More information about the CDK Nag can be found on these locations:</p> <ul> <li>AWS CDK NAG</li> <li>Manage application security and compliance with the AWS Cloud Development Kit and cdk-nag</li> </ul>"},{"location":"developer_guides/security.html#how-to-enable-disable","title":"How to enable / disable","text":"<p>The AWS CDK Nag is such an essential part of ensuring the security of the IaaC project that it\u2019s use is mandatory.</p>"},{"location":"developer_guides/security.html#amazon-codeguru-reviewer","title":"Amazon CodeGuru Reviewer","text":"<p>Amazon CodeGuru Reviewer detects vulnerabilities and automates code reviews with machine-learning powered recommendations.</p> <p>Amazon CodeGuru Reviewer is included in pipelines created with AWS CodeCommit as VCS and it automatically reviews the created Pull Requests and provides actionable recommendations on the changes.</p> <p>Amazon CodeGuru Reviewer recommendations are available directly on the Pull Requests or on the AWS Console / Amazon CodeGuru / Reviewer / Code Reviews.</p>"},{"location":"developer_guides/security.html#how-to-enable-disable_1","title":"How to enable / disable","text":"<p>The scanning can be enabled/disabled with the <code>AppConfig.repositoryConfig.CODECOMMIT.codeGuruReviewer</code> configuration. If the configuration value is true then it is enabled. If the configuration false then it is disabled.</p>"},{"location":"developer_guides/security.html#amazon-codeguru-security","title":"Amazon CodeGuru Security","text":"<p>Amazon CodeGuru Security is a static application security testing (SAST) tool that combines machine learning (ML) and automated reasoning to identify vulnerabilities in your code, providing recommendations on how to fix the identified vulnerabilities, and tracking the status of the vulnerabilities until closure.</p> <p>Amazon Code Guru is applied on the pipeline as part of the Build stage to ensures the solution security meets with the highest standard. The scanning stops the pipeline in case there is any findings that have higher severity than <code>High</code> default. The threshold level can be adjusted by the <code>AppConfig.codeGuruScanThreshold</code> configuration option.</p> <p>The Amazon Code Guru findings and recommendations can be found on the AWS Console / Amazon CodeGuru / Security / Findings . The Findings page provides a holistic view about the security recommendations. Information about each Scan can be found on the AWS Console / Amazon CodeGuru / Security / Scans page.</p>"},{"location":"developer_guides/security.html#how-to-enable-disable_2","title":"How to enable / disable","text":"<p>The scanning can be enabled/disabled with the <code>AppConfig.codeGuruScanThreshold</code> configuration. If the configuration is present than it is enabled. If the configuration is missing the scan will be disabled.</p>"},{"location":"developer_guides/security.html#better-npm-audit","title":"Better NPM Audit","text":"<p>The goal of this project is to provide additional features on top of the existing npm audit options. We hope to encourage more people to do security audits for their projects.</p> <p>More information about Better NPM Audit.</p>"},{"location":"developer_guides/security.html#how-to-disable","title":"How to disable","text":"<p>Remove the <code>audit:deps:nodejs</code> script from the <code>package.json</code>.</p>"},{"location":"developer_guides/security.html#pip-audit","title":"pip-audit","text":"<p>pip-audit is a tool for scanning Python environments for packages with known vulnerabilities. It uses the Python Packaging Advisory Database (https://github.com/pypa/advisory-database) via the PyPI JSON API as a source of vulnerability reports.</p> <p>More information about pip-audit.</p>"},{"location":"developer_guides/security.html#how-to-disable_1","title":"How to disable","text":"<p>Remove the <code>audit:deps:python</code> script from the <code>package.json</code>.</p>"},{"location":"developer_guides/security.html#semgrep","title":"Semgrep","text":"<p>Semgrep accelerates your security journey by swiftly scanning code and package dependencies for known issues, software vulnerabilities, and detected secrets with unparalleled efficiency. Semgrep offers:</p> <ul> <li>Code to find bugs &amp; vulnerabilities using custom or pre-built rules</li> <li>Supply Chain to find dependencies with known vulnerabilities</li> <li>Secrets to find hard-coded credentials that shouldn't be checked into source code</li> </ul> <p>More information about Semgrep.</p>"},{"location":"developer_guides/security.html#how-to-enable-disable_3","title":"How to enable / disable","text":"<p>Add/remove the <code>semgrep</code> entry to/from the <code>SECURITY_SCANNERS</code> list in the <code>scripts/check-code-scan-security.sh</code>.</p>"},{"location":"developer_guides/security.html#shellcheck","title":"Shellcheck","text":"<p>ShellCheck is a static analysis tool for shell scripts.</p> <p>More information about ShellCheck.</p>"},{"location":"developer_guides/security.html#how-to-enable-disable_4","title":"How to enable / disable","text":"<p>Add/remove the <code>shellcheck</code> entry to/from the <code>SECURITY_SCANNERS</code> list in the <code>scripts/check-code-scan-security.sh</code>.</p>"},{"location":"developer_guides/security.html#bandit","title":"Bandit","text":"<p>Bandit is a tool designed to find common security issues in Python code. To do this, Bandit processes each file, builds an AST from it, and runs appropriate plugins against the AST nodes.</p> <p>More information about Bandit.</p>"},{"location":"developer_guides/security.html#how-to-enable-disable_5","title":"How to enable / disable","text":"<p>Add/remove the <code>bandit</code> entry to/from the <code>SECURITY_SCANNERS</code> list in the <code>scripts/check-code-scan-security.sh</code>.</p>"},{"location":"developer_guides/security.html#security-checks-on-github-actions","title":"Security checks on GitHub Actions","text":"<p>GitHub Actions executes the enabled security checks as part of the pull requests checks. In case any of the enabled security tools identify a security issue the corresponding check fails and protect the codebase.</p> <p>For Bandit, Shellcheck, and Semgrep tools the Github Actions integration converts the security findings to Junit and Checkstyle outputs that Github can present in the <code>Files changed</code> tab to help the troubleshooting.</p> <p>If there is no security findings from these tools:</p> <ul> <li>the <code>Checkstyle Source Code Analyzer report</code> will report <code>0 violation(s) found</code> that means the Shellcheck tool has not found any issue</li> <li>the <code>JUnit Test Report</code> will report <code>No test results found!</code> that means neither the Semgrep nor the Bandit tools have not found any issue</li> </ul> <p>Notice: As the actual security scanning is not part of the <code>Checkstyle Source Code Analyzer</code> or <code>JUnit</code> these reports will report 0s as execution time. The scanning of these tools are executed as part of the <code>Security Scans</code></p>"},{"location":"developer_guides/variables.html","title":"Variables","text":""},{"location":"developer_guides/variables.html#cdk-cicd-wrapper-variables","title":"CDK CI/CD Wrapper Variables","text":"ENV Variable Package.json config Default Value Description AWS_REGION deployment region ACCOUNT_RES account id for resources account where pipeline will run ACCOUNT_DEV account id for DEV environment account ACCOUNT_INT account id for INT environment account ACCOUNT_PROD account id for PROD environment account RES_ACCOUNT_AWS_PROFILE sets the named profile to use for the RES account. this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> DEV_ACCOUNT_AWS_PROFILE sets the named profile to use for the DEV account. this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> INT_ACCOUNT_AWS_PROFILE sets the named profile to use for the INT account. this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> PROD_ACCOUNT_AWS_PROFILE sets the named profile to use for the PROD account. this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> AWS_PROFILE sets the default named profile to use for aws cli or cdk commands when no <code>--profile</code> is provided. set to the same value as <code>RES_ACCOUNT_AWS_PROFILE</code> this profile must exist in <code>~/.aws/credentials</code> or <code>~/.aws/config</code> applicationName Wrapper sets the name of the Application CDK_QUALIFIER cdkQualifier wrapper used to distinguish between multiple deployments of a VP project in the same account. Good practice to customize per deployment. GIT_REPOSITORY repositoryName sets the name of the Git repository in the format org/name REPOSITORY_TYPE repositoryType sets the type of the repository, <code>GITHUB</code> or <code>CODECOMMIT</code> CODESTAR_CONNECTION_ARN sets the codestar connection required for GITHUB type CICD_VPC_TYPE cicdVpcType NO_VPC sets the type of the VPC: <code>NO_VPC</code>, <code>VPC</code>, or <code>VPC_FROM_LOOK_UP</code>. CICD_VPC_ID cicdVpcId for use with <code>VPC_FROM_LOOK_UP</code> to set the vpc ID CICD_VPC_CIDR cicdVpcCidr 172.31.0.0/20 for use with <code>VPC</code> to set the CIDR block of the VPC CICD_VPC_CIDR_MASK cicdVpcCidrMask 24 for use with <code>VPC</code> to set the Subnet size PROXY_SECRET_ARN used to set the ARN for the proxy secrets to enable proxy"},{"location":"developer_guides/vcs_codecommit.html","title":"AWS CodeCommit Integration","text":"<p>Note: AWS CodeCommit will be deemphasized after July 25, 2024. Consider using S3-based or GitHub repositories instead.</p>"},{"location":"developer_guides/vcs_codecommit.html#configuration","title":"Configuration","text":"<p>Configure your pipeline to use CodeCommit:</p> <pre><code>import { RepositorySource, PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n  .repository(RepositorySource.codecommit())\n  // ... other configuration\n  .synth(app);\n</code></pre>"},{"location":"developer_guides/vcs_codecommit.html#quick-setup","title":"Quick Setup","text":"<p>After the configure has finished and generated the .env file then you need to add the changes into git and commit them.</p> <p>You need to configure the downstream of the repository for deployment. In your local machine you need to install the <code>git-remote-codecommit</code> using the following command:</p> <pre><code>sudo pip3 install git-remote-codecommit\n</code></pre> <pre><code>CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD);\ngit remote add downstream codecommit::${AWS_REGION}://${RES_ACCOUNT_AWS_PROFILE}@${GIT_REPOSITORY};\ngit commit -am \"feat: init downstream\";\ngit push -u downstream ${CURRENT_BRANCH}:main ### default branch for CodePipeline can be configured in config/AppConfig.ts\n</code></pre>"},{"location":"developer_guides/vcs_codecommit.html#changing-default-branch","title":"Changing default branch","text":"<p>You can change the default branch which is picked up by the CodePipeline to trigger the pipeline with the following code snippet (during the pipeline definition):</p> <pre><code>import { BasicRepositoryProvider, PipelineBlueprint,RepositorySource } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n  .repository(RepositorySource.codecommit({\n    repositoryName: 'my-repo',\n    branch: 'main',\n    enableCodeGuruReviewer: true,\n    enablePullRequestChecks: true\n  }))\n</code></pre>"},{"location":"developer_guides/vcs_codecommit.html#pointers-to-external-documentation","title":"Pointers to external documentation","text":"<ul> <li>Setup steps for HTTPS connections to AWS CodeCommit with git-remote-codecommit</li> </ul>"},{"location":"developer_guides/vcs_github.html","title":"GitHub Integration - AWS CodeStar Connection","text":"<p>To be able to use GitHub repositories in AWS CodePipeline with CDK CI/CD Wrapper, an AWS CodeStar Connection needs to be established. For more details go to the GitHub connection page.</p>"},{"location":"developer_guides/vcs_github.html#quick-setup","title":"Quick Setup","text":"<p>To create the AWS CodeStar Connection go to the desired AWS account where the AWS CodePipeline is planned to be placed and execute the following command.</p> <pre><code>aws codestar-connections create-connection --provider-type GitHub --profile $RES_ACCOUNT_AWS_PROFILE --region ${AWS_REGION} --connection-name MyConnection\n</code></pre> <p>This will initialize the connection from the AWS side. As a follow up go to the AWS CodeStar Connection on the Console and follow up the installation steps through the browser.</p> <p>Note: The user needs to have the following permission to establish the connection.</p> <ul> <li>Ownership permission on the GitHub Organization / Account</li> <li>IAM Permissions on the account</li> <li>codestar-connections:ListConnections</li> <li>codestar-connections:CreateConnection</li> <li>codestar-connections:UpdateConnectionInstallation</li> </ul>"},{"location":"developer_guides/vcs_github.html#configuration","title":"Configuration","text":"<p>Configure your pipeline to use GitHub:</p> <pre><code>import { RepositorySource, PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n  .repository(RepositorySource.github({\n    repositoryName: 'owner/my-repo',\n    branch: 'main',\n    codeStarConnectionArn: 'arn:aws:codestar-connections:region:account:connection/uuid'\n  }))\n  .synth(app);\n</code></pre>"},{"location":"developer_guides/vcs_github.html#known-issues","title":"Known Issues","text":"<ul> <li>Careful if you see a page like this when you open the Console  You might be using a wrong region or you don't have the right permissions.</li> <li>Make sure you have cookies enabled for your browser and you have the right permissions on both AWS and GitHub side or you could see something as shown in the screenshot below </li> </ul>"},{"location":"developer_guides/vcs_github.html#pointers-to-external-documentation","title":"Pointers to external documentation","text":"<ul> <li>GitHub connection</li> <li>Update a pending connection</li> </ul>"},{"location":"developer_guides/vcs_s3.html","title":"Amazon S3 based Git Repository Integration","text":"<p>As AWS CodeCommit will be deemphasized after July 25, 2024, you can use S3 as a Git repository with CDK CI/CD Wrapper. This approach uses the git-remote-s3 tool to enable S3 as a git remote and LFS server.</p>"},{"location":"developer_guides/vcs_s3.html#prerequisites","title":"Prerequisites","text":"<ul> <li>Install the git-remote-s3 Python package:</li> </ul> <pre><code>pip install git-remote-s3\n</code></pre>"},{"location":"developer_guides/vcs_s3.html#quick-setup","title":"Quick Setup","text":"<p>Configure your pipeline to use S3 as the repository:</p> <pre><code>import { RepositorySource, PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst pipeline = PipelineBlueprint.builder()\n  .repository(RepositorySource.s3({\n    bucketName: 'my-git-bucket',\n    prefix: 'my-repo',  // Optional: Use a prefix to organize multiple repos\n    branch: 'main',     // Optional: Defaults to 'main'\n    roles: ['arn:aws:iam::123456789012:role/MyRole'] // Optional: Roles that can access the repo\n  }))\n  // ... other configuration\n  .synth(app);\n</code></pre>"},{"location":"developer_guides/vcs_s3.html#cloning-the-repository","title":"Cloning the Repository","text":"<p>To clone a repository stored in S3:</p> <pre><code># For repositories without a prefix\ngit clone s3+zip://my-git-bucket my-local-repo\n\n# For repositories with a prefix\ngit clone s3+zip://my-git-bucket/my-repo my-local-repo\n</code></pre> <p>The <code>s3+zip://</code> protocol ensures that an additional zip archive is created alongside the git bundle, which is required for AWS CodePipeline integration.</p>"},{"location":"developer_guides/vcs_s3.html#working-with-branches","title":"Working with Branches","text":"<p>Creating and pushing branches works as with any other Git repository:</p> <pre><code>git checkout -b feature/new-feature\ngit add .\ngit commit -m \"feat: add new feature\"\ngit push origin feature/new-feature\n</code></pre>"},{"location":"developer_guides/vcs_s3.html#large-file-storage-lfs-support","title":"Large File Storage (LFS) Support","text":"<p>The S3-based repository supports Git LFS. To use it:</p> <ol> <li> <p>Install git-lfs To use LFS you need to first install git-lfs. You can refer to the official documentation on how to do this on your system.</p> </li> <li> <p>In your repository: <pre><code>git-lfs-s3 install\ngit lfs track \"*.zip\"  # Track large files\ngit add .gitattributes\n</code></pre></p> </li> </ol>"},{"location":"developer_guides/vcs_s3.html#security-considerations","title":"Security Considerations","text":"<ul> <li>All data is encrypted at rest using Amazon S3's encryption capabilities</li> <li>Use bucket policies and IAM roles to control access</li> </ul>"},{"location":"developer_guides/vcs_s3.html#using-with-aws-codepipeline","title":"Using with AWS CodePipeline","text":"<p>The Amazon S3 based repository automatically creates ZIP archives that can be used as source artifacts in AWS CodePipeline. The ZIP files are stored at: <pre><code>s3://my-git-bucket/my-repo/refs/heads/&lt;branch&gt;/repo.zip\n</code></pre></p>"},{"location":"developer_guides/vcs_s3.html#known-limitations","title":"Known Limitations","text":"<ul> <li>No built-in pull request functionality</li> <li>Concurrent writes need to be managed carefully</li> <li>Branch deletion must be done using the <code>git-remote-s3</code> CLI</li> </ul> <p>For more information about git-remote-s3, visit the official repository.</p>"},{"location":"faqs/index.html","title":"Frequently asked questions","text":"<p>Below we list the most common issues you might encounter during the deployment using the CDK CI/CD Wrapper</p>"},{"location":"faqs/index.html#common-issues","title":"Common Issues","text":"<ul> <li>When using Cloud9 in the RES account and you want to deploy the code cross-account then you need to define the profiles for the DEV and INT Account as usual (adding them in the ~/.aws/config). The RES profile can be omitted in this case while doing the initial bootstrap, except for the DEV and INT or PROD stages where the profile is mandatory to establish a trust relationship between the RES account and the other environments (DEV/INT/PROD).</li> <li><code>when calling the PutParameter operation: The security token included in the request is invalid</code>: This usually happens if you use Cloud9. Make sure to disable AWS managed temporary credentials and give the full admin access to your Cloud9 Managed role in order to be able to execute everything necessary. </li> <li><code>Resource handler returned message: \"Policy contains a statement with one or more invalid principals. (Service: Kms, Status Code: 400, Request ID: a9f9e73b-cf2c-4862-9536-af92aa0ed656)\" (RequestToken: 949e9034-f910-7eb3-a4a2-427bc9e676b9, HandlerErrorCode: InvalidRequest)</code></li> <li>Make sure that the role you are trying to add to the policy exists in the given account.</li> <li>If you get <code>InvalidLocationConstraint</code> error during bucket creation, while executing <code>aws s3api create-bucket</code>   command, then consider removing <code>--create-bucket-configuration LocationConstraint</code> parameter. This error usually occurs   if the default region is the same as the one set in the LocationConstraint.</li> <li>If the pipeline fails with <code>AccessDeniedException</code> error or lacks any AWS resources, then this might be caused by the   wrong region setup. In this case some resources are deployed into another region. Check the region value that is set in   the <code>export_vars.sh</code> when you initially created the script or your cli env var <code>AWS_REGION</code>. The region should   be consistent across those files.</li> <li>Make sure the <code>CDK_QUALIFIER</code> meets the requirement of CDK - Qualifier must be an alphanumeric identifier of at most 10 characters</li> <li>If you have already deployed RES/DEV/INT and want to disable INT then please do the following:   <pre><code>export ACCOUNT_INT=\"-\"\nnpx dotenv-cli -- npm run cdk deploy --all --region ${AWS_REGION} --profile $RES_ACCOUNT_AWS_PROFILE --qualifier ${CDK_QUALIFIER}\n</code></pre>   After performing this please do not forget to delete your CloudFormation resources on the previous INT Account.</li> <li>If you see an error <code>CreateRepository request is not allowed because there is no existing repository in this AWS account or AWS Organization</code> when performing the initial deploy step it means that your AWS Organization is not able to create new CodeCommit repositories, so you will need to choose the CodeStar option to connect to an external repository.  CodeCommit repositories can only be created in AWS Organizations that already had at least 1 CodeCommit repository in a child account on July 25, 2024.</li> </ul>"},{"location":"getting_started/index.html","title":"Getting Started with the CDK CI/CD Wrapper","text":"<p>This guide gives you clear steps to set up and customize a Continuous Integration and Continuous Delivery (CI/CD) pipeline for your AWS CDK project. Following these steps will automate the build, testing, and delivery of your AWS CDK project, giving you a smooth workflow.</p>"},{"location":"getting_started/index.html#overview","title":"Overview","text":"<p>The CI/CD pipeline simplifies your development process, making sure your project undergoes thorough testing and validation before moving to different stages like development, integration, or production. It utilizes AWS services like AWS CodePipeline, AWS CodeBuild, and AWS CodeCommit/GitHub to manage the entire workflow seamlessly.</p>"},{"location":"getting_started/index.html#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure that you have the following prerequisites in place:</p> <ol> <li>AWS Accounts: You will need access to multiple AWS accounts for different deployment stages (e.g., development, integration, production). If you prefer, you can also use a single account setup.</li> <li>AWS CLI Profiles: Configure AWS CLI profiles with appropriate permissions for each AWS account you plan to use.</li> <li>jq Command Line JSON Processor: Install the <code>jq</code> command-line JSON processor (version 1.5 or later).</li> <li>Docker: Install Docker (version 24.0.x or later).</li> <li>Python and Pipenv: If you plan to develop Python Lambda functions, ensure that you have Python (version 3.11 or later) and Pipenv (version 2023 or later) installed.</li> <li>Version Control System (VCS): The CI/CD pipeline provisions an AWS CodeCommit Git repository by default for hosting your project's source code. However, not all accounts can use CodeCommit after July 25, 2024.  You can also use CodeConnections so that the project source code is stored in Bitbucket Cloud, Github or Gitlab.</li> </ol> <p>For more detailed information on prerequisites, refer to the Prerequisites documentation.</p> <p>Below we explain how to integrate the CDK CI/CD Wrapper into existing and new CDK Projects</p>"},{"location":"getting_started/index.html#new-cdk-project","title":"New CDK project","text":"<p>You can apply the CDK CI/CD Wrapper to any of your existing CDK projects enable the CI/CD around your solution. If you don't have an existing CDK project then you can create one as shown in this guide step-by-step:</p> <pre><code>mkdir my-project\ncd my-project\nnpx aws-cdk@latest init app --language typescript\n</code></pre>"},{"location":"getting_started/index.html#installation","title":"Installation","text":"<ol> <li>Install the CDK CI/CD Wrapper pipeline package by running the following command:</li> </ol> <pre><code>npm i @cdklabs/cdk-cicd-wrapper @cdklabs/cdk-cicd-wrapper-cli\n</code></pre> <p>Note: If the <code>@cdklabs</code> scope is not available from the public NPM registry, you will need to configure a private NPM registry.</p>"},{"location":"getting_started/index.html#setup-local-environment","title":"Setup Local Environment","text":"<p>We suggest using the provided CLI tool to set up your local environment, as it simplifies the configuration process for the CI/CD pipeline. Simply follow these steps:</p> <ol> <li> <p>Run the <code>npx @cdklabs/cdk-cicd-wrapper-cli@latest configure</code> command and follow the instructions.</p> </li> <li> <p>After modifying the placeholders in the script</p> </li> </ol> <p>Note: The CLI Configure script supports the RES, DEV, INT, and PROD stages by default, but you can extend the list of stages as needed. If you plan to use a GitHub repository to host your project, you will need to know your AWS CodeStar Connection ARN.</p>"},{"location":"getting_started/index.html#bootstrap-your-stages","title":"Bootstrap your stages","text":"<p>The CDK CI/CD Wrapper uses the AWS CDK Toolkit with a cross-account trust relationship to deploy to multiple AWS accounts. This bootstrapping process must be established for each stage, and each account must have a trust relationship with the RES account..</p> <p>If you are reusing an existing CDK bootstrapping setup, you can skip this step. Otherwise, follow the instructions below to bootstrap your stages:</p> <ol> <li>Prepare the RES stage:</li> </ol> <pre><code>CDK_QUALIFIER=$(jq -r '.config.cdkQualifier' package.json)\nnpx dotenv-cli -- npm run cdk bootstrap -- --profile $RES_ACCOUNT_AWS_PROFILE --qualifier ${CDK_QUALIFIER} aws://${ACCOUNT_RES}/${AWS_REGION}\n</code></pre> <ol> <li>Prepare the DEV stage:</li> </ol> <pre><code>CDK_QUALIFIER=$(jq -r '.config.cdkQualifier' package.json)\nnpx dotenv-cli -- npm run cdk bootstrap -- --profile $DEV_ACCOUNT_AWS_PROFILE  --qualifier ${CDK_QUALIFIER} --cloudformation-execution-policies \\\narn:aws:iam::aws:policy/AdministratorAccess \\\n--trust ${ACCOUNT_RES} aws://${ACCOUNT_DEV}/${AWS_REGION}\n</code></pre> <ol> <li>Prepare the INT stage:</li> </ol> <pre><code>CDK_QUALIFIER=$(jq -r '.config.cdkQualifier' package.json)\nnpx dotenv-cli -- npm run cdk bootstrap -- --profile $INT_ACCOUNT_AWS_PROFILE --qualifier ${CDK_QUALIFIER} --cloudformation-execution-policies \\\narn:aws:iam::aws:policy/AdministratorAccess \\\n--trust ${ACCOUNT_RES} aws://${ACCOUNT_INT}/${AWS_REGION}\n</code></pre> <ol> <li>Prepare the PROD stage:</li> </ol> <pre><code>CDK_QUALIFIER=$(jq -r '.config.cdkQualifier' package.json)\nnpx dotenv-cli -- npm run cdk bootstrap -- --profile $PROD_ACCOUNT_AWS_PROFILE --qualifier ${CDK_QUALIFIER} --cloudformation-execution-policies \\\narn:aws:iam::aws:policy/AdministratorAccess \\\n--trust ${ACCOUNT_RES} aws://${ACCOUNT_PROD}/${AWS_REGION}\n</code></pre> <p>Note: Update the variables in the command with your actual account IDs and AWS region. To activate <code>PROD</code>, you must explicitly include it in the <code>.defineStages([Stage.RES, Stage.DEV, Stage.INT, Stage.PROD])</code> as outlined in step 2 below. Always specify all the stages you require; do not add only <code>Stage.PROD</code> and assume the other stages will be included automatically. For more info on how to add custom stages please refer to here</p>"},{"location":"getting_started/index.html#configure-gitignore","title":"Configure .gitignore","text":"<p>Ensure that the following lines are in your <code>.gitignore</code> file:</p> <ul> <li><code>.npmrc</code> (if you are using a private NPM repository)</li> <li><code>.env</code></li> </ul>"},{"location":"getting_started/index.html#cdk-project-setup","title":"CDK project setup","text":"<p>To set up the CI/CD pipeline in your AWS CDK project, follow these steps:</p> <ol> <li> <p>Open your entry file, typically located at <code>bin/&lt;your-main-file&gt;.ts</code> (where <code>your-main-file</code> is the name of your root project directory).</p> </li> <li> <p>Include the <code>PipelineBlueprint.builder().synth(app)</code> statement in your entry file, like so:</p> </li> </ol> <pre><code>import * as cdk from 'aws-cdk-lib';\nimport { PipelineBlueprint, Stage } from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\n\n/**\n * To enable the `Stage.PROD` stage in your pipeline you have to explicitly add it into the `.defineStages()` hook as below.\n * In our case we have DEV, INT and PROD so we add all of them explicitly as we assume you have them all in your project.\n * Attention: Any stage not included in the defineStages() function will be excluded from the pipeline.\n * This is done for safety reasons, to not export accidentally `PROD` env vars and have it deployed into the wrong account.\n */\nPipelineBlueprint.builder().defineStages([Stage.RES, Stage.DEV, Stage.INT, Stage.PROD]).synth(app);\n</code></pre> <p>This will deploy the CI/CD pipeline with its default configuration without deploying any stacks into the staging accounts.</p> <ol> <li>Optional: If you want to include additional stacks in the CI/CD pipeline, modify your entry file as follows:</li> </ol> <pre><code>import * as cdk from 'aws-cdk-lib';\nimport { PipelineBlueprint, Stage, GlobalResources } from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\n\nPipelineBlueprint.builder().defineStages([Stage.RES, Stage.DEV, Stage.INT, Stage.PROD]).addStack({\nprovide: (context) =&gt; {\n   // Create your stacks here\n   new YourStack(context.scope, `${context.blueprintProps.applicationName}YourStack`, {\n      applicationName: context.blueprintProps.applicationName,\n      stageName: context.stage,\n   });\n   new YourOtherStack(context.scope, `${context.blueprintProps.applicationName}YourOtherStack`, {\n      applicationQualifier: context.blueprintProps.applicationQualifier,\n      encryptionKey: context.get(GlobalResources.ENCRYPTION)!.kmsKey,\n   });\n}}).synth(app);\n</code></pre> <p>Note: Refer to the Developer Guide for more information on the <code>PipelineBlueprint</code>.</p> <ol> <li> <p>The CDK CI/CD Wrapper expects to have the <code>validate</code>, <code>lint</code>, <code>test</code>, <code>audit</code> scripts defined. If you are missing any of the <code>npm run</code> scripts (e.g., ), or want to use the provided CLI tool for one or more actions, you should add the following definitions to your <code>package.json</code> file:</p> </li> <li> <ol> <li>Adding cdk script (necessay when you run the <code>npm run cdk</code> and uses the local cdk version rather than the global one)   <pre><code> jq --arg key \"cdk\" --arg val \"npx aws-cdk@2.162.1\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\n</code></pre></li> </ol> </li> <li> <ol> <li>Adding validate script    <pre><code>jq --arg key \"validate\" --arg val \"cdk-cicd validate\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"validate:fix\" --arg val \"cdk-cicd validate --fix\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\n</code></pre></li> </ol> </li> <li> <ol> <li>Adding lint script, we recommend using eslint and you can initalise it    <pre><code>npm init @eslint/config\n\njq --arg key \"lint\" --arg val \"eslint . --ext .ts --max-warnings 0\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"lint:fix\" --arg val \"eslint . --ext .ts --fix\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\n</code></pre></li> </ol> </li> <li> <ol> <li>Adding audit scripts    <pre><code>npm install --save -D concurrently\njq --arg key \"audit\" --arg val \"concurrently 'npm:audit:*(\\!fix)'\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"audit:deps:nodejs\" --arg val \"cdk-cicd check-dependencies --npm\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"audit:deps:python\" --arg val \"cdk-cicd check-dependencies --python\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"audit:deps:security\" --arg val \"cdk-cicd security-scan --bandit --semgrep --shellcheck\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"audit:license\" --arg val \"npm run license\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"audit:fix:license\" --arg val \"npm run license:fix\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"license\" --arg val \"cdk-cicd license\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\njq --arg key \"license:fix\" --arg val \"cdk-cicd license --fix\" '.scripts[$key] = $val' package.json | jq . &gt; package.json.tmp; mv package.json.tmp package.json;\n</code></pre></li> </ol> </li> </ol> <pre><code>{\n  ...\n  \"scripts\": {\n    \"audit:deps:nodejs\": \"cdk-cicd check-dependencies --npm\",\n    \"audit:deps:python\": \"cdk-cicd check-dependencies --python\",\n    \"audit:fix:license\": \"npm run license:fix\",\n    \"audit:license\": \"npm run license\",\n    \"audit:scan:security\": \"cdk-cicd security-scan --bandit --semgrep --shellcheck --ci\",\n    \"audit\": \"npx concurrently 'npm:audit:*(!fix)'\",\n    \"cdk\": \"npx aws-cdk@2.162.1\",\n    \"license:fix\": \"cdk-cicd license --fix\",\n    \"license\": \"cdk-cicd license\",\n    \"lint:fix\": \"eslint . --ext .ts --fix\",\n    \"lint\": \"eslint . --ext .ts --max-warnings 0\",\n    \"test\": \"jest\",\n    \"validate:fix\": \"cdk-cicd validate --fix\",\n    \"validate\": \"cdk-cicd validate\",\n    ...\n  }\n  ...\n}\n</code></pre> <p>Note: If you are using <code>eslint</code> for linting, ensure that the configuration files are present or generate them with <code>npm init @eslint/config</code>.</p> <ol> <li>Before deploying, run the following commands to ensure your project is ready:</li> </ol> <pre><code>npm run validate:fix\nnpm run audit:fix:license\n</code></pre> <ul> <li><code>npm run validate:fix</code> will create the required <code>package-verification.json</code> file for you.</li> <li> <p><code>npm run audit:fix:license</code> will generate a valid Notice file for you.</p> </li> <li> <p>Deploy all the stacks by running the following command:</p> </li> </ul> <pre><code>npx dotenv-cli -- npm run cdk deploy -- --all --region ${AWS_REGION} --profile $RES_ACCOUNT_AWS_PROFILE --qualifier ${CDK_QUALIFIER}\n</code></pre> <p>Once the command finishes, the following CDK Stacks will be deployed into your RES Account:</p> <ul> <li>PipelineRepository: Responsible for either creating the CodeCommit repository  and setting up PullRequest automation for CodeGuru scanning and running a set of configured commands, or establishing the CodeStar connection between your AWS RES Account and the configured GitHub repository.</li> <li>SSMParameterStack: Responsible for creating parameters in the SSM Parameter Store, such as Account IDs.</li> <li>VPCStack: Responsible for enabling the running of the build stages of the pipeline in a VPC, with or without a proxy. By default, this stack is not created unless configured via <code>npx @cdklabs/cdk-cicd-wrapper-cli@latest configure</code>. Check here for more information on possible configurations.</li> <li>EncryptionStack: Responsible for creating the KMS Key used to encrypt all created CloudWatch Log Groups.</li> <li>PipelineStack: Responsible for creating the CodeCommit Repository and the CodePipeline with all the CodeBuild Steps.</li> </ul>"},{"location":"getting_started/index.html#configuring-continuous-integration","title":"Configuring Continuous Integration","text":"<p>The CI/CD pipeline comes with a set of predefined steps for checking the correctness of your source code:</p> <ul> <li><code>npm ci ##  Downloads the NPM dependencies.</code></li> <li><code>npm run validate ## Validates that the package-lock.json file has not been changed or corrupted.</code></li> <li><code>npm run audit ## Validates that the third-party dependencies are free from any known CVEs.</code></li> <li><code>npm run lint ## Checks source code linting.</code></li> <li><code>npm run build ## Builds the source code.</code></li> <li><code>npm run test ## Runs the included tests.</code></li> <li><code>npm run cdk synth ## Synthesizes the CDK projects and runs the CDK NAG.</code></li> </ul> <p>If all steps are finished successfully, the Continuous Integration (CI) part is considered complete.</p> <p>Note: The steps described above can be modified and extended. Additionally, any of the <code>npm run</code> steps can be disabled by changing the corresponding script definition to <code>true</code>. Use this approach only as a last resort.</p> <p>Note: A few additional steps are executed before the <code>npm run validate</code> step for configuring NPM registries and HTTP proxies.</p> <p>Note: The same steps are executed as part of the AWS CodeCommit's PullRequest review process.</p>"},{"location":"getting_started/index.html#deploy-changes-with-gitops","title":"Deploy Changes with GitOps","text":"<p>After the required infrastructure has been deployed, you can apply the GitOps practice to deploy changes.</p>"},{"location":"getting_started/index.html#push-the-local-repository-to-remote-codecommit","title":"Push the Local Repository to Remote (CodeCommit)","text":"<p>If you are using CodeCommit, you need to configure the downstream of the repository for deployment. On your local machine, install the <code>git-remote-codecommit</code> package using the following command:</p> <pre><code>sudo pip3 install git-remote-codecommit\n</code></pre> <p>Then, push your local repository to the remote CodeCommit repository:</p> <pre><code>CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD);\ngit remote add origin codecommit::${AWS_REGION}://${RES_ACCOUNT_AWS_PROFILE}@${GIT_REPOSITORY};\ngit commit -am \"feat: init origin\";\ngit push -u origin ${CURRENT_BRANCH}:main\n</code></pre> <p>Note: The default branch for the CI/CD pipeline can be configured.</p>"},{"location":"getting_started/index.html#push-the-local-repository-to-remote-github","title":"Push the Local Repository to Remote (GitHub)","text":"<p>If you are using GitHub, add the remote repository and push your local repository:</p> <pre><code>CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD);\ngit remote add origin git@github.com:${GIT_REPOSITORY}.git;\ngit commit -am \"feat: init origin\";\ngit push -u origin ${CURRENT_BRANCH}:main\n</code></pre> <p>Note: The <code>origin</code> remote alias might already be configured, in which case you need to change or replace it.</p> <p>Note: The default branch for the CI/CD pipeline can be configured.</p> <p>By following these steps, you have successfully set up and configured the CI/CD pipeline for your AWS CDK project. Your project will now be automatically built, tested, and deployed to the appropriate stages whenever changes are pushed to the remote repository.</p>"},{"location":"getting_started/migration_guide.html","title":"Migration Guide from CDK CI/CD Wrapper","text":"<p>This topic details the required steps to migrate existing Vanilla Pipeline projects to use the CDK CI/CD Wrapper.</p>"},{"location":"getting_started/prerequisites.html","title":"Prerequisites","text":"<p>This documentation provides a step-by-step guide for setting up the necessary prerequisites to work with AWS Lambda functions and CDK (Cloud Development Kit) pipelines. Before proceeding, ensure you have the following dependencies installed and configured correctly.</p>"},{"location":"getting_started/prerequisites.html#aws-account","title":"AWS Account","text":"<ul> <li>You need to have access to an AWS account for the respective environments (RES/DEV/INT/PROD).</li> </ul>"},{"location":"getting_started/prerequisites.html#operating-system","title":"Operating System","text":"<ul> <li>The setup can be performed on macOS, Linux, or Windows. If you're using Windows, it's recommended to use the Linux Subsystem for Windows (WSL) or a Cloud9 environment with Ubuntu Server 22.04 LTS Platform in your RES account.</li> </ul>"},{"location":"getting_started/prerequisites.html#terminal","title":"Terminal","text":"<ul> <li>You need to have a terminal emulator installed, such as Bash or ZSH.</li> </ul>"},{"location":"getting_started/prerequisites.html#docker","title":"Docker","text":"<ul> <li>Install Docker version 24.0.x or later.</li> </ul>"},{"location":"getting_started/prerequisites.html#aws-cli","title":"AWS CLI","text":"<ul> <li>Install the AWS Command Line Interface (AWS CLI) version 2 by following the instructions here.</li> </ul>"},{"location":"getting_started/prerequisites.html#aws-credentials-and-profiles","title":"AWS Credentials and Profiles","text":"<ul> <li>Configure your AWS credentials and profiles for each environment (RES/DEV/INT/PROD) by following the instructions here. The credentials should be stored in the <code>~/.aws/config</code> file.</li> </ul>"},{"location":"getting_started/prerequisites.html#nodejs-and-npm","title":"Node.js and NPM","text":"<ul> <li>Install Node.js version 18.18. or higher and NPM version 10.2. or higher.</li> </ul>"},{"location":"getting_started/prerequisites.html#jq-command-line-json-processor","title":"jq Command-line JSON Processor","text":"<ul> <li>Install the <code>jq</code> command-line JSON processor by following the instructions for your operating system here.</li> </ul>"},{"location":"getting_started/prerequisites.html#additional-dependencies-for-python-lambda-functions","title":"Additional Dependencies for Python Lambda Functions","text":"<p>If you're developing Python Lambda functions, you'll need the following additional dependencies:</p> <ul> <li>Install Python version 3.11 or later.</li> <li>Install Pipenv version 2023.* or later by following the instructions here.</li> </ul>"},{"location":"getting_started/projen.html","title":"Setting up a project with Projen","text":"<p>Projen is a tool that helps define and maintain complex project configurations through code. It allows you to generate project configuration files from a well-typed definition, making it easier to manage and maintain your project structure.</p>"},{"location":"getting_started/projen.html#prerequisites","title":"Prerequisites","text":"<p>Before getting started, ensure that you have the following prerequisites installed:</p> <ul> <li>Node.js (version 16.x or later)</li> <li>npm (comes bundled with Node.js)</li> </ul> <p>Projen doesn't need to be installed separately. You will be using <code>npx</code> to run Projen, which takes care of all the required setup steps.</p>"},{"location":"getting_started/projen.html#step-1-initialize-a-new-project","title":"Step 1: Initialize a new project","text":"<p>Follow these steps to initialize a new project using Projen:</p> <ol> <li>Open your terminal or command prompt.</li> <li>Navigate to the directory where you want to create your new project.</li> <li>Run the following command to initialize a new CDK CI/CD Wrapper project:</li> </ol> <pre><code>npx projen@latest new awscdk-app-ts --no-git --deps @cdklabs/cdk-cicd-wrapper-projen\n</code></pre> <p>This command initializes a new AWS CDK TypeScript app project with the <code>@cdklabs/cdk-cicd-wrapper-projen</code> dependency.</p> <ol> <li>Open the <code>.projenrc.ts</code> file and add the following code:</li> </ol> <pre><code>import { awscdk } from 'projen';\nimport { CdkCICDWrapper } from '@cdklabs/cdk-cicd-wrapper-projen';\n\nconst project = new awscdk.AwsCdkTypeScriptApp({\n  cdkVersion: '2.1.0',\n  defaultReleaseBranch: 'main',\n  deps: ['@cdklabs/cdk-cicd-wrapper'],\n  name: 'project',\n  projenrcTs: true,\n});\n\n//@ts-ignore Projen Versions can be different during the upgrade process and would resolve complains about assignability issues.\nnew CdkCICDWrapper(project, {\n  cdkQualifier: 'wrapper',\n  repositoryName: 'projen-sample-wrapper',\n  repositoryType: 'CODECOMMIT', // Must be 'GITHUB' for a codestar connection\n});\n\nproject.synth();\n</code></pre> <p>This code configures the project with the necessary settings for the AWS CDK and the <code>CdkCICDWrapper</code> component.  Note that a PROD stage will not be created by default, so add it here if required.  eg.</p> <pre><code>new CdkCICDWrapper(project, {\n   cdkQualifier: 'wrapper',\n   repositoryName: 'projen-sample-wrapper',\n   repositoryType: 'CODECOMMIT',\n   stages: [ // Must be a list of all stages other than RES and may include custom stages\n      'DEV',\n      'INT',\n      'PROD',\n   ]\n});\n</code></pre> <ol> <li>Enable the project.</li> </ol> <pre><code>npx projen\n</code></pre> <ol> <li>Before deploying, run the following commands to ensure your project is ready:</li> </ol> <pre><code>npm run validate -- --fix\nnpm run license -- --fix\n</code></pre> <ul> <li><code>npm run validate -- --fix</code> will create the required <code>package-verification.json</code> file for you.</li> <li><code>npm run license -- --fix</code> will generate a valid Notice file for you.</li> </ul>"},{"location":"getting_started/projen.html#step-2-configure-stacks","title":"Step 2: Configure stacks","text":"<p>The <code>PipelineBlueprint</code> component provided by the <code>{{ npm_pipeline }}</code> package allows you to define and configure the stacks for your application. Here's an example of how you can configure your stacks:</p> <pre><code>import * as cdk from 'aws-cdk-lib';\nimport { PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\n\nPipelineBlueprint.builder().addStack({\n  provide: (context) =&gt; {\n    // Create your stacks here.  Note that the scope parameter must be `context.scope`, not `app`\n    new YourStack(context.scope, `${context.blueprintProps.applicationName}YourStack`, {\n      applicationName: context.blueprintProps.applicationName,\n      stageName: context.stage,\n    });\n    new YourOtherStack(context.scope, `${context.blueprintProps.applicationName}YourOtherStack`, {\n      applicationQualifier: context.blueprintProps.applicationQualifier,\n      encryptionKey: context.get(GlobalResources.Encryption)!.kmsKey,\n    });\n  }\n}).synth(app);\n</code></pre> <p>Note: Refer to the Developer Guide for more information on the <code>PipelineBlueprint</code> component and how to configure your stacks.</p>"},{"location":"getting_started/projen.html#step-3-configure-environment-variables-create-env-file","title":"Step 3: Configure environment variables / create .env file","text":"<p>The CDK CI/CD Wrapper uses environment variables to store sensitive information and configuration settings. The <code>CdkCICDWrapper</code> component creates a sample <code>.env</code> file in the root directory of your project and defines the necessary variables there. You must fill out the values for these variables.</p> <p>If you are using CodeConnections to access an external git repository, add the following value to the .env file with the correct values for region, account number and connection ID:</p> <pre><code>CODESTAR_CONNECTION_ARN=arn:aws:codeconnections:[region]:[account number]:connection/[connection ID]\n</code></pre> <p>This file is created once, and you must maintain it manually as needed.</p>"},{"location":"getting_started/projen.html#step-4-bootstrap-your-stages","title":"Step 4: Bootstrap your stages","text":"<p>The CDK CI/CD Wrapper uses the AWS CDK Toolkit with a cross-account trust relationship to deploy to multiple AWS accounts. This bootstrapping process must be established for each stage, and each account must have a trust relationship with the RES account.</p> <p>If you are reusing an existing CDK bootstrapping setup, you can skip this step. Otherwise, follow these instructions to bootstrap your stages:</p> <ol> <li>Prepare the RES stage:</li> </ol> <pre><code>npm run bootstrap RES\n</code></pre> <ol> <li>Prepare the DEV stage:</li> </ol> <pre><code>npm run bootstrap DEV\n</code></pre> <ol> <li>Prepare the INT stage:</li> </ol> <pre><code>npm run bootstrap INT\n</code></pre> <ol> <li>Prepare the PROD stage (if configured):</li> </ol> <pre><code>npm run bootstrap PROD\n</code></pre> <p>Note: The stages have to be defined in the <code>.projenrc.ts</code> file <code>CdkCICDWrapperOptions.stages</code> variable and PROD is not configured by default.  </p>"},{"location":"getting_started/projen.html#step-5-deploy-the-pipeline","title":"Step 5: Deploy the pipeline","text":"<p>Once you have completed the previous steps, you can deploy the pipeline:</p> <ol> <li>In your terminal or command prompt, navigate to the root directory of your project.</li> <li>Run the following command to deploy the pipeline:</li> </ol> <pre><code>npm run deploy\n</code></pre> <p>This command will prompt you to confirm the deployment and then create the necessary resources for your pipeline in AWS.</p>"},{"location":"getting_started/projen.html#step-6-push-your-changes-to-the-git-repository","title":"Step 6: Push your changes to the git repository","text":"<p>After the deployment is complete, Projen will automatically trigger the pipeline and begin the process of building, testing, and deploying your application infrastructure based on the defined stages. Push your changes to the Git repository to start the pipeline process.</p>"},{"location":"getting_started/projen.html#conclusion","title":"Conclusion","text":"<p>Congratulations! You have successfully set up a project with Projen and configured a pipeline for building and deploying your cloud-based application infrastructure. This documentation provides an overview of the process and guides you through the necessary steps.</p> <p>If you need further assistance or have any questions, please refer to the official Projen documentation or reach out to the project maintainers for support.</p>"},{"location":"getting_started/projen_with_taskfile.html","title":"Setting Up a Project with Projen","text":"<p>Projen is a tool that helps define and maintain complex project configurations through code. It allows you to generate project configuration files from a well-typed definition, making it easier to manage and maintain your project structure.</p>"},{"location":"getting_started/projen_with_taskfile.html#prerequisites","title":"Prerequisites","text":"<p>Before getting started, ensure that you have the following prerequisites installed:</p> <ul> <li>Node.js (version 16.x or later)</li> <li>npm (comes bundled with Node.js)</li> </ul> <p>Projen doesn't need to be installed separately. You will be using <code>npx</code> to run Projen, which takes care of all the required steps of the setup.</p>"},{"location":"getting_started/projen_with_taskfile.html#step-1-initialize-a-new-project","title":"Step 1: Initialize a new project","text":"<p>Follow these steps to initialize a new project using Projen:</p> <ol> <li>Open your terminal or command prompt.</li> <li>Navigate to the directory where you want to create your new project.</li> <li>Run the following command to initialize a new CDK CI/CD Wrapper project:</li> </ol> <pre><code>npx projen@latest new awscdk-app-ts --no-git --deps @cdklabs/cdk-cicd-wrapper-projen\n</code></pre> <p>This command initializes a new AWS CDK TypeScript app project with the <code>@cdklabs/cdk-cicd-wrapper-projen</code> dependency.</p> <ol> <li>Open the <code>.projenrc.ts</code> file and add the following code:</li> </ol> <pre><code>import { awscdk } from 'projen';\nimport { CdkCICDWrapper } from '@cdklabs/cdk-cicd-wrapper-projen';\n\nconst project = new awscdk.AwsCdkTypeScriptApp({\n  cdkVersion: '2.1.0',\n  defaultReleaseBranch: 'main',\n  deps: ['@cdklabs/cdk-cicd-wrapper'],\n  name: 'project',\n  projenrcTs: true,\n});\n\n//@ts-ignore Projen Versions can be different during the upgrade process and would resolve complains about assignability issues.\nnew CdkCICDWrapper(project, {\n  cdkQualifier: 'wrapper',\n  repositoryName: 'projen-sample-wrapper',\n  repositoryType: 'CODECOMMIT',\n  taskfile: true,\n});\n\nproject.synth();\n</code></pre> <p>This code configures the project with the necessary settings for the AWS CDK and the <code>CdkCICDWrapper</code> component.</p> <ol> <li> <p>Execute the <code>npx projen</code> command to enable the project.</p> </li> <li> <p>Before deploying, run the following commands to ensure your project is ready:</p> </li> </ol> <pre><code>task prepare\n</code></pre>"},{"location":"getting_started/projen_with_taskfile.html#step-2-configure-stacks","title":"Step 2: Configure stacks","text":"<p>The <code>PipelineBlueprint</code> component provided by the <code>{{ npm_pipeline }}</code> package allows you to define and configure the stacks for your application. Here's an example of how you can configure your stacks:</p> <pre><code>import * as cdk from 'aws-cdk-lib';\nimport { PipelineBlueprint } from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\n\nPipelineBlueprint.builder().addStack({\n  provide: (context) =&gt; {\n    // Create your stacks here\n    new YourStack(context.scope, `${context.blueprintProps.applicationName}YourStack`, {\n      applicationName: context.blueprintProps.applicationName,\n      stageName: context.stage,\n    });\n    new YourOtherStack(context.scope, `${context.blueprintProps.applicationName}YourOtherStack`, {\n      applicationQualifier: context.blueprintProps.applicationQualifier,\n      encryptionKey: context.get(GlobalResources.Encryption)!.kmsKey,\n    });\n  }\n}).synth(app);\n</code></pre> <p>Note: Refer to the Developer Guide for more information on the <code>PipelineBlueprint</code> component and how to configure your stacks.</p>"},{"location":"getting_started/projen_with_taskfile.html#step-3-configure-environment-variables-create-env-file","title":"Step 3: Configure environment variables / create .env file","text":"<p>The CDK CI/CD Wrapper uses environment variables to store sensitive information and configuration settings. The <code>CdkCICDWrapper</code> component creates a sample <code>.env</code> file in the root directory of your project and defines the necessary variables there. You must fill out the values for these variables.</p> <p>This file is created once, and you must maintain it manually as needed.</p>"},{"location":"getting_started/projen_with_taskfile.html#step-4-bootstrap-your-stages","title":"Step 4: Bootstrap your stages","text":"<p>The CDK CI/CD Wrapper uses the AWS CDK Toolkit with a cross-account trust relationship to deploy to multiple AWS accounts. This bootstrapping process must be established for each stage, and each account must have a trust relationship with the RES account.</p> <p>If you are reusing an existing CDK bootstrapping setup, you can skip this step. Otherwise, follow these instructions to bootstrap your stages:</p> <pre><code>task bootstrap\n</code></pre> <p>Note: The stages have to be defined in the <code>.env</code> file in the <code>STAGES_ENABLED</code> variable.</p>"},{"location":"getting_started/projen_with_taskfile.html#step-5-deploy-the-pipeline","title":"Step 5: Deploy the pipeline","text":"<p>Once you have completed the previous steps, you can deploy the pipeline:</p> <ol> <li>In your terminal or command prompt, navigate to the root directory of your project.</li> <li>Run the following command to deploy the pipeline:</li> </ol> <pre><code>task deploy\n</code></pre> <p>This command will prompt you to confirm the deployment and then create the necessary resources for your pipeline in AWS.</p>"},{"location":"getting_started/projen_with_taskfile.html#step-6-push-your-changes-to-the-git-repository","title":"Step 6: Push your changes to the git repository","text":"<p>After the deployment is complete, Projen will automatically trigger the pipeline and begin the process of building, testing, and deploying your application infrastructure based on the defined stages. Push your changes to the Git repository to start the pipeline process.</p>"},{"location":"getting_started/projen_with_taskfile.html#conclusion","title":"Conclusion","text":"<p>Congratulations! You have successfully set up a project with Projen and configured a pipeline for building and deploying your cloud-based application infrastructure. This documentation provides an overview of the process and guides you through the necessary steps.</p> <p>If you need further assistance or have any questions, please refer to the official Projen documentation or reach out to the project maintainers for support.</p>"},{"location":"mcp/index.html","title":"MCP Tools","text":"<p>The CDK CI/CD Wrapper provides specialized MCP (Model Context Protocol) Tools that integrate seamlessly with AI-powered development assistants to help diagnose, troubleshoot, and optimize your CDK CI/CD Wrapper applications.</p>"},{"location":"mcp/index.html#what-is-mcp","title":"What is MCP?","text":"<p>The Model Context Protocol (MCP) is an open standard that enables AI assistants to securely access external tools and data sources. MCP servers provide specialized capabilities that can be accessed by any MCP-compatible client, including popular AI coding assistants.</p>"},{"location":"mcp/index.html#available-mcp-tools","title":"Available MCP Tools","text":""},{"location":"mcp/index.html#debugger-server","title":"Debugger Server","text":"<p>The CDK CI/CD Wrapper Debugger is a specialized MCP server that provides comprehensive debugging and validation tools for CDK CI/CD Wrapper projects.</p> <p>Key Features: - \ud83d\udd27 Comprehensive Configuration Analysis - Validates all environment variables and configuration files - \ud83d\udcca Stage Definition Verification - Checks deployment stage configurations and account mappings - \ud83d\udd17 Git Provider Configuration - Validates GitHub/CodeCommit setup and connectivity - \u2699\ufe0f CI/CD Configuration Analysis - Analyzes CodePipeline or GitHub Actions configuration - \ud83d\udd0c Plugin Security Analysis - Identifies custom plugins and security implications - \ud83c\udf10 VPC Configuration Validation - Ensures proper VPC and networking setup</p> <p>Learn more about the Debugger \u2192 | View Source Code \u2192</p>"},{"location":"mcp/index.html#compatible-mcp-clients","title":"Compatible MCP Clients","text":"<p>The MCP tools work with any MCP-compatible client, including:</p> <ul> <li>Amazon Q CLI - Amazon's AI-powered command-line assistant</li> <li>Cline - The Collaborative AI Coder for VS Code</li> <li>Any other MCP-compatible client - Following the standard MCP protocol</li> </ul>"},{"location":"mcp/index.html#getting-started","title":"Getting Started","text":"<p>To get started with MCP tools:</p> <ol> <li>Choose an MCP Client - Install one of the compatible clients (we recommend Cline for VS Code)</li> <li>Configure the MCP Server - Set up the connection to the CDK CI/CD Wrapper MCP server</li> <li>Start Debugging - Ask your AI assistant to analyze your CDK CI/CD Wrapper project</li> </ol> <p>Example usage with any MCP-compatible AI assistant:</p> <pre><code>\"Can you use the cdk-cicd-wrapper-debugger to check my project configuration?\"\n</code></pre> <p>The AI assistant will automatically connect to the MCP server and provide comprehensive analysis and recommendations.</p>"},{"location":"mcp/index.html#benefits","title":"Benefits","text":"<ul> <li>AI-Powered Troubleshooting - Work with AI assistants to quickly identify and resolve issues</li> <li>Comprehensive Validation - Run complete health checks on your projects</li> <li>Proactive Issue Detection - Catch problems before they cause deployment failures</li> <li>Security Analysis - Identify potentially unsafe configurations and security risks</li> <li>Environment Validation - Ensure proper setup of all required components</li> </ul>"},{"location":"mcp/debugger.html","title":"CDK CI/CD Wrapper Debugger MCP Server","text":"<p>An MCP (Model Context Protocol) server providing specialized debugging tools for CDK CI/CD Wrapper applications.</p> <p>\ud83d\udcc2 View Source Code \u2192</p>"},{"location":"mcp/debugger.html#overview","title":"Overview","text":"<p>This MCP server provides a suite of tools for diagnosing and resolving common issues in CDK CI/CD Wrapper applications. It helps identify configuration problems, deployment failures, and environment setup issues that can occur when working with the CDK CI/CD Wrapper.</p>"},{"location":"mcp/debugger.html#implementation-details","title":"Implementation Details","text":"<p>This server uses the standard MCP Server implementation from the Python MCP SDK:</p> <ul> <li>Uses <code>from mcp.server.fastmcp import FastMCP</code> for proper MCP server initialization</li> <li>Provides six specialized debugging tools</li> <li>Runs with stdio transport for direct communication with MCP clients</li> </ul>"},{"location":"mcp/debugger.html#local-environment-requirements","title":"Local Environment Requirements","text":"<p>Before installing and running the debugger MCP server, ensure your environment meets the following requirements:</p> <ul> <li>Python 3.10+: The server requires Python 3.10 or newer</li> <li>pip or uv package manager: For installing dependencies</li> <li>AWS CLI: Configured with appropriate profiles if you want to test AWS resource access</li> <li>Cline AI extension: Installed in VSCode</li> <li>Git: For cloning the repository (if needed)</li> </ul> <p>For AWS functionality, the following environment should be configured:</p> <ul> <li>AWS credentials: Properly set up in <code>~/.aws/credentials</code> with necessary profiles</li> <li>AWS region: Configured in your environment or AWS config</li> </ul>"},{"location":"mcp/debugger.html#scripts","title":"Scripts","text":"<p>The debugger includes several utility scripts to streamline development and testing:</p>"},{"location":"mcp/debugger.html#scriptsinitsh","title":"<code>scripts/init.sh</code>","text":"<p>Initializes the development environment by: 1. Creating a Python virtual environment (if it doesn't exist) 2. Installing the <code>uv</code> package manager (if not already installed) 3. Installing all dependencies from requirements.txt</p> <pre><code># Make the initialization script executable (if not already)\nchmod +x scripts/init.sh\n\n# Run the initialization script\n./scripts/init.sh\n</code></pre>"},{"location":"mcp/debugger.html#scriptsstartsh","title":"<code>scripts/start.sh</code>","text":"<p>Starts the MCP server: 1. Checks if the virtual environment exists (prompts to run init.sh if not) 2. Activates the virtual environment 3. Launches the MCP server</p> <pre><code># Make the script executable (if not already)\nchmod +x scripts/start.sh\n\n# Start the MCP server\n./scripts/start.sh\n</code></pre>"},{"location":"mcp/debugger.html#scriptstestsh","title":"<code>scripts/test.sh</code>","text":"<p>Runs the test suite with coverage reporting: 1. Creates a .coveragerc file with specific settings 2. Runs pytest on the entire test suite 3. Generates coverage reports for server.py and tools/ 4. Ensures a minimum coverage threshold (currently 50%) 5. Displays which lines are missing coverage</p> <pre><code># Make the script executable (if not already)\nchmod +x scripts/test.sh\n\n# Run the tests\n./scripts/test.sh\n</code></pre>"},{"location":"mcp/debugger.html#scriptslintsh","title":"<code>scripts/lint.sh</code>","text":"<p>Formats the Python code using Black: 1. Checks if the virtual environment exists 2. Formats all Python code in tools/, tests/, and server.py</p> <pre><code># Make the script executable (if not already)\nchmod +x scripts/lint.sh\n\n# Format the code\n./scripts/lint.sh\n</code></pre> <p>You can also perform these steps manually:</p> <pre><code># Create and activate virtual environment\npython3 -m venv .venv\nsource .venv/bin/activate\n\n# Install uv if not already installed\ncurl -LsSf https://astral.sh/uv/install.sh | sh\nexport PATH=\"$HOME/.cargo/bin:$PATH\"\n\n# Install dependencies using uv\nuv pip install -r requirements.txt\n\n# Run the server\npython server.py\n</code></pre>"},{"location":"mcp/debugger.html#environment-variable-support","title":"Environment Variable Support","text":"<p>The debugger automatically loads environment variables from multiple sources:</p> <ol> <li>System environment variables - Variables set in your current shell session</li> <li>.env files - Loads from <code>.env</code>, <code>.env.local</code>, and <code>.env.development</code> files in the project directory</li> <li>Priority - System environment variables take precedence over .env file variables</li> </ol> <p>This follows the common developer practice of using <code>npx dotenv-cli</code> or similar tools to manage environment variables.</p>"},{"location":"mcp/debugger.html#available-tools","title":"Available Tools","text":""},{"location":"mcp/debugger.html#configuration-analysis-tools","title":"Configuration Analysis Tools","text":""},{"location":"mcp/debugger.html#check_comprehensive_config","title":"<code>check_comprehensive_config</code>","text":"<p>Performs a comprehensive configuration check for CDK CI/CD Wrapper projects, examining environment variables and configuration files to ensure all required parameters are properly set.</p> <pre><code>check_comprehensive_config(project_path=\"/path/to/cdk-project\")\n</code></pre>"},{"location":"mcp/debugger.html#check_stage_definitions","title":"<code>check_stage_definitions</code>","text":"<p>Verifies that stages are correctly defined through environment variables or code, ensuring account mappings are present and environment variables are set appropriately.</p> <pre><code>check_stage_definitions(project_path=\"/path/to/cdk-project\")\n</code></pre>"},{"location":"mcp/debugger.html#git-provider-tools","title":"Git Provider Tools","text":""},{"location":"mcp/debugger.html#check_git_provider","title":"<code>check_git_provider</code>","text":"<p>Checks Git provider configuration (GitHub or CodeCommit) and validates connectivity. For CodeCommit, performs a connectivity test using the RES account credentials to ensure repositories can be accessed.</p> <pre><code>check_git_provider(project_path=\"/path/to/cdk-project\")\n</code></pre>"},{"location":"mcp/debugger.html#cicd-configuration-tools","title":"CI/CD Configuration Tools","text":""},{"location":"mcp/debugger.html#check_ci_configuration","title":"<code>check_ci_configuration</code>","text":"<p>Determines which CI system is being used (CodePipeline or GitHub Actions) and validates its configuration. For CodePipeline, analyzes the version, Docker base image, and CodeBuild environment settings.</p> <pre><code>check_ci_configuration(project_path=\"/path/to/cdk-project\")\n</code></pre>"},{"location":"mcp/debugger.html#plugin-analysis-tools","title":"Plugin Analysis Tools","text":""},{"location":"mcp/debugger.html#check_plugins","title":"<code>check_plugins</code>","text":"<p>Identifies and analyzes any custom plugins used in the project, including potential security implications. Specifically highlights plugins that enable public access or other security-sensitive configurations.</p> <pre><code>check_plugins(project_path=\"/path/to/cdk-project\")\n</code></pre>"},{"location":"mcp/debugger.html#networking-configuration-tools","title":"Networking Configuration Tools","text":""},{"location":"mcp/debugger.html#check_vpc_configuration","title":"<code>check_vpc_configuration</code>","text":"<p>Validates VPC configuration in CDK CI/CD Wrapper projects and ensures all necessary proxy configurations are present when VPC proxy is enabled.</p> <pre><code>check_vpc_configuration(project_path=\"/path/to/cdk-project\")\n</code></pre>"},{"location":"mcp/debugger.html#configuring-mcp-clients-for-the-cdk-cicd-wrapper-debugger","title":"Configuring MCP Clients for the CDK CI/CD Wrapper Debugger","text":"<p>This MCP server can be used with any MCP-compatible client. Below are configuration instructions for popular clients:</p>"},{"location":"mcp/debugger.html#compatible-mcp-clients","title":"Compatible MCP Clients","text":"<ul> <li>Amazon Q CLI - Amazon's AI-powered command-line assistant (Installation Guide)</li> <li>Cline - The Collaborative AI Coder. Experience an AI development partner that amplifies your engineering capabilities</li> <li>Any other MCP-compatible client - The server follows the standard MCP protocol specification</li> </ul>"},{"location":"mcp/debugger.html#configuring-cline-ai-vs-code-extension","title":"Configuring Cline AI (VS Code Extension)","text":"<p>To use this MCP server with Cline AI in VS Code, you need to configure the MCP server in the Cline AI extension settings. Here's a step-by-step guide:</p>"},{"location":"mcp/debugger.html#1-locate-your-mcp-server-configuration-file","title":"1. Locate Your MCP Server Configuration File","text":"<p>The Cline AI MCP server configuration is typically located at <code>~/.config/cline/mcp-server-config.json</code>. If this file doesn't exist, you can create it with the appropriate directory structure.</p>"},{"location":"mcp/debugger.html#2-configure-the-mcp-server","title":"2. Configure the MCP Server","text":"<p>Add the CDK CI/CD Wrapper Debugger server configuration to your MCP server configuration file. There are several approaches depending on your environment:</p>"},{"location":"mcp/debugger.html#option-1-using-the-repository-path","title":"Option 1: Using the Repository Path","text":"<p>If you have the repository checked out:</p> <pre><code>{\n  \"mcpServers\": {\n    \"cdk-cicd-wrapper-debugger\": {\n      \"command\": \"$SHELL\",\n      \"args\": [\n        \"-c\",\n        \"cd $HOME/path/to/cdk-cicd-wrapper/mcp-servers/debugger &amp;&amp; source .venv/bin/activate &amp;&amp; python server.py\"\n      ],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre> <p>Replace <code>$HOME/path/to/cdk-cicd-wrapper</code> with the actual path to your project.</p>"},{"location":"mcp/debugger.html#option-2-using-uv-package-manager","title":"Option 2: Using UV Package Manager","text":"<p>If you have UV installed:</p> <pre><code>{\n  \"mcpServers\": {\n    \"cdk-cicd-wrapper-debugger\": {\n      \"command\": \"uv\",\n      \"args\": [\"--directory\", \"$CURRENT_DIR/mcp-servers/debugger\", \"run\", \"server.py\"],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/debugger.html#option-3-using-current-directory-with-relative-path","title":"Option 3: Using Current Directory with Relative Path","text":"<p>If the debugger is in your current working directory:</p> <pre><code>{\n  \"mcpServers\": {\n    \"cdk-cicd-wrapper-debugger\": {\n      \"command\": \"python\",\n      \"args\": [\"$CURRENT_DIR/mcp-servers/debugger/server.py\"],\n      \"disabled\": false\n    }\n  }\n}\n</code></pre>"},{"location":"mcp/debugger.html#3-using-the-debugger-with-cline-ai","title":"3. Using the Debugger with Cline AI","text":"<p>Once configured, you can use the debugger tools through Cline AI by opening your CDK CI/CD Wrapper project in VS Code and asking Cline AI to analyze your project. Here are some example prompts:</p> <ul> <li>\"Can you use the cdk-cicd-wrapper-debugger to check my project configuration?\"</li> <li>\"Analyze my CDK CI/CD Wrapper project using the debugger tools.\"</li> <li>\"Check for VPC configuration issues in my CDK CI/CD Wrapper project.\"</li> </ul> <p>Cline AI will connect to the MCP server and use the appropriate tools to analyze your project.</p>"},{"location":"mcp/debugger.html#configuring-amazon-q-cli","title":"Configuring Amazon Q CLI","text":"<p>Amazon Q CLI can also connect to this MCP server. Here's how to configure it:</p>"},{"location":"mcp/debugger.html#1-install-amazon-q-cli","title":"1. Install Amazon Q CLI","text":"<p>If you haven't already, install Amazon Q CLI following the official AWS documentation.</p>"},{"location":"mcp/debugger.html#2-configure-mcp-server-for-amazon-q","title":"2. Configure MCP Server for Amazon Q","text":"<p>Create or update your Amazon Q CLI MCP configuration. The exact configuration method may vary depending on your Amazon Q CLI version, but typically involves:</p> <pre><code># Example configuration for Amazon Q CLI\n# (Please refer to the latest Amazon Q CLI documentation for exact syntax)\nq configure mcp add \\\n  --name cdk-cicd-wrapper-debugger \\\n  --command \"python\" \\\n  --args \"$HOME/path/to/cdk-cicd-wrapper/mcp-servers/debugger/server.py\"\n</code></pre>"},{"location":"mcp/debugger.html#3-using-with-amazon-q-cli","title":"3. Using with Amazon Q CLI","text":"<p>Once configured, you can interact with the debugger through Amazon Q CLI:</p> <pre><code># Example usage (syntax may vary based on Amazon Q CLI version)\nq chat \"Use the cdk-cicd-wrapper-debugger to analyze my CDK project at ./my-project\"\n</code></pre>"},{"location":"mcp/debugger.html#4-troubleshooting-mcp-server-connection","title":"4. Troubleshooting MCP Server Connection","text":"<p>If your MCP client cannot connect to the server:</p> <ol> <li>Verify that the path in your MCP server configuration is correct</li> <li>Ensure the virtual environment is activated and all dependencies are installed</li> <li>Check that the server script has execute permissions</li> <li>Examine client console logs for any error messages</li> <li>Test the server manually by running <code>python server.py</code> in the debugger directory</li> </ol>"},{"location":"mcp/debugger.html#usage-examples","title":"Usage Examples","text":""},{"location":"mcp/debugger.html#example-1-using-with-cline-ai","title":"Example 1: Using with Cline AI","text":"<p>When using this MCP server with Cline AI, you can request analysis like this:</p> <pre><code>\"Can you analyze my CDK CI/CD Wrapper project configuration using the debugger tools? \nThe project is located at ./my-cdk-project\"\n</code></pre> <p>Cline will then use the MCP tools to: 1. Check comprehensive configuration settings 2. Verify stage definitions 3. Validate Git provider configuration 4. Check CI/CD configuration 5. Analyze any custom plugins 6. Validate VPC and networking settings</p>"},{"location":"mcp/debugger.html#example-2-troubleshooting-configuration-issues","title":"Example 2: Troubleshooting Configuration Issues","text":"<p>Ask Cline to diagnose specific configuration problems:</p> <pre><code>\"My CDK CI/CD Wrapper project is having issues with VPC configuration. \nCan you diagnose what might be wrong?\"\n</code></pre> <p>Cline will use the <code>check_vpc_configuration</code> tool to analyze the VPC setup and provide recommendations.</p>"},{"location":"mcp/debugger.html#example-3-complete-project-validation","title":"Example 3: Complete Project Validation","text":"<p>Request a comprehensive analysis:</p> <pre><code>\"Please perform a complete validation of my CDK CI/CD Wrapper project, \nincluding configuration, stages, Git provider, CI/CD setup, plugins, and VPC configuration.\"\n</code></pre>"},{"location":"mcp/debugger.html#test-coverage","title":"Test Coverage","text":"<p>The debugger includes comprehensive test coverage for all components:</p>"},{"location":"mcp/debugger.html#testing-framework","title":"Testing Framework","text":"<ul> <li>Uses pytest for running tests</li> <li>Implements coverage reporting with pytest-cov</li> <li>Currently enforces a minimum coverage threshold of 50%</li> <li>Configuration defined in .coveragerc</li> </ul>"},{"location":"mcp/debugger.html#test-suite-organization","title":"Test Suite Organization","text":"<p>The test suite covers:</p> <ol> <li>Server Components</li> <li>Server initialization and registration (<code>test_server.py</code>, <code>test_server_registration.py</code>)</li> <li>Server helper functions (<code>test_server_helpers.py</code>)</li> <li> <p>MCP integration (<code>test_mcp_integration.py</code>)</p> </li> <li> <p>Debugging Tools</p> </li> <li>CI Checker (<code>test_ci_checker_comprehensive.py</code>, <code>test_ci_configuration.py</code>)</li> <li>Configuration Checker (<code>test_comprehensive_config.py</code>)</li> <li>Git Provider (<code>test_git_provider.py</code>)</li> <li>Plugin Analysis (<code>test_plugins.py</code>)</li> <li>Stage Definitions (<code>test_stage_definitions.py</code>)</li> <li>VPC Configuration (<code>test_vpc_configuration.py</code>, <code>test_vpc_language_support.py</code>)</li> <li>Tool Mocking (<code>test_tools_mock.py</code>)</li> </ol>"},{"location":"mcp/debugger.html#running-the-tests","title":"Running the Tests","text":"<pre><code># Run the full test suite with coverage reporting\n./scripts/test.sh\n</code></pre>"},{"location":"mcp/debugger.html#common-debugging-workflows","title":"Common Debugging Workflows","text":""},{"location":"mcp/debugger.html#workflow-1-complete-project-validation","title":"Workflow 1: Complete Project Validation","text":"<ol> <li>Check comprehensive configuration: <code>check_comprehensive_config(project_path=\"./project\")</code></li> <li>Verify stage definitions: <code>check_stage_definitions(project_path=\"./project\")</code></li> <li>Validate Git provider setup: <code>check_git_provider(project_path=\"./project\")</code></li> <li>Check CI/CD configuration: <code>check_ci_configuration(project_path=\"./project\")</code></li> <li>Analyze custom plugins: <code>check_plugins(project_path=\"./project\")</code></li> <li>Validate VPC configuration: <code>check_vpc_configuration(project_path=\"./project\")</code></li> </ol>"},{"location":"mcp/debugger.html#workflow-2-troubleshooting-configuration-issues","title":"Workflow 2: Troubleshooting Configuration Issues","text":"<ol> <li>Check comprehensive configuration: <code>check_comprehensive_config(project_path=\"./project\")</code></li> <li>Identify specific problem areas from the comprehensive check</li> <li>Run specialized tools for problem areas (e.g., <code>check_vpc_configuration</code> for VPC issues)</li> <li>Follow recommendations provided by the tools</li> </ol>"},{"location":"mcp/debugger.html#contributing","title":"Contributing","text":"<p>Contributions to enhance the debugging capabilities of this MCP server are welcome. Please ensure that any new tools follow the existing pattern and include proper error handling and documentation.</p>"},{"location":"mcp/debugger.html#license","title":"License","text":"<p>Apache 2.0</p>"},{"location":"overview/index.html","title":"CDK CI/CD Wrapper","text":""},{"location":"overview/index.html#introduction","title":"Introduction","text":"<p>The CDK CI/CD Wrapper is a comprehensive CI/CD platform for AWS CDK-based applications and solutions. It provides a standardized and easy-to-use Continuous Integration solution leveraging AWS CodeBuild. The process ensures that the codebase follows code style guidelines, can be successfully compiled, runs supplied tests, and performs various quality checks related to security.</p> <p>Once the codebase successfully passes the quality gates, the CDK CI/CD Wrapper enables Continuous Deployment of the solution across multiple stages, such as DEV, INT, and PROD. For each stage, you can configure pre and post deployment steps to hook in various activities like integration and end-to-end testing. Additionally, you can have post-deployment steps to finalize the deployment activities.</p>"},{"location":"overview/index.html#why-use-the-cdk-cicd-wrapper","title":"Why use the CDK CI/CD Wrapper?","text":"<p>Setting up CI/CD pipelines for AWS CDK-based projects is a recurring and time-consuming activity for many teams. This process often results in different \"flavors\" of pipelines, leading to duplicated effort and increased maintenance and governance complexity.</p> <p>The CI/CD process setup is often thought of as a one-time activity, but in reality, it is a continuous process that needs to be done systematically.</p> <p>The CDK CI/CD Wrapper can address these issues and drastically reduce the effort needed to maintain and develop AWS CDK-based solutions, allowing you to focus on your solution while it takes care of the CI/CD process.</p> <p>Here are some key features provided by the CDK CI/CD Wrapper:</p> <ul> <li> Customizable CI steps to meet project requirements</li> <li> Integration of various security scanning tools</li> <li> Multi-staged Continuous Deployment process</li> <li> Flexible definition of stages, with the ability to extend the default (DEV/INT/PROD) stages with custom stages like EXP</li> <li> Separate stack deployment specification for each stage</li> <li> Pre/Post deploy hooks during the deployment in each stage (DEV/INT/PROD)</li> <li> PRE -&gt; Unit Tests</li> <li> POST -&gt; Functional Tests, Load Testing</li> <li> Automated Open Source License checking (with a provided list of licenses that should not be present in your PRODUCTION workloads)</li> <li> Centralized storage of compliance logs in S3 buckets pre-configured on a per-stage/environment basis</li> <li> Build Lambda Layers for Python and scan dependencies in the CI/CD (in case of CVE findings, block the pipeline)</li> </ul> <p>These features can be used independently in any project as part of the CDK CI/CD Wrapper CLI, even if your project is not based on AWS CDK.</p>"},{"location":"overview/index.html#cicd-process-overview","title":"CI/CD Process Overview","text":"<p>The CI/CD process in the CDK CI/CD Wrapper establishes the following:</p> <ol> <li>Changes are committed to the Git repository in a branch, and a Pull Request (PR) is created for the <code>main</code> branch.</li> <li>The PR is reviewed, approved, and merged into the <code>main</code> branch.</li> <li>For AWS CodeCommit repositories, the CDK CI/CD Wrapper provides out-of-the-box automatic PR checks.</li> <li>Once the codebase is merged into <code>main</code>, an AWS CodePipeline is triggered to execute the CI/CD process:</li> <li>Build: This is the Continuous Integration step, which executes the build, test, lint, and audit actions to ensure code quality and security before deployment to any stages.</li> <li>Synthesize: This step executes <code>cdk synth</code> and runs the CDK Nag to promote infrastructure best practices.</li> <li>Update RES: This step updates the infrastructure elements in the RES account with the AWS CloudFormation Service.</li> <li>Update DEV: This step updates the infrastructure elements in the DEV account with the AWS CloudFormation Service.</li> <li>Update INT: This step updates the infrastructure elements in the INT account with the AWS CloudFormation Service.</li> <li>Update PROD: This step updates the infrastructure elements in the PROD account with the AWS CloudFormation Service.</li> </ol>"},{"location":"overview/index.html#infrastructure-elements","title":"Infrastructure Elements","text":"<p>The CDK CI/CD Wrapper architecture is based on using DevOps services provided by AWS to deliver the CI/CD solution.</p> <p></p> <p>You can read more about these elements in the Developer Guide.</p>"},{"location":"overview/index.html#getting-started","title":"Getting Started","text":"<p>If you are eager to start using the CDK CI/CD Wrapper, check out the Getting Started guides.</p>"},{"location":"overview/index.html#contributing-to-the-cdk-cicd-wrapper","title":"Contributing to the CDK CI/CD Wrapper","text":"<p>The team encourages you to contribute to make it an even better framework. For details, see contributing.</p>"},{"location":"workshops/index.html","title":"CDK CI/CD Wrapper Workshops","text":"<p>This repository contains a collection of workshops that demonstrate how to use the CDK CI/CD Wrapper to deploy a CI/CD pipeline for any projects on AWS.</p>"},{"location":"workshops/basics-lvl300/index.html","title":"Introduction &amp; Overview","text":"<p>Welcome, and thank you for joining us!</p> <p>We are excited to have you here to learn more about the CDK CI/CD Wrapper, a powerful tool designed to streamline your CI/CD processes using AWS CDK.</p>"},{"location":"workshops/basics-lvl300/index.html#target-audience","title":"Target Audience","text":"<p>This workshop is tailored for builders such as:</p> <ul> <li>Software Developers</li> <li>DevOps Engineers</li> <li>Cloud Engineers</li> </ul> <p>You should have prior experience with AWS CDK and be familiar with developing or maintaining cloud applications using CDK.</p> <ul> <li>Expected Completion Time: 1.5 hours</li> </ul>"},{"location":"workshops/basics-lvl300/index.html#background-knowledge","title":"Background Knowledge","text":"<p>To successfully complete this workshop, it\u2019s recommended that you have knowledge of the following:</p> <ul> <li>TypeScript/JavaScript</li> <li>Basic Python</li> <li>Linux and Bash scripting</li> <li>Infrastructure-as-Code (IaC) with AWS CDK</li> </ul>"},{"location":"workshops/basics-lvl300/index.html#what-you-will-learn","title":"What You Will Learn","text":"<p>In this workshop, we will guide you through the following steps:</p> <ol> <li> <p>Creating a CDK Project &amp; Bootstrapping the AWS Account    Learn how to initiate and configure your AWS environment for CDK development.</p> </li> <li> <p>Defining Quality Gates and Continuous Integration    Establish quality controls and build automation processes to ensure code quality and efficiency.</p> </li> <li> <p>Creating a Pipeline and Enabling GitOps    Set up a CI/CD pipeline and integrate GitOps to streamline deployment workflows.</p> </li> <li> <p>Developing with Workbench    Utilize the Workbench environment to accelerate development and testing workflows.</p> </li> <li> <p>Building a GenAI Solution    Deliver a Generative AI solution from start to end, incorporating it into your CI/CD pipeline for seamless deployment.</p> </li> <li> <p>Putting Everything Together    Combine all components to build a production-ready CI/CD pipeline that\u2019s scalable and efficient.</p> </li> </ol>"},{"location":"workshops/basics-lvl300/index.html#architecture-overview","title":"Architecture Overview","text":"<p>Before we dive in, here\u2019s an architecture diagram of the CDK CI/CD Wrapper to ensure you\u2019re familiar with the outcome.</p> <p></p> <p>The diagram illustrates how AWS services like CodeCommit, CodePipeline, and CloudFormation work together to automate the CI/CD process across different accounts, integrating security, compliance, and automation tools such as Amazon KMS, CodeGuru, and S3.</p> <p>Disclaimer: In this workshop, we are using AWS CodeCommit for simplicity and to demonstrate the core concepts of the CDK CI/CD Wrapper. However, the CDK CI/CD Wrapper is highly flexible and can be integrated with any third-party repository management system that supports AWS CodeConnections, such as GitHub, GitLab, or Bitbucket.</p>"},{"location":"workshops/basics-lvl300/index.html#demo-application-image-generation-using-amazon-bedrock","title":"Demo application: Image Generation using Amazon Bedrock","text":"<p>In this workshop, you will be deploying a demo application powered by AWS Fargate and AWS Bedrock using the CDK CI/CD Wrapper. Below is a high-level architectural overview of the demo application:</p> <p></p> <p>Key Components:</p> <ul> <li> <p>Application Load Balancer: This component manages incoming traffic and distributes it to the underlying Fargate tasks. It ensures that your application is highly available and scalable by routing requests efficiently.</p> </li> <li> <p>AWS Fargate (Streamlit Application): The main application is hosted as a Streamlit web app on AWS Fargate, a serverless compute engine that runs containers. Fargate abstracts the server management, allowing us to focus on the application logic.</p> </li> <li> <p>Amazon Bedrock: The backend logic interacts with Amazon Bedrock to power the generative AI capabilities. The Streamlit app communicates with Amazon Bedrock to generate images based on user-provided prompts.</p> </li> </ul> <p>Click on start to begin the workshop.</p> <p>Start</p>"},{"location":"workshops/basics-lvl300/00-prerequisites.html","title":"Prerequisites","text":""},{"location":"workshops/basics-lvl300/00-prerequisites.html#aws-account-setup","title":"AWS Account Setup","text":"<p>Before starting the workshop, ensure you have the following:</p> <ul> <li>AWS Account with administrative access</li> <li>Default VPC in your account</li> <li>AWS Region: You can use any of the following regions:<ul> <li><code>us-east-1</code></li> <li><code>us-east-2</code></li> <li><code>us-west-2</code></li> <li><code>eu-central-1</code></li> <li><code>eu-west-1</code></li> <li><code>eu-west-2</code></li> </ul> </li> </ul>"},{"location":"workshops/basics-lvl300/00-prerequisites.html#amazon-bedrock-setup","title":"Amazon Bedrock Setup","text":"<p>We will be using Amazon Bedrock to access foundation models in this workshop. Below, we configure model access in Amazon Bedrock for building and running generative AI applications. Bedrock provides models from multiple providers.</p>"},{"location":"workshops/basics-lvl300/00-prerequisites.html#amazon-bedrock-setup-instructions","title":"Amazon Bedrock Setup Instructions","text":"<ol> <li> <p>Search for Amazon Bedrock in the AWS console. </p> </li> <li> <p>Expand the side menu and select Model access. </p> </li> <li> <p>Click Enable specific models. </p> </li> <li> <p>Select the following models:</p> </li> <li>Amazon (All Titan models)</li> <li>Click Next, review, and then submit. </li> <li>Monitor model access status and ensure Access granted. </li> </ol> \u2713 Congratulations! you've successfully set up Amazon Bedrock!"},{"location":"workshops/basics-lvl300/00-prerequisites.html#workspace-setup","title":"Workspace Setup","text":"<p>You will need a workspace to run the workshop. You can use the Amazon SageMaker Studio CodeEditor for this workshop or you can use your local machine.</p>"},{"location":"workshops/basics-lvl300/00-prerequisites.html#configure-amazon-sagemaker-studio-codeeditor","title":"Configure Amazon SageMaker Studio CodeEditor","text":"<ol> <li>Download the CloudFormation template to your local machine: cdk-cicd-workshop.yml</li> </ol>"},{"location":"workshops/basics-lvl300/00-prerequisites.html#cloudformation-stack-setup","title":"CloudFormation Stack Setup","text":"<p>Within your AWS account:</p> <ol> <li>Navigate to AWS CloudFormation (via AWS Console) to create a new stack. </li> <li>On the \"Create stack\" screen, under the Specify a template section, select the Upload a template file option and navigate to select the <code>cdk-cicd-workshop.yml</code> file you downloaded earlier. Click Next. </li> <li>On the \"Specify stack details\" screen, under the Stack name section, provide a name for the CloudFormation stack (e.g., <code>cdk-cicd-workshop</code>).</li> <li>Leave the rest of the parameters unchanged, and click Next. </li> <li>On the \"Configure stack options\" screen, leave the default parameters unchanged, scroll to the bottom of the page, and click Next.</li> <li>On the \"Review\" screen, scroll to the bottom of the page and check the box: \"I acknowledge that AWS CloudFormation might create IAM resources.\". Click Create Stack.    </li> </ol> <p>CloudFormation will take a few minutes to run and set up your environment. Please wait for this step to complete.</p> \u2713 Congratulations! You have successfully deployed the AWS environment for this workshop. Next, we will verify the environment."},{"location":"workshops/basics-lvl300/00-prerequisites.html#open-amazon-sagemaker-studio-codeeditor","title":"Open Amazon SageMaker Studio CodeEditor","text":"<ol> <li>In the AWS console, type \"SageMaker\" in the search bar and navigate to the Amazon SageMaker service page.</li> <li>Click on the Studio link in the left navigation pane under the Control Panel. </li> <li> <p>You should see a pre-configured user. Click Open Studio.     This will open the SageMaker Studio UI in a new browser window.</p> </li> <li> <p>Click on the Code Editor icon under Applications and run the <code>my-space</code> application. </p> </li> <li>Click Open to launch the Code Editor in a new browser tab. </li> <li>In the Project folder, open the <code>cdk-cicd-example</code> project, which is already initialized for you. </li> </ol> \u2713 Congratulations! You have a ready to go CodeEditor.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/00-prerequisites.html#configure-local-machine","title":"Configure Local Machine","text":"<p>Install the following tools on your local machine:</p> <ul> <li>AWS CLI</li> <li>AWS CDK</li> <li>Docker</li> <li>Git</li> <li>Node.js</li> <li>Python</li> </ul> <p>Configure the following environment variables:</p> <pre><code>export AWS_REGION=&lt;region&gt;\nexport AWS_ACCOUNT_ID=&lt;account-id&gt;\nexport AWS_PROFILE=&lt;profile&gt; # Optional in case you have multiple profiles\n</code></pre> Congratulations! You have a ready to go workspace.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/01-create-cdk-project.html","title":"Create a CDK Project &amp; Bootstrap the AWS Account","text":"<p>In this section, we will create a CDK project and bootstrap your AWS account to prepare it for deploying resources using AWS CDK.</p>"},{"location":"workshops/basics-lvl300/01-create-cdk-project.html#step-1-create-a-cdk-typescript-project","title":"Step 1: Create a CDK TypeScript Project","text":"<p>We will start by initializing a new CDK project in TypeScript.</p> <pre><code>npx -y aws-cdk init --language typescript\n</code></pre>"},{"location":"workshops/basics-lvl300/01-create-cdk-project.html#step-2-add-the-cdk-cicd-wrapper","title":"Step 2: Add the CDK CI/CD Wrapper","text":"<p>To add the necessary wrapper for your project, run the following command:</p> <pre><code>npm install --include=dev --save @cdklabs/cdk-cicd-wrapper @cdklabs/cdk-cicd-wrapper-cli\n</code></pre>"},{"location":"workshops/basics-lvl300/01-create-cdk-project.html#step-3-bootstrap-the-resourcing-res-account","title":"Step 3: Bootstrap the Resourcing (RES) Account","text":"<p>You need to bootstrap your AWS account so it can manage CDK resources. You can refer to the official AWS CDK Bootstrapping Documentation for more details.</p>"},{"location":"workshops/basics-lvl300/01-create-cdk-project.html#optional-modify-cdkjson-configuration","title":"Optional: Modify <code>cdk.json</code> Configuration","text":"<p>Add the following CDK configurations to your <code>cdk.json</code> file for additional control over the bootstrapping process:</p> <ul> <li>toolkitStackName</li> <li>@aws-cdk/core:bootstrapQualifier</li> </ul> <p></p> <p>Bootstrap the Account</p> <pre><code>npm run cdk bootstrap\n</code></pre> <p>If you've configured <code>@aws-cdk-core:bootstrapQualifier</code>, use the following command with the qualifier:</p> <pre><code>npm run cdk bootstrap -- --qualifier cdkcicd\n</code></pre>"},{"location":"workshops/basics-lvl300/01-create-cdk-project.html#step-4-verify-the-bootstrap","title":"Step 4: Verify the Bootstrap","text":"<p>After running the bootstrap command, verify that the <code>CDKToolkit</code> or if you've configured <code>toolkitStackName</code> stack is present in the AWS CloudFormation Service.</p>"},{"location":"workshops/basics-lvl300/01-create-cdk-project.html#real-life-setup-for-multiple-aws-accounts","title":"Real-Life Setup for Multiple AWS Accounts","text":"<p>For this workshop, we are using a single AWS account. However, in real-world scenarios, each stage (e.g., DEV, INT, PROD) would have its own dedicated AWS account. You\u2019ll need to bootstrap each of these accounts with the same CDK qualifier and establish trust with the resourcing account.</p> <p>Here\u2019s an example command to bootstrap a different account with a trust relationship:</p> <pre><code>npm run cdk bootstrap -- \\\n  --qualifier cdkcicd  \\\n  --profile &lt;my_aws_profile_for_other_account&gt; \\\n  --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\\n  --trust &lt;resource_account_number&gt; aws://&lt;stage_account_number&gt;/&lt;region&gt;\n</code></pre> \u2713 Congratulations! You have a created a CDK project and bootstrapped your AWS account for CDK development.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html","title":"Define the Quality Gates and Continuous Integration","text":"<p>In this section, we will guide you through setting up quality gates and continuous integration (CI) in your workflow. You\u2019ll learn how to configure checkpoints to ensure your code meets standards and how to automate integration and testing using CI tools.</p> <p>The setup of quality gates and CI may vary depending on the technologies and tools used in the project, but at a high level, they follow these key steps: code style checking or static code analysis (linting), vulnerability scanning for dependencies and the codebase, project building, and executing various tests.</p> <p>We will mainly edit the <code>package.json</code> file in this section. Open that file and follow the steps below.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#build-test-steps","title":"Build &amp; Test Steps","text":"<p>The build and test steps are already included in this workshop\u2019s setup. Let\u2019s test them.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-1-run-the-build-command-to-transpile-the-typescript-code-to-javascript","title":"Step 1: Run the build command to transpile the TypeScript code to JavaScript.","text":"<pre><code>npm run build\n</code></pre> <p>Congratulations! You\u2019ve successfully compiled the project. Your code is now transpiled from TypeScript to JavaScript.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-2-run-the-test-command-to-execute-the-unit-tests","title":"Step 2: Run the test command to execute the Unit tests.","text":"<pre><code>npm run test\n</code></pre> <p>Well done! You\u2019ve completed running the unit tests. These checks ensure that your code behaves as expected.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#unifying-code-style-and-static-code-checks","title":"Unifying Code Style and Static Code Checks","text":""},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-3-install-eslint","title":"Step 3: Install ESLint","text":"<p>For NPM projects, it\u2019s common to use eslint for code styling and static code analysis. To install eslint, run the following command:</p> <pre><code>npm install --save-dev eslint @eslint/core @eslint/js @types/eslint__js typescript typescript-eslint @stylistic/eslint-plugin\n</code></pre>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-4-create-the-eslint-configuration-file","title":"Step 4: Create the ESLint Configuration File","text":"<p>Create a file called <code>eslint.config.mjs</code> in the project root with the following content:</p> <pre><code>import eslint from '@eslint/js';\nimport tseslint from 'typescript-eslint';\nimport stylistic from '@stylistic/eslint-plugin';\n\nexport default tseslint.config(\n  eslint.configs.recommended,\n  ...tseslint.configs.strict,\n  ...tseslint.configs.stylistic,\n  stylistic.configs.customize({\n    indent: 2,\n    quotes: 'single',\n    semi: true,\n  }),\n  {\n    ignores: [\n      'node_modules/**/*',\n      'cdk.out/**/*',\n      '**/*.js',\n      '**/*.d.ts',\n    ],\n  },\n  {\n    rules: {\n      '@stylistic/eol-last': ['off'], // workshop code removes the tailing spaces, that is why this rule disabled\n      '@typescript-eslint/no-useless-constructor': ['warn'], // AWS CDK example code has useless constructor\n    },\n  },\n);\n</code></pre> <p>Great job! You\u2019ve set up your ESLint configuration, which will help maintain code quality and uniformity across the project.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-5-add-the-lint-script-to-packagejson","title":"Step 5: Add the lint script to <code>package.json</code>","text":"<p>Open the <code>package.json</code> file and insert a new script called <code>lint</code> like this: <code>\"lint\": \"eslint .\"</code></p> <p>Your <code>package.json</code> should look like:</p> <pre><code>{\n  \"name\": \"cdk-cicd-example\",\n  \"version\": \"0.1.0\",\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"test\": \"jest\",\n    \"lint\": \"eslint .\",\n    \"cdk\": \"cdk\"\n  }\n}\n</code></pre>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-6-run-the-lint-script-to-test-it","title":"Step 6: Run the lint script to test it.","text":"<pre><code>npm run lint\n</code></pre> <p>Congratulations! You\u2019ve successfully run the linter. Your code is now checked for style and potential errors.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#security-scan-of-third-party-dependencies-and-codebase","title":"Security Scan of Third-Party Dependencies and Codebase","text":""},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-7-add-a-third-party-dependency-audit-step","title":"Step 7: Add a Third-Party dependency audit step","text":"<p>Edit the <code>package.json</code> and include the audit step for dependencies:</p> <pre><code>\"audit:deps\": \"cdk-cicd check-dependencies --npm --python\"\n</code></pre> <p>This command will analyze both NPM and Python dependencies and report any known vulnerabilities.</p> <p>Awesome! You\u2019ve added an important step to scan your third-party dependencies for vulnerabilities.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-8-add-a-security-scan-step-for-the-codebase","title":"Step 8: Add a security scan step for the codebase","text":"<p>Include the security scan for the source code in <code>package.json</code>:</p> <pre><code>\"audit:security-scan\": \"cdk-cicd security-scan --bandit --semgrep --shellcheck\"\n</code></pre> <p>This will run scanners (Bandit, Semgrep, Shellcheck) on the codebase to detect security risks.</p> <p>Well done! You\u2019ve set up the security scan to keep your code safe from common vulnerabilities.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#ensure-packagejson-integrity","title":"Ensure <code>package.json</code> Integrity","text":""},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-9-validate-packagejson","title":"Step 9: Validate <code>package.json</code>","text":"<p>Edit the <code>package.json</code> and include the following validation script:</p> <pre><code>\"validate\": \"cdk-cicd validate\"\n</code></pre> <p>To run the validation:</p> <pre><code>npm run validate\n</code></pre> <p>This may fail on the first execution since validation hasn\u2019t been executed before. To fix it, run:</p> <pre><code>npm run validate -- --fix\n</code></pre> Repeat this process anytime you modify the `package.json` file. <p>Fantastic! You\u2019ve ensured that your configuration is now validated, keeping your project secure and consistent.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#verifying-third-party-licenses","title":"Verifying Third-Party Licenses","text":""},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-10-audit-licenses","title":"Step 10: Audit licenses","text":"<p>Edit <code>package.json</code> to include a license audit step:</p> <pre><code>\"audit:license\": \"cdk-cicd license\"\n</code></pre> <p>To run the license audit:</p> <pre><code>npm run audit:license\n</code></pre> <p>It may fail the first time because it verifies the existence of the <code>NOTICE</code> file in your repository. Fix it by running:</p> <pre><code>npm run audit:license -- --fix\n</code></pre> <p>This will generate the <code>NOTICE</code> file and the <code>OSS_License_Summary.csv</code> summarizing the used license types in your project.</p> Repeat this process anytime you modify the package.json, requirement.txt, and / or Pipfile. <p>Congrats! You\u2019ve completed the license audit, ensuring all third-party dependencies are legally valid and accounted for.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#concurrent-execution-of-audits","title":"Concurrent Execution of Audits","text":"<p>Running multiple security checks can take time, so it's beneficial to parallelize them.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#step-10-edit-the-packagejson-to-include","title":"Step 10: Edit the <code>package.json</code> to include:","text":"<pre><code>\"audit\": \"concurrently 'npm:audit:*'\"\n</code></pre> <p>Install the dependency:</p> <pre><code>npm install --save-dev concurrently\n</code></pre> <p>Run the audit command:</p> <pre><code>npm run audit\n</code></pre> <p>If the audit fails due to <code>package.json</code> modifications, run:</p> <pre><code>npm run audit:license -- --fix\nnpm run validate -- --fix\n</code></pre> <p>Then, re-run:</p> <pre><code>npm run audit\n</code></pre> <p>Amazing! You\u2019ve successfully parallelized your audit tasks, saving time while ensuring your code remains safe and compliant.</p>"},{"location":"workshops/basics-lvl300/02-define-quality-gates-ci.html#summary","title":"Summary","text":"<p>By the end of this section, we have defined all the necessary steps for a high-quality, robust CI pipeline for an AWS CDK-based project. These include:</p> <ul> <li>validate: Ensures our configuration isn\u2019t tampered with.</li> <li>build: Ensures our code compiles correctly.</li> <li>test: Ensures tests are executed.</li> <li>lint: Ensures code style and quality.</li> <li>audit: Ensures dependencies are vulnerability-free and legally valid, and the codebase doesn't introduce security risks.</li> </ul> Show Solution <p>The <code>package.json</code> file should look like this: <pre><code>{\n  \"name\": \"cdk-cicd-example\",\n  \"version\": \"0.1.0\",\n  \"bin\": {\n    \"cdk-cicd-example\": \"bin/cdk-cicd-example.js\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"watch\": \"tsc -w\",\n    \"test\": \"jest\",\n    \"lint\": \"eslint .\",\n    \"audit\": \"concurrently 'npm:audit:*'\",\n    \"audit:deps\": \"cdk-cicd check-dependencies --npm --python\",\n    \"audit:security-scan\": \"cdk-cicd security-scan --bandit --semgrep --shellcheck\",\n    \"audit:license\": \"cdk-cicd license\",\n    \"validate\": \"cdk-cicd validate\",\n    \"cdk\": \"cdk\"\n  },\n  \"devDependencies\": {\n    \"@eslint/js\": \"^9.10.0\",\n    \"@stylistic/eslint-plugin\": \"^2.8.0\",\n    \"@types/eslint__js\": \"^8.42.3\",\n    \"@types/jest\": \"^29.5.12\",\n    \"@types/node\": \"22.5.4\",\n    \"aws-cdk\": \"2.158.0\",\n    \"concurrently\": \"^9.0.1\",\n    \"eslint\": \"^9.10.0\",\n    \"jest\": \"^29.7.0\",\n    \"ts-jest\": \"^29.2.5\",\n    \"ts-node\": \"^10.9.2\",\n    \"typescript\": \"~5.6.2\",\n    \"typescript-eslint\": \"^8.6.0\"\n  },\n  \"dependencies\": {\n    \"@cdklabs/cdk-cicd-wrapper\": \"^0.2.12\",\n    \"@cdklabs/cdk-cicd-wrapper-cli\": \"^0.2.10\",\n    \"aws-cdk-lib\": \"2.158.0\",\n    \"constructs\": \"^10.0.0\",\n    \"source-map-support\": \"^0.5.21\"\n  }\n}\n</code></pre></p> \u2713 Congratulations! You\u2019ve completed setting up all your quality gates and continuous integration steps. You now have a strong foundation for building, testing, and securing your AWS CDK project!  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html","title":"Creating a Pipeline and Enabling GitOps","text":"<p>In this section, we are going to create the AWS CodePipeline and the required resources with the help of the CDK CI/CD Wrapper.</p>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#clean-up-the-example-stack","title":"Clean up the Example Stack","text":""},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-1-open-the-example-file","title":"Step 1: Open the Example File","text":"<p>First, open your <code>bin/cdk-cicd-example.ts</code> file. It should look like this:</p> <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport { CdkCicdExampleStack } from '../lib/cdk-cicd-example-stack';\n\nconst app = new cdk.App();\nnew CdkCicdExampleStack(app, 'CdkCicdExampleStack', {\n  /* If you don't specify 'env', this stack will be environment-agnostic.\n   * Account/Region-dependent features and context lookups will not work,\n   * but a single synthesized template can be deployed anywhere. */\n\n  /* Uncomment the next line to specialize this stack for the AWS Account\n   * and Region that are implied by the current CLI configuration. */\n  // env: { account: process.env.CDK_DEFAULT_ACCOUNT, region: process.env.CDK_DEFAULT_REGION },\n\n  /* Uncomment the next line if you know exactly what Account and Region you\n   * want to deploy the stack to. */\n  // env: { account: '123456789012', region: 'us-east-1' },\n\n  /* For more information, see https://docs.aws.amazon.com/cdk/latest/guide/environments.html */\n});\n</code></pre>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-2-remove-the-example-stack","title":"Step 2: Remove the Example Stack","text":"<p>Let\u2019s remove the example stack by deleting the following blocks:</p> <pre><code>import { CdkCicdExampleStack } from '../lib/cdk-cicd-example-stack';\n</code></pre> <p>and</p> <pre><code>new CdkCicdExampleStack(app, 'CdkCicdExampleStack', {\n  /* Account/Region environment configuration */\n});\n</code></pre>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-3-remove-the-unnecessary-file","title":"Step 3: Remove the unnecessary File","text":"<p>Delete the <code>lib/cdk-cicd-example-stack.ts</code> file, as it\u2019s no longer needed.</p>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-4-verify-the-clean-up","title":"Step 4: Verify the Clean Up","text":"<p>Your <code>bin/cdk-cicd-example.ts</code> file should now look like this:</p> <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\n\nconst app = new cdk.App();\n</code></pre>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#create-the-pipeline","title":"Create the Pipeline","text":""},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-5-import-the-cdk-cicd-wrapper","title":"Step 5: Import the CDK CI/CD Wrapper","text":"<p>Now, let\u2019s import the CDK CI/CD Wrapper. Add the following import statement after the <code>aws-cdk-lib</code> import:</p> <pre><code>import * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n</code></pre> <p>The updated <code>bin/cdk-cicd-example.ts</code> file should now look like:</p> <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\n</code></pre>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-6-define-the-pipeline-with-builder","title":"Step 6: Define the Pipeline with Builder","text":"<p>Next, we will create the pipeline using the CDK CI/CD Wrapper. Define the pipeline stages with the following code:</p> <pre><code>wrapper.PipelineBlueprint.builder()\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: process.env.AWS_ACCOUNT_ID },\n  ])\n  .synth(app);\n</code></pre> You can also configure the <code>ACCOUNT_RES</code> environment variable with the AWS account ID instead of defining it through the <code>defineStages</code> method. The variables <code>ACCOUNT_DEV</code> and <code>ACCOUNT_INT</code> are supported as well. <p>Congratulations! Your code is ready to deploy the pipeline.</p> Show Solution <p>The <code>bin/cdk-cicd-example.ts</code> file should look like this: <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\n\nwrapper.PipelineBlueprint.builder()\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: process.env.AWS_ACCOUNT_ID },\n  ])\n  .synth(app);\n</code></pre></p>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#deploy-the-pipeline","title":"Deploy the Pipeline","text":""},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-7-verify-the-code-can-be-synthesized","title":"Step 7: Verify the Code Can Be Synthesized","text":"<p>Run the following command to synthesize the pipeline:</p> <pre><code>npm run cdk synth\n</code></pre>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-8-deploy-the-pipeline","title":"Step 8: Deploy the Pipeline","text":"<p>Deploy the pipeline using this command:</p> <pre><code>npm run cdk deploy -- --all\n</code></pre> <p>During the deployment process, you will be asked to review the AWS IAM policies that will be deployed. After reviewing them, type 'y'.</p> \u2713 Congratulations! The pipeline has been successfully deployed."},{"location":"workshops/basics-lvl300/03-create-pipeline.html#optional-review-the-infrastructure","title":"(Optional) Review the Infrastructure","text":"<p>Let\u2019s review the infrastructure that was deployed. Go to the AWS CloudFormation service and check the following stacks:</p> Stack Description Resources <code>cdk-cicd-example</code> The core stack containing the AWS CodePipeline and all related resources like AWS CodeBuilds and IAM Roles. Various resources <code>cdk-cicd-exampleRepository</code> AWS CodeCommit repository stack with pull request verification and AWS CodeGuru Reviewer integration. CodeCommit, CodeGuru Reviewer <code>cdk-cicd-exampleSSMParameterStack</code> AWS SSM Parameters for environment variable mirroring. SSM Parameters <code>cdk-cicd-exampleEncryptionStack</code> AWS KMS Key used for data encryption at rest. KMS Key <code>cdk-cicd-exampleComplianceLogBucket</code> This stack ensures that an Amazon S3 Bucket exists for logging. S3 Bucket"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#enabling-gitops","title":"Enabling GitOps","text":"<p>Now that our repository and pipeline are in place, we can start pushing changes to the repository.</p>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-9-add-the-codecommit-repository-as-a-remote","title":"Step 9: Add the CodeCommit repository as a remote","text":"<pre><code>git remote add origin codecommit::$AWS_REGION://cdk-cicd-example\n</code></pre>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-10-install-the-codecommit-remote-plugin","title":"Step 10: Install the CodeCommit remote plugin","text":"<pre><code>pip install git-remote-codecommit\n</code></pre>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-11-commit-and-push-the-changes","title":"Step 11: Commit and push the changes","text":"<pre><code>git add .\ngit commit -m \"feat: initialize pipeline\"\ngit push -u origin main\n</code></pre> <p>After pushing the changes, you can check the repository in the AWS Management Console.</p> <p></p> <p>Congratulations! Your changes have been committed and pushed to the repository.</p>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#observe-the-pipeline","title":"Observe the Pipeline","text":"<p>After pushing the changes to the repository, it's important to observe the progress of the pipeline in AWS CodePipeline to ensure everything is working as expected.</p>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-12-access-aws-codepipeline","title":"Step 12: Access AWS CodePipeline","text":"<ol> <li> <p>Navigate to the AWS Management Console.</p> </li> <li> <p>In the search bar, type CodePipeline and select AWS CodePipeline from the results.</p> </li> </ol> <p></p> <ol> <li>In the CodePipeline dashboard, find the pipeline named <code>cdk-cicd-example</code> (or the name you've given your pipeline).</li> </ol>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-13-view-pipeline-stages","title":"Step 13: View Pipeline Stages","text":"<ol> <li>Click on the <code>cdk-cicd-example</code> pipeline to open its details.</li> <li>You will see the different stages of the pipeline, such as Source, Build, and UpdatePipeline.</li> </ol>"},{"location":"workshops/basics-lvl300/03-create-pipeline.html#step-14-monitor-the-pipeline-execution","title":"Step 14: Monitor the Pipeline Execution","text":"<p>Each stage of the pipeline will show its current status. You can monitor the progress of each stage in real-time.</p> <ul> <li>Source Stage: This stage retrieves the latest commit from the AWS CodeCommit repository.</li> <li>Build Stage: In this stage, AWS CodeBuild runs the CI commands defined in your pipeline, compiling the code and running tests.</li> <li>UpdatePipeline Stage: Finally, the UpdatePipeline stage uses AWS CloudFormation to self-update the pipeline.</li> </ul> <p></p> <p>If the pipeline succeeds, all stages will be marked as Succeeded.</p> \u2713 Congratulations! Your CI/CD pipeline is ready to be used.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html","title":"Develop a GenAI Solution with CDK CI/CD Workbench","text":""},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#what-is-workbench","title":"What is Workbench?","text":"<p>A Workbench is a dedicated development environment where infrastructure code can be created, tested, and iterated upon before it's mature enough to be deployed through an automated pipeline. It\u2019s particularly useful for development teams that don\u2019t have personal AWS accounts for testing and experimentation. The Workbench allows developers to simulate their infrastructure changes in a safe environment without affecting the production pipeline. This ensures that the infrastructure code evolves and stabilizes before it\u2019s promoted to deployment.</p> <p>Now, let\u2019s go through the steps to create a GenAI solution using the Workbench.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#create-an-ecs-cluster-in-the-workbench","title":"Create an ECS Cluster in the Workbench","text":""},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-1-create-the-infrastructure-stack","title":"Step 1: Create the Infrastructure Stack","text":"<p>We\u2019ll begin by creating a file for defining an ECS Cluster.</p> <ol> <li>Create a file in <code>lib/demo-stack.ts</code> and add the following content:</li> </ol> <pre><code>import * as cdk from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport * as ecs from 'aws-cdk-lib/aws-ecs';\n\nexport class DemoStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create an ECS Cluster\n    new ecs.Cluster(this, 'DemoCluster', {\n      clusterName: cdk.Names.uniqueResourceName(this, {\n        maxLength: 50,\n      }),\n      enableFargateCapacityProviders: true,\n      containerInsights: true,\n    });\n  }\n}\n</code></pre> <p>Congratulations! You\u2019ve successfully created the infrastructure definition for an ECS Cluster.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-2-extend-the-pipeline-with-a-dev-stage","title":"Step 2: Extend the Pipeline with a DEV Stage","text":"<ol> <li>Open the <code>bin/cdk-cicd-example.ts</code> file and modify the pipeline to add a DEV stage as the Workbench target.</li> <li>Replace the <code>.defineStages</code> block with the following:</li> </ol> <pre><code>.defineStages([\n  { stage: wrapper.Stage.RES, account: process.env.AWS_ACCOUNT_ID },\n  { stage: wrapper.Stage.DEV, account: process.env.AWS_ACCOUNT_ID },\n])\n</code></pre> <p>Well done! You\u2019ve extended the pipeline to include a DEV stage, which will act as your Workbench.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-3-deploy-the-dev-stage-configuration","title":"Step 3: Deploy the DEV Stage Configuration","text":"<p>Since we\u2019ve defined a new stage with an environment variable, we need to deploy this change to the AWS SSM Parameter Store.</p> <ol> <li> <p>Run the following command to deploy the new stage:</p> <pre><code>npm run cdk deploy -- --all\n</code></pre> <p>Or you can deploy the specific SSM parameter stack:</p> <pre><code>npm run cdk deploy -- cdk-cicd-exampleSSMParameterStack\n</code></pre> </li> </ol> <p>Great! The DEV stage has been successfully deployed.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-4-define-the-workbench","title":"Step 4: Define the Workbench","text":"<ol> <li>Update the pipeline to define the Workbench by adding the following code:</li> </ol> <pre><code>.workbench({\n  provide(context) {\n    new DemoStack(context.scope, 'DemoStack', { env: context.environment });\n  },\n})\n</code></pre> <ol> <li>Import the <code>DemoStack</code> class at the top of the file:</li> </ol> <pre><code>import { DemoStack } from '../lib/demo-stack';\n</code></pre> <p>This code integrates the <code>DemoStack</code> into the Workbench environment.</p> <p>Fantastic! The Workbench has been successfully set up.</p> Show Solution <p>The <code>bin/cdk-cicd-example.ts</code> file should look like this: <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\nimport { DemoStack } from '../lib/demo-stack';\n\nconst app = new cdk.App();\n\nwrapper.PipelineBlueprint.builder()\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: process.env.AWS_ACCOUNT_ID },\n    { stage: wrapper.Stage.DEV, account: process.env.AWS_ACCOUNT_ID },\n  ])\n  .workbench({\n    provide(context) {\n      new DemoStack(context.scope, 'DemoStack', { env: context.environment });\n    },\n  })\n  .synth(app);\n</code></pre></p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#deploy-the-workbench","title":"Deploy the Workbench","text":"<p>Now that the Workbench has been set up, let\u2019s deploy it to the AWS account.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-5-add-a-utility-script-to-packagejson","title":"Step 5: Add a Utility Script to Package.json","text":"<ol> <li>Open the <code>package.json</code> file.</li> <li> <p>Add a utility script element for the Workbench:</p> <pre><code>\"workbench\": \"cdk -c workbench=true\"\n</code></pre> </li> </ol> <p>Nice job! The Workbench utility script has been added to your project.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-6-deploy-the-workbench","title":"Step 6: Deploy the Workbench","text":"<p>Run the following command to deploy the Workbench environment:</p> <pre><code>npm run workbench deploy -- --all\n</code></pre> <p>This command will likely fail due to security checks.</p> <p></p> <p>Great start! Now, let\u2019s address the deployment issues.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-7-resolve-cdk-nag-errors","title":"Step 7: Resolve CDK-Nag Errors","text":"<p>The CDK CI/CD Wrapper uses CDK-Nag to ensure secure and compliant deployments. Let\u2019s resolve any errors that arise during the Workbench deployment.</p> <ol> <li>Open the <code>lib/demo-stack.ts</code> file.</li> <li> <p>Add the following line to ensure proper logging for security purposes:</p> <pre><code>cluster.vpc.addFlowLog('demo-flow-log');\n</code></pre> </li> </ol> <p>Well done! You\u2019ve ensured that your infrastructure is secure and compliant.</p> Show Solution <p>The <code>lib/demo-stack.ts</code> file should look like this: <pre><code>import * as cdk from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport * as ecs from 'aws-cdk-lib/aws-ecs';\n\nexport class DemoStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create an ECS Cluster\n    const cluster = new ecs.Cluster(this, 'DemoCluster', {\n      clusterName: cdk.Names.uniqueResourceName(this, {\n        maxLength: 50,\n      }),\n      enableFargateCapacityProviders: true,\n      containerInsights: true,\n    });\n\n    cluster.vpc.addFlowLog('demo-flow-log');\n  }\n}\n</code></pre></p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-8-redeploy-the-workbench","title":"Step 8: Redeploy the Workbench","text":"<ol> <li> <p>Run the following command to redeploy the Workbench after addressing the security checks:</p> <pre><code>npm run workbench deploy -- --all\n</code></pre> <p>During deployment, you will be asked to approve new AWS IAM permissions. Type \u2018y\u2019 to confirm.</p> </li> </ol> \u2713 Congratulations! The Workbench has been successfully deployed with the security issues resolved."},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#workbench-environment-user-separation","title":"Workbench Environment &amp; User Separation","text":"<p>You might notice that the new stacks have a <code>sagemakeruser</code> prefix, which corresponds to the active username in the CodeEditor. This behavior ensures that workbench deployments are tied to individual users, allowing multiple developers to share the same AWS account without interfering with each other\u2019s work.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#share-the-code-with-the-team","title":"Share the code with the team","text":""},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-10-commit-and-push-the-changes","title":"Step 10: Commit and Push the Changes","text":"<ol> <li> <p>Run the following commands to validate and commit the changes:</p> <pre><code>npm run audit:license -- --fix\nnpm run validate -- --fix\nnpm run lint -- --fix\ngit add .\ngit commit -m \"feat: ECS cluster created in workbench\"\ngit push\n</code></pre> </li> </ol> <p>Congratulations! You\u2019ve successfully committed your changes and pushed them to the repository.</p>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#step-11-observe-the-pipeline","title":"Step 11: Observe the pipeline","text":"<ol> <li>Navigate to the AWS CodePipeline console.</li> <li>Select the pipeline and observe the changes as they progress through the pipeline.</li> <li>Notice that no changes are deployed to the development environment</li> </ol>"},{"location":"workshops/basics-lvl300/04-develop-genai-solution.html#final-notes-on-workbench","title":"Final Notes on Workbench","text":"<p>The Workbench allows infrastructure code to evolve in a controlled, isolated environment. Any changes inside the Workbench are considered work in progress and are not deployed through the delivery pipeline until they are mature enough. This helps avoid long-living branches, simplifies code merging, and accelerates development by providing immediate feedback through the Workbench environment.</p> \u2713 Congratulations! Your Team can new deploy your stack into their own Workbench environment.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/05-deploy-stack.html","title":"Deploy Stack with the Pipeline","text":"<p>Now that we are satisfied with our DemoStack implementation in the Workbench, it\u2019s time to deploy it through the pipeline. </p>"},{"location":"workshops/basics-lvl300/05-deploy-stack.html#update-the-pipeline-to-include-the-demostack","title":"Update the Pipeline to Include the DemoStack","text":"<p>This time, we will use the BaseStackProvider class, which helps maintain cleaner and more manageable code.</p>"},{"location":"workshops/basics-lvl300/05-deploy-stack.html#step-1-create-the-demoprovider-class","title":"Step 1: Create the DemoProvider Class","text":"<p>We\u2019ll begin by creating a <code>bin/demo-provider.ts</code> file that will use the <code>BaseStackProvider</code> class to provide the DemoStack.</p> <ol> <li>Create a file named <code>bin/demo-provider.ts</code>.</li> <li>Add the following content to the file:</li> </ol> <pre><code>import * as wrapper from '@cdklabs/cdk-cicd-wrapper';\nimport { DemoStack } from '../lib/demo-stack';\n\nexport class DemoProvider extends wrapper.BaseStackProvider {\n  stacks(): void {\n    new DemoStack(this.scope, 'DemoStack', { env: this.env });\n  }\n}\n</code></pre> <p>Congratulations! You\u2019ve successfully created the <code>DemoProvider</code> class to manage the deployment of the <code>DemoStack</code>.</p>"},{"location":"workshops/basics-lvl300/05-deploy-stack.html#step-2-add-the-demoprovider-to-the-pipeline","title":"Step 2: Add the DemoProvider to the Pipeline","text":"<p>Next, we will modify the <code>bin/cdk-cicd-example.ts</code> file to include the DemoProvider.</p> <ol> <li>Open the <code>bin/cdk-cicd-example.ts</code> file.</li> <li> <p>Add the following line to include the DemoProvider class:</p> <p><pre><code>.addStack(new DemoProvider())\n</code></pre> 3. Import the <code>DemoProvider</code> class at the top of the file:</p> <pre><code>import { DemoProvider } from './demo-provider';\n</code></pre> </li> </ol> <p>Great work! You\u2019ve successfully updated the pipeline to include the DemoProvider class.</p> Show Solution <p>The <code>bin/cdk-cicd-example.ts</code> file should look like this: <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\nimport { DemoStack } from '../lib/demo-stack';\nimport { DemoProvider } from './demo-provider';\n\nconst app = new cdk.App();\n\nwrapper.PipelineBlueprint.builder()\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: process.env.AWS_ACCOUNT_ID },\n    { stage: wrapper.Stage.DEV, account: process.env.AWS_ACCOUNT_ID },\n  ])\n  .workbench({\n    provide(context) {\n      new DemoStack(context.scope, 'DemoStack', { env: context.environment });\n    },\n  })\n  .addStack(new DemoProvider())\n  .synth(app);\n</code></pre></p>"},{"location":"workshops/basics-lvl300/05-deploy-stack.html#step-3-commit-and-push-the-changes","title":"Step 3: Commit and Push the Changes","text":"<p>Let\u2019s commit and push the changes to the repository so the pipeline can pick them up.</p> <ol> <li> <p>Run the following command to fix any linting issues:</p> <pre><code>npm run lint -- --fix\n</code></pre> </li> <li> <p>Add the changes to Git:</p> <pre><code>git add .\n</code></pre> </li> <li> <p>Commit the changes with a meaningful message:</p> <pre><code>git commit -m \"feat: include DemoStack in CD\"\n</code></pre> </li> <li> <p>Push the changes to the remote repository:</p> <pre><code>git push\n</code></pre> </li> </ol> <p>Fantastic! Your changes have been committed and pushed to the repository.</p>"},{"location":"workshops/basics-lvl300/05-deploy-stack.html#step-4-monitor-the-pipeline-for-deployment","title":"Step 4: Monitor the Pipeline for Deployment","text":"<p>Once the changes are pushed, the pipeline will update, and a new DEV stage will appear for deploying the DemoStack.</p> <ol> <li>Go to the AWS CodePipeline service in the AWS Management Console.</li> <li>Select the <code>cdk-cicd-example</code> pipeline.</li> <li>Monitor the progress of the pipeline. The UpdatePipeline step will update the pipeline configuration to include the new DEV stage.</li> </ol> \u2713 Congratulations! You\u2019ve successfully integrated the **DemoStack** into the pipeline.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html","title":"Develop a GenAI Solution with CDK CI/CD Workbench Part 2","text":"<p>In this section, we will continue developing the GenAI solution using the Workbench. We will create an AWS ECS Fargate task to run a Streamlit application that will host a Python web application to generate images using Amazon Bedrock.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#enhance-the-solution","title":"Enhance the Solution","text":""},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-1-get-your-ip-address","title":"Step 1: Get your IP address","text":"<p>Before proceeding, we need to obtain your IP address to ensure that access to the application is restricted to only you.</p> <ol> <li> <p>Open the following URL: https://checkip.amazonaws.com/.</p> <p>This will display your current IP address.</p> </li> <li> <p>Note down your IP address, as you will need it later to configure access restrictions for the application.</p> </li> </ol>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-2-create-the-fargate-task-definition","title":"Step 2: Create the Fargate Task Definition","text":"<p>We\u2019ll start by enhancing the solution with an ECS Fargate task definition to run the Streamlit application.</p> <ol> <li>Open the file <code>lib/demo-stack.ts</code> and add the following code after the ECS Cluster definition:</li> </ol> <pre><code>const taskRole = new iam.Role(this, 'TaskRole', {\n    assumedBy: new iam.ServicePrincipal('ecs-tasks.amazonaws.com'),\n    inlinePolicies: {\n        BedrockInvokeModel: new iam.PolicyDocument({\n        statements: [\n            new iam.PolicyStatement({\n            actions: ['bedrock:InvokeModel'],\n            resources: [`arn:aws:bedrock:${cdk.Aws.REGION}::foundation-model/amazon.titan-image-generator-v1`],\n            }),\n        ],\n        }),\n    },\n});\n\n// Define a Fargate task definition\nconst fargateTaskDefinition = new ecs.FargateTaskDefinition(this, 'StreamlitAppTaskDef', {\n    taskRole,\n});\n\n// Add container to task definition\nconst container = fargateTaskDefinition.addContainer('StreamlitContainer', {\n    image: ecs.ContainerImage.fromAsset(path.resolve(__dirname, 'image_prompts'), { networkMode: ecrAsset.NetworkMode.custom('sagemaker') }),\n    memoryLimitMiB: 512,\n    cpu: 256,\n    logging: new ecs.AwsLogDriver({ streamPrefix: 'streamlit-app' }),\n});\n\n// Expose the container on port 8501 (Streamlit default port)\ncontainer.addPortMappings({\n    containerPort: 8501,\n    protocol: ecs.Protocol.TCP,\n});\n\n// Create security group for ALB\nconst albSecurityGroup = new ec2.SecurityGroup(this, 'ALBSecurityGroup', {\n    vpc: cluster.vpc,\n    allowAllOutbound: true,\n    description: 'Security group for ALB with restricted ingress',\n});\n\nfor (const ip of allowedIPs) {\n    albSecurityGroup.addIngressRule(\n        ec2.Peer.ipv4(ip),\n        ec2.Port.tcp(80),\n        `Allow HTTP from ${ip}`,\n    );\n}\n\n// Create Fargate service in ECS\nconst loadBalancer = new ecsPatterns.ApplicationLoadBalancedFargateService(this, 'StreamlitFargateService', {\n    cluster: cluster, // Required\n    taskDefinition: fargateTaskDefinition,\n    desiredCount: 1,\n    publicLoadBalancer: true,\n    openListener: false,\n});\n\nloadBalancer.loadBalancer.addSecurityGroup(albSecurityGroup);\n\nnag.NagSuppressions.addResourceSuppressions(\n    loadBalancer,\n    [\n        {\n        id: 'AwsSolutions-ELB2',\n        reason: 'ELB access logs',\n        },\n    ],\n    true,\n);\n\nnag.NagSuppressions.addResourceSuppressions(fargateTaskDefinition, [{\n    id: 'AwsSolutions-IAM5',\n    reason: 'Allow * permissions.',\n    appliesTo: ['Resource::*']\n}], true);\n</code></pre> <ol> <li>Add the following import statements at the top of the file:</li> </ol> <pre><code>import * as iam from 'aws-cdk-lib/aws-iam';\nimport * as ec2 from 'aws-cdk-lib/aws-ec2';\nimport * as ecrAsset from 'aws-cdk-lib/aws-ecr-assets';\nimport * as ecsPatterns from 'aws-cdk-lib/aws-ecs-patterns';\nimport * as path from 'path';\nimport * as nag from 'cdk-nag';\n</code></pre> <ol> <li>Add the following code to the <code>allowedIPs</code> array in the <code>lib/demo-stack.ts</code> file:</li> </ol> <pre><code>const allowedIPs = ['&lt;your-ip-address&gt;/32'];\n</code></pre> <p>Congratulations! You've successfully defined the Fargate task to run the Streamlit app.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-3-create-the-streamlit-application","title":"Step 3: Create the Streamlit Application","text":"<p>Let\u2019s create the Streamlit application that will interact with Amazon Bedrock for generating images.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-31-create-the-docker-setup","title":"Step 3.1: Create the Docker Setup","text":"<ol> <li> <p>Create a new directory called <code>image_prompts</code> in the lib folder.</p> </li> <li> <p>Create a new file called <code>Dockerfile</code> in the <code>image_prompts</code> folder.</p> </li> <li> <p>Add the following content to the <code>Dockerfile</code>:</p> </li> </ol> <pre><code>FROM python:3.12-slim\n\n# Set the working directory\nWORKDIR /app\n\n# Install pipenv to manage dependencies\nRUN pip install pipenv\n\n# Copy the Pipfile and Pipfile.lock first to leverage Docker cache\nCOPY Pipfile Pipfile.lock ./\n\n# Install project dependencies from Pipfile\nRUN pipenv install --system --deploy --ignore-pipfile\n\n# Copy the rest of the application code\nCOPY . .\n\n# Expose the port on which Streamlit runs\nEXPOSE 8501\n\n# Command to run Streamlit app\nCMD [\"streamlit\", \"run\", \"image_prompts_app.py\", \"--server.port\", \"8501\", \"--server.address\", \"0.0.0.0\"]\n</code></pre> <p>Well done! The Docker setup for the Streamlit app is complete.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-32-define-dependencies-and-application-code","title":"Step 3.2: Define Dependencies and Application Code","text":"<ol> <li>Create a new file called <code>Pipfile</code> in the <code>image_prompts</code> folder.</li> <li>Add the following content to the <code>Pipfile</code>:</li> </ol> <pre><code>[[source]]\nurl = \"https://pypi.python.org/simple\"\nverify_ssl = true\nname = \"pypi\"\n\n[packages]\nstreamlit = \"*\"\nbotocore = \"*\"\nboto3 = \"*\"\n\n[requires]\npython_version = \"3\"\n</code></pre> <ol> <li>Create a new file called <code>Pipfile.lock</code> in the <code>image_prompts</code> folder. Open a terminal and run the following command to generate the <code>Pipfile.lock</code> file:</li> </ol> <pre><code>cd lib/image_prompts &amp;&amp; pipenv lock &amp;&amp; cd ../..\n</code></pre> <p>Nice work! The dependencies for the Streamlit app have been set up.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-33-add-the-streamlit-application-logic","title":"Step 3.3: Add the Streamlit Application Logic","text":"<ol> <li>Create a new file called <code>image_prompts_app.py</code> in the <code>image_prompts</code> folder.</li> <li>Add the following content to <code>image_prompts_app.py</code>:</li> </ol> <pre><code>import streamlit as st\nimport image_prompts_lib as glib\n\n\nst.set_page_config(layout=\"wide\", page_title=\"Image Generation\")\n\nst.title(\"Image Generation\")\n\ncol1, col2 = st.columns(2)\n\n\nwith col1:\n    st.subheader(\"Image parameters\")\n\n    prompt_text = st.text_area(\"What you want to see in the image:\", height=100, help=\"The prompt text\")\n    negative_prompt = st.text_input(\"What shoud not be in the image:\", help=\"The negative prompt\")\n\n    generate_button = st.button(\"Generate\", type=\"primary\")\n\n\nwith col2:\n    st.subheader(\"Result\")\n\n    if generate_button:\n        with st.spinner(\"Drawing...\"):\n            generated_image = glib.get_image_from_model(\n                prompt_content=prompt_text, \n                negative_prompt=negative_prompt,\n            )\n\n        st.image(generated_image)\n</code></pre> <p>Awesome! The Streamlit application is ready to generate images.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-34-create-the-helper-library","title":"Step 3.4: Create the Helper Library","text":"<ol> <li>Create a new file called <code>image_prompts_lib.py</code> in the <code>image_prompts</code> folder.</li> <li>Add the following content to <code>image_prompts_lib.py</code>:</li> </ol> <pre><code>import boto3\nimport json\nimport base64\nfrom io import BytesIO\nfrom random import randint\n\n#get the stringified request body for the InvokeModel API call\ndef get_titan_image_generation_request_body(prompt, negative_prompt=None):\n\n    body = { #create the JSON payload to pass to the InvokeModel API\n        \"taskType\": \"TEXT_IMAGE\",\n        \"textToImageParams\": {\n            \"text\": prompt,\n        },\n        \"imageGenerationConfig\": {\n            \"numberOfImages\": 1,  # Number of images to generate\n            \"quality\": \"premium\",\n            \"height\": 512,\n            \"width\": 512,\n            \"cfgScale\": 8.0,\n            \"seed\": randint(0, 100000),  #nosec Use a random seed\n        },\n    }\n\n    if negative_prompt:\n        body['textToImageParams']['negativeText'] = negative_prompt\n\n    return json.dumps(body)\n\n\n#get a BytesIO object from the Titan Image Generator response\ndef get_titan_response_image(response):\n\n    response = json.loads(response.get('body').read())\n\n    images = response.get('images')\n\n    image_data = base64.b64decode(images[0])\n\n    return BytesIO(image_data)\n\n\n#generate an image using Amazon Titan Image Generator\ndef get_image_from_model(prompt_content, negative_prompt=None):\n    session = boto3.Session()\n\n    bedrock = session.client(service_name='bedrock-runtime') #creates a Bedrock client\n\n    body = get_titan_image_generation_request_body(prompt_content, negative_prompt=negative_prompt)\n\n    response = bedrock.invoke_model(body=body, modelId=\"amazon.titan-image-generator-v1\", contentType=\"application/json\", accept=\"application/json\")\n\n    output = get_titan_response_image(response)\n\n    return output\n</code></pre> <p>Fantastic! The helper library is in place to interact with AWS Bedrock.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-4-deploy-the-workbench","title":"Step 4: Deploy the Workbench","text":"<p>Run the following command to deploy the Workbench environment:</p> <pre><code>npm run workbench deploy -- --all\n</code></pre> <p>Well done! The Workbench has been successfully deployed.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-5-verify-the-deployment","title":"Step 5: Verify the Deployment","text":"<p>The deployment process may take a few minutes. Once it's complete, the LoadBalancer URL will be displayed in the terminal.</p> <ol> <li>Open the LoadBalancer URL in your browser to verify the deployment. The Streamlit application should be accessible.</li> </ol> <p>Congratulations! Your application is up and running.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#introduce-feature-flag","title":"Introduce Feature Flag","text":"<p>Now, we need to introduce a feature flag to control whether the Streamlit application should be deployed. This allows us to work on the feature without immediately deploying it through the pipeline.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-6-add-the-feature-flag-to-control-the-streamlit-app","title":"Step 6: Add the Feature Flag to Control the Streamlit App","text":"<ol> <li> <p>Open the <code>lib/demo-stack.ts</code> file and wrap the Streamlit app logic inside a feature flag check. The feature flag allows us to selectively enable or disable the deployment of the Streamlit app:</p> <pre><code>if (cdk.FeatureFlags.of(this).isEnabled('feature-streamlit')) {\n    wrapper.logger.info('Feature Streamlit is enabled');\n\n    const taskRole = new iam.Role(this, 'TaskRole', {\n    // ... Streamlit app definition\n    });\n\n    nag.NagSuppressions.addResourceSuppressions(fargateTaskDefinition.executionRole!, [{\n        id: 'AwsSolutions-IAM5',\n        reason: 'Allow * permissions.',\n        appliesTo: ['Resource::*']\n    }], true);\n}\n</code></pre> </li> <li> <p>Import the CDK CI/CD Wrapper module at the top of the file:</p> <pre><code>import * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n</code></pre> </li> </ol> Show Solution <p>The <code>lib/demo-stack.ts</code> file should look like this: <pre><code>import * as cdk from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\nimport * as ecs from 'aws-cdk-lib/aws-ecs';\nimport * as iam from 'aws-cdk-lib/aws-iam';\nimport * as ec2 from 'aws-cdk-lib/aws-ec2';\nimport * as ecrAsset from 'aws-cdk-lib/aws-ecr-assets';\nimport * as ecsPatterns from 'aws-cdk-lib/aws-ecs-patterns';\nimport * as path from 'path';\nimport * as nag from 'cdk-nag';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n\nconst allowedIPs = ['&lt;your-ip-address&gt;/32'];\n\nexport class DemoStack extends cdk.Stack {\n  constructor(scope: Construct, id: string, props?: cdk.StackProps) {\n    super(scope, id, props);\n\n    // Create an ECS Cluster\n    const cluster = new ecs.Cluster(this, 'DemoCluster', {\n      clusterName: cdk.Names.uniqueResourceName(this, {\n        maxLength: 50,\n      }),\n      enableFargateCapacityProviders: true,\n      containerInsights: true,\n    });\n\n    cluster.vpc.addFlowLog('demo-flow-log');\n    if (cdk.FeatureFlags.of(this).isEnabled('feature-streamlit')) {\n      wrapper.logger.info('Feature Streamlit is enabled');\n\n      const taskRole = new iam.Role(this, 'TaskRole', {\n        assumedBy: new iam.ServicePrincipal('ecs-tasks.amazonaws.com'),\n        inlinePolicies: {\n          BedrockInvokeModel: new iam.PolicyDocument({\n            statements: [\n              new iam.PolicyStatement({\n                actions: ['bedrock:InvokeModel'],\n                resources: [`arn:aws:bedrock:${cdk.Aws.REGION}::foundation-model/amazon.titan-image-generator-v1`],\n              }),\n            ],\n          }),\n        },\n      });\n\n      // Define a Fargate task definition\n      const fargateTaskDefinition = new ecs.FargateTaskDefinition(this, 'StreamlitAppTaskDef', {\n        taskRole,\n      });\n\n      // Add container to task definition\n      const container = fargateTaskDefinition.addContainer('StreamlitContainer', {\n        image: ecs.ContainerImage.fromAsset(path.resolve(__dirname, 'image_prompts'), { networkMode: ecrAsset.NetworkMode.custom('sagemaker') }),\n        memoryLimitMiB: 512,\n        cpu: 256,\n        logging: new ecs.AwsLogDriver({ streamPrefix: 'streamlit-app' }),\n      });\n\n      // Expose the container on port 8501 (Streamlit default port)\n      container.addPortMappings({\n        containerPort: 8501,\n        protocol: ecs.Protocol.TCP,\n      });\n\n      // Create security group for ALB\n      const albSecurityGroup = new ec2.SecurityGroup(this, 'ALBSecurityGroup', {\n        vpc: cluster.vpc,\n        allowAllOutbound: true,\n        description: 'Security group for ALB with restricted ingress',\n      });\n\n      for (const ip of allowedIPs) {\n        albSecurityGroup.addIngressRule(\n          ec2.Peer.ipv4(ip),\n          ec2.Port.tcp(80),\n          `Allow HTTP from ${ip}`,\n        );\n      }\n\n      // Create Fargate service in ECS\n      const loadBalancer = new ecsPatterns.ApplicationLoadBalancedFargateService(this, 'StreamlitFargateService', {\n        cluster: cluster, // Required\n        taskDefinition: fargateTaskDefinition,\n        desiredCount: 1,\n        publicLoadBalancer: true,\n        openListener: false,\n      });\n\n      loadBalancer.loadBalancer.addSecurityGroup(albSecurityGroup);\n\n      nag.NagSuppressions.addResourceSuppressions(\n        loadBalancer,\n        [\n          {\n            id: 'AwsSolutions-ELB2',\n            reason: 'ELB access logs',\n          },\n        ],\n        true,\n      );\n\n      nag.NagSuppressions.addResourceSuppressions(fargateTaskDefinition, [{\n        id: 'AwsSolutions-IAM5',\n        reason: 'Allow * permissions.',\n        appliesTo: ['Resource::*'],\n      }], true);\n    }\n  }\n}\n</code></pre></p> <p>Great job! The Streamlit app is now controlled by a feature flag.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-7-test-the-feature-flag","title":"Step 7: Test the Feature Flag","text":"<p>Let\u2019s test if the feature flag works as expected.</p> <ol> <li> <p>Run the following command to synthesize the CDK code without the feature flag:</p> <pre><code>npm run workbench synth\n</code></pre> </li> <li> <p>Notice there is no log about the Streamlit app in the console.</p> </li> <li> <p>Now enable the feature flag by running this command:</p> <pre><code>npm run workbench synth -- --context feature-streamlit=true\n</code></pre> </li> <li> <p>You should see a log message indicating that the Streamlit app feature is enabled:</p> <pre><code>[Info at /sagemaker-user-cdk-cicd-example] Feature Streamlit is enabled\n</code></pre> </li> </ol> <p>Fantastic! The feature flag works as expected.</p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-8-enable-the-feature-flag-by-default-in-workbench","title":"Step 8: Enable the Feature Flag by Default in Workbench","text":"<p>If we want to enable the feature flag by default in the Workbench environment, we can set it in the pipeline configuration.</p> <ol> <li> <p>Open the <code>bin/cdk-cicd-example.ts</code> file and update the Workbench configuration:</p> <pre><code>.workbench({\n    provide(context) {\n      context.scope.node.setContext('feature-streamlit', true);\n      new DemoStack(context.scope, 'DemoStack', { env: context.environment });\n    },\n})\n</code></pre> </li> </ol> <p>Well done! The feature flag is now enabled by default in the Workbench.</p> Show Solution <p>The <code>bin/cdk-cicd-example.ts</code> file should look like this: <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\nimport { DemoStack } from '../lib/demo-stack';\nimport { DemoProvider } from './demo-provider';\n\nconst app = new cdk.App();\n\nwrapper.PipelineBlueprint.builder()\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: process.env.AWS_ACCOUNT_ID },\n    { stage: wrapper.Stage.DEV, account: process.env.AWS_ACCOUNT_ID },\n  ])\n  .workbench({\n    provide(context) {\n      context.scope.node.setContext('feature-streamlit', true);\n      new DemoStack(context.scope, 'DemoStack', { env: context.environment });\n    },\n  })\n  .addStack(new DemoProvider())\n  .synth(app);\n</code></pre></p>"},{"location":"workshops/basics-lvl300/06-develop-genai-solution-part-2.html#step-9-commit-and-push-the-changes","title":"Step 9: Commit and Push the Changes","text":"<ol> <li> <p>Run the following command to fix any linting issues:</p> <pre><code>npm run lint -- --fix\n</code></pre> </li> <li> <p>Run the following commands to update the license and validate the package.json:</p> <pre><code>npm run audit:license -- --fix\nnpm run validate -- --fix\n</code></pre> </li> <li> <p>Add the changes to Git:</p> <pre><code>git add .\n</code></pre> </li> <li> <p>Commit the changes with a meaningful message:</p> <pre><code>git commit -m \"feat: add feature flag for Streamlit\"\n</code></pre> </li> <li> <p>Push the changes to the repository:</p> <pre><code>git push\n</code></pre> </li> </ol> \u2713 Congratulations! You\u2019ve successfully prepared the Streamlit app for deployment using a feature flag.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/basics-lvl300/07-deploy-solution.html","title":"Deploy the Solution","text":"<p>Now that we are satisfied with our DemoStack implementation in the Workbench, it\u2019s time to enable the feature flag and deploy it through the pipeline.</p>"},{"location":"workshops/basics-lvl300/07-deploy-solution.html#step-1-enable-the-feature-flag","title":"Step 1: Enable the Feature Flag","text":"<p>Open the <code>cdk.json</code> file and add the following line to the context:</p> <pre><code>\"context\": {\n  \"feature-streamlit\": true,\n  ...\n}\n</code></pre>"},{"location":"workshops/basics-lvl300/07-deploy-solution.html#step-2-commit-and-push-the-changes","title":"Step 2: Commit and Push the Changes","text":"<p>Let\u2019s commit and push the changes to the repository so the pipeline can pick them up.</p> <p>Run the following command to fix any linting issues:</p> <pre><code>npm run lint -- --fix\n</code></pre> <p>Add the changes to Git:</p> <pre><code>git add .\n</code></pre> <p>Commit the changes with a meaningful message:</p> <pre><code>git commit -m \"feat: enable Streamlit feature flag\"\n</code></pre> <p>Push the changes to the remote repository:</p> <pre><code>git push\n</code></pre> <p>Fantastic! Your changes have been committed and pushed to the repository.</p>"},{"location":"workshops/basics-lvl300/07-deploy-solution.html#step-3-monitor-the-pipeline-for-deployment","title":"Step 3: Monitor the Pipeline for Deployment","text":"<p>Once the changes are pushed, the pipeline will deploy the new streamlit application.</p> <ol> <li>Go to the AWS CodePipeline service in the AWS Management Console.</li> <li>Select the <code>cdk-cicd-example</code> pipeline.</li> <li>Monitor the progress of the pipeline.</li> </ol> <p>Awesome! The deployment is in progress and soon your solution will be live.</p> \u2713 Congratulations! You\u2019ve successfully finished the workshop.  <p>Finish</p>"},{"location":"workshops/basics-lvl300/08-summary.html","title":"Summary: Achievements &amp; Strengths of the CDK CI/CD Wrapper","text":"<p>Throughout this workshop, we explored how the CDK CI/CD Wrapper enables development teams to streamline the entire process of building, testing, and deploying cloud-native solutions using AWS infrastructure. Let\u2019s recap what we have achieved and the value the CDK CI/CD Wrapper has brought to the table:</p>"},{"location":"workshops/basics-lvl300/08-summary.html#key-achievements","title":"Key Achievements","text":"<ol> <li> <p>Created a CI/CD Pipeline with CDK:     We leveraged the CDK CI/CD Wrapper to build a robust, multi-stage pipeline that automates the entire continuous integration and delivery (CI/CD) process. By abstracting the complexities of setting up a pipeline, the tool enabled us to focus on delivering value quickly.</p> </li> <li> <p>Integrated Quality Gates:     With built-in quality checks, we ensured that only high-quality, secure code moves forward through the pipeline. This included running tests, linting, static code analysis, security scans, and license checks \u2013 all integrated seamlessly with the pipeline.</p> </li> <li> <p>Developed a Generative AI Solution:    Using Amazon Bedrock and AWS ECS Fargate, we developed a GenAI-powered Streamlit application for image generation. The tool's ability to create sandboxed development environments (Workbench) ensured that we could test and refine this solution without disrupting the main pipeline.</p> </li> <li> <p>Introduced Feature Flags:     The feature flag system allowed us to control the deployment of new features like the Streamlit application. This granular control enabled teams to safely test new functionality in lower environments without impacting production systems.</p> </li> <li> <p>Deployed Through a Multi-Stage Pipeline:     We successfully deployed the solution through the DEV stage using the CDK CI/CD Wrapper. The flexibility of the tool allowed us to handle multiple AWS environments and stages effortlessly, all while automating deployment using the pipeline.</p> </li> </ol>"},{"location":"workshops/basics-lvl300/08-summary.html#strengths-of-the-cdk-cicd-wrapper","title":"Strengths of the CDK CI/CD Wrapper","text":"<ol> <li> <p>Simplicity &amp; Automation:    The CDK CI/CD Wrapper abstracts away much of the complexity associated with setting up and managing pipelines, CI/CD workflows, and AWS environments. Developers can focus on delivering features and rely on the wrapper to handle pipeline configuration, quality checks, and deployments.</p> </li> <li> <p>End-to-End CI/CD:    With its ability to seamlessly integrate testing, linting, security scans, and deployment stages, the wrapper ensures that every part of the CI/CD process is automated and robust. From code validation to deployment, it handles everything in one unified flow.</p> </li> <li> <p>Flexibility for Multi-Account AWS Setups:    The tool is designed for real-world use cases, where different stages (DEV, INT, PROD) are hosted in separate AWS accounts. It provides an easy mechanism for managing bootstrapping, resource provisioning, and cross-account trust with minimal configuration.</p> </li> <li> <p>Powerful Development Environments (Workbench):    The Workbench feature stands out as a development sandbox (without calling it that) where developers can safely test infrastructure code. It provides a way to validate infrastructure changes or experiment with new ideas before they\u2019re deployed to production.</p> </li> <li> <p>Feature Flag Control:    The tool\u2019s ability to introduce and manage feature flags allows development teams to control which features are deployed and when. This is crucial for teams adopting agile or DevOps practices, as it allows them to release new features incrementally.</p> </li> <li> <p>Streamlined GenAI Integration:    By leveraging Amazon Bedrock and AWS ECS Fargate, the CDK CI/CD Wrapper enabled us to quickly integrate advanced Generative AI capabilities into our solution. This showcases how easily the tool integrates modern, cutting-edge AWS services into the pipeline.</p> </li> <li> <p>Developer-Centric:    CDK CI/CD Wrapper is built with developers in mind, simplifying both infrastructure-as-code and continuous delivery. The tool empowers teams to take ownership of the entire deployment lifecycle, from initial development to production release.</p> </li> </ol>"},{"location":"workshops/basics-lvl300/08-summary.html#final-thoughts","title":"Final Thoughts","text":"<p>With the CDK CI/CD Wrapper, development teams can accelerate their cloud-native journey by automating the most tedious parts of building, testing, and deploying solutions. It not only reduces manual effort but also increases the quality, security, and speed of your deliveries. </p> <p>By leveraging powerful AWS services and combining them with this tool, we are now well-equipped to handle complex CI/CD workflows with confidence.</p> Congratulations! You've completed the workshop and mastered the fundamentals of building CI/CD pipelines, implementing feature flags, and developing a Generative AI solution with AWS."},{"location":"workshops/basics-lvl300/09-clean-up.html","title":"Clean Up","text":"<p>Congratulations! You have successfully completed the workshop. You can now clean up the resources created in this workshop.</p> <p>To clean up the resources, follow these steps:</p>"},{"location":"workshops/basics-lvl300/09-clean-up.html#step-1-delete-the-cloudformation-stacks","title":"Step 1: Delete the CloudFormation Stacks","text":"<ol> <li>Delete all the CloudFormation stacks created during the workshop. 1.1. Ensure that you delete CDKToolkit stack at the last!!! 1.2. There are dependencies between the stacks, so you need to delete them in the reverse order of creation.</li> </ol>"},{"location":"workshops/basics-lvl300/09-clean-up.html#step-2-delete-the-s3-buckets","title":"Step 2: Delete the S3 Buckets","text":""},{"location":"workshops/basics-lvl300/09-clean-up.html#step-3-delete-the-amazon-sagemaker-studio-domain","title":"Step 3: Delete the Amazon SageMaker Studio Domain","text":"<p>Open the Amazon SageMaker Studio. </p> <p>Click on the <code>Domains</code>. </p> <p>Select the <code>cdk-cicd-example</code> domain. Go to the Space management tab, select the <code>my-space</code> and click on the <code>Delete</code> button. </p> <p>It will show a pop-up to confirm the deletion. Click on the <code>Yes, delete space</code> button, then type in the <code>delete</code> to the input field than click the <code>Delete space</code> button to delete the user space. </p> <p>Then go to the <code>User profiles</code> tab. </p> <p>Select the user profile and click on the <code>Delete</code> button. </p> <p>There will be a pop-up to confirm the deletion. Click on the <code>Yes, delete user profile</code> button, then type in the <code>delete</code> to the input field than click the <code>Delete user profile</code> button to delete the user profile.</p> <p>Then go to the <code>Domain settings</code> tab. Scroll down to the <code>Delete Domain</code> section. Click on the <code>Delete Domain</code> button. </p> <p>There will be a pop-up to confirm the deletion. Click on the <code>Yes, delete my domain</code> button, then type in the <code>delete</code> to the input field than click the <code>Delete domain</code> button to delete the domain.</p>"},{"location":"workshops/basics-lvl300/faq.html","title":"FAQ","text":""},{"location":"workshops/basics-lvl300/faq.html#how-to-open-the-terminal-in-amazon-sagemaker-studio-code-editor","title":"How to open the terminal in Amazon SageMaker Studio - Code Editor?","text":"<p>To open the terminal in Amazon SageMaker Studio - Code Editor, follow these steps: - Click on the <code>Menu</code> icon on the top left corner of the Code Editor. - Select <code>Terminal</code> from the dropdown menu. - Select <code>New Terminal</code> to open a new terminal window.</p>"},{"location":"workshops/basics-lvl300/faq.html#what-to-do-if-the-cdk-init-cannot-be-run-in-a-non-empty-directory-error-occurs","title":"What to do if the \"<code>cdk init</code> cannot be run in a non-empty directory!\" error occurs?","text":"<p>If you encounter the \"<code>cdk init</code> cannot be run in a non-empty directory!\" error, it means that the directory you are trying to initialize is not empty. Most likely your terminal is not in the correct directory. To resolve this issue, make sure you are in the <code>/home/sagemaker-user/cdk-cicd-example</code> directory where you want to initialize the CDK project.</p>"},{"location":"workshops/basics-lvl300/faq.html#i-am-getting-a-prompt-to-studioregionsagemeakeraws-wants-to-see-text-and-images-copied-to-the-clipboard-what-should-i-do","title":"I am getting a prompt to <code>*.studio.&lt;region&gt;.sagemeaker.aws</code> wants to \"See text and images copied to the clipboard\", what should I do?","text":"<p>Amazon SageMaker Studio uses the clipboard to copy and paste text and images between the local machine and the Studio environment. If you see this prompt, you can allow the clipboard access by clicking on the <code>Allow</code> button.</p>"},{"location":"workshops/basics-lvl300/faq.html#how-to-clean-the-npm-cache","title":"How to clean the npm cache?","text":"<p>In case you have get to an npm notarget error during any <code>npm install</code> command, you can try to clean the npm cache with the following command:</p> <pre><code>npm cache clean --force\n</code></pre>"},{"location":"workshops/github-pipeline/index.html","title":"Introduction &amp; Overview","text":""},{"location":"workshops/github-pipeline/index.html#welcome","title":"Welcome","text":"<p>Welcome to the workshop on leveraging the GitHub Pipeline Plugin with the CDK CI/CD Wrapper. In this session, you'll learn how to seamlessly integrate your GitHub repositories with GitHub Actions to automate the deployment of AWS CDK applications to AWS environments. This workshop is designed to demonstrate how the plugin simplifies the continuous integration and deployment process by connecting GitHub and AWS.</p> <p>We are excited to help you explore how this new plugin can supercharge your CI/CD workflows!</p>"},{"location":"workshops/github-pipeline/index.html#target-audience","title":"Target Audience","text":"<p>This workshop is aimed at:</p> <ul> <li>Developers, DevOps engineers, and Cloud engineers who are managing their AWS infrastructure using AWS CDK.</li> <li>Teams that host their source code on GitHub and are looking to leverage GitHub Actions for continuous delivery of AWS applications.</li> <li>Individuals who are already familiar with CI/CD workflows and are interested in optimizing AWS deployments through GitHub Actions.</li> </ul> <p>You should have prior experience with AWS CDK and be familiar with developing or maintaining cloud applications using CDK.</p> <ul> <li>Expected Completion Time: 45 minutes</li> </ul>"},{"location":"workshops/github-pipeline/index.html#background-knowledge","title":"Background Knowledge","text":"<p>To get the most out of this workshop, the following knowledge is recommended:</p> <ul> <li>AWS CDK: Familiarity with creating, maintaining, and deploying cloud infrastructure using AWS CDK.</li> <li>GitHub &amp; GitHub Actions: Basic understanding of how GitHub repositories and GitHub Actions work to automate workflows.</li> <li>CI/CD Concepts: Knowledge of continuous integration and continuous deployment practices, including automated testing and deployments.</li> <li>AWS Accounts &amp; Services: You should have access to an AWS account and be familiar with core services like AWS IAM, AWS CodePipeline, AWS CloudFormation, and AWS IAM Roles.</li> </ul>"},{"location":"workshops/github-pipeline/index.html#what-you-will-learn","title":"What You Will Learn","text":"<p>By the end of this workshop, you will learn how to:</p> <ul> <li>Use the GitHub Pipeline Plugin to connect GitHub repositories to the CDK CI/CD Wrapper for seamless deployment to AWS accounts.</li> <li>Create a GitHub Actions pipeline that automatically deploys your AWS CDK applications.</li> <li>Manage multi-account AWS deployments with ease through GitHub Actions.</li> <li>Implement security best practices while using GitHub to manage CI/CD workflows in AWS.</li> </ul>"},{"location":"workshops/github-pipeline/index.html#architecture-overview","title":"Architecture Overview","text":"<p>In this workshop, we will deploy a multi-stage pipeline for an AWS CDK application using GitHub Actions. Here\u2019s a high-level overview of the architecture:</p> <ol> <li>GitHub Repository: Hosts the source code of your AWS CDK application.</li> <li>GitHub Actions: Used to automate the testing, building, and deployment of the application to AWS environments.</li> <li>AWS CDK CI/CD Wrapper: Manages the continuous integration and deployment of the AWS CDK application across multiple AWS accounts (DEV, INT, PROD).</li> <li>AWS Accounts: The deployment targets where the AWS CDK application will be provisioned, using GitHub Actions for each stage of the pipeline (DEV, INT, PROD).</li> </ol> <p></p> <p>Click on start to begin the workshop.</p> <p>Start</p>"},{"location":"workshops/github-pipeline/00-prerequisites.html","title":"Prerequisites","text":""},{"location":"workshops/github-pipeline/00-prerequisites.html#aws-account-setup","title":"AWS Account Setup","text":"<p>Before starting the workshop, ensure you have the following:</p> <ul> <li>AWS Account with administrative access</li> <li>GitHub Account and an empty GitHub repository</li> </ul>"},{"location":"workshops/github-pipeline/00-prerequisites.html#workspace-setup","title":"Workspace Setup","text":"<p>You will need a workspace to run the workshop. You can use the Amazon SageMaker Studio CodeEditor for this workshop or you can use your local machine.</p>"},{"location":"workshops/github-pipeline/00-prerequisites.html#configure-amazon-sagemaker-studio-codeeditor","title":"Configure Amazon SageMaker Studio CodeEditor","text":"<ol> <li>Download the CloudFormation template to your local machine: cdk-cicd-github-workshop.yml</li> </ol>"},{"location":"workshops/github-pipeline/00-prerequisites.html#cloudformation-stack-setup","title":"CloudFormation Stack Setup","text":"<p>Within your AWS account:</p> <ol> <li>Navigate to AWS CloudFormation (via AWS Console) to create a new stack. </li> <li>On the \"Create stack\" screen, under the Specify a template section, select the Upload a template file option and navigate to select the <code>cdk-cicd-workshop.yml</code> file you downloaded earlier. Click Next. </li> <li>On the \"Specify stack details\" screen, under the Stack name section, provide a name for the CloudFormation stack (e.g., <code>cdk-cicd-workshop</code>).</li> <li>Leave the rest of the parameters unchanged, and click Next. </li> <li>On the \"Configure stack options\" screen, leave the default parameters unchanged, scroll to the bottom of the page, and click Next.</li> <li>On the \"Review\" screen, scroll to the bottom of the page and check the box: \"I acknowledge that AWS CloudFormation might create IAM resources.\". Click Create Stack.    </li> </ol> <p>CloudFormation will take a few minutes to run and set up your environment. Please wait for this step to complete.</p> \u2713 Congratulations! You have successfully deployed the AWS environment for this workshop. Next, we will verify the environment."},{"location":"workshops/github-pipeline/00-prerequisites.html#open-amazon-sagemaker-studio-codeeditor","title":"Open Amazon SageMaker Studio CodeEditor","text":"<ol> <li>In the AWS console, type \"SageMaker\" in the search bar and navigate to the Amazon SageMaker service page.</li> <li>Click on the Studio link in the left navigation pane under the Control Panel. </li> <li> <p>You should see a pre-configured user. Click Open Studio.     This will open the SageMaker Studio UI in a new browser window.</p> </li> <li> <p>Click on the Code Editor icon under Applications and run the <code>my-space</code> application. </p> </li> <li>Click Open to launch the Code Editor in a new browser tab. </li> <li>In the Project folder, open the <code>cdk-cicd-wrapper-github</code> project, which is already initialized for you. </li> </ol> \u2713 Congratulations! You have a ready to go CodeEditor.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/github-pipeline/00-prerequisites.html#configure-local-machine","title":"Configure Local Machine","text":"<p>Install the following tools on your local machine:</p> <ul> <li>AWS CLI</li> <li>AWS CDK</li> <li>Docker</li> <li>Git</li> <li>Node.js</li> <li>Python</li> </ul> <p>Configure the following environment variables:</p> <pre><code>export AWS_REGION=&lt;region&gt;\nexport AWS_ACCOUNT_ID=&lt;account-id&gt;\nexport AWS_PROFILE=&lt;profile&gt; # Optional in case you have multiple profiles\n</code></pre> Congratulations! You have a ready to go workspace.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/github-pipeline/01-create-cdk-project.html","title":"Create a CDK Project &amp; Bootstrap the AWS Account","text":"<p>In this section, we will create a CDK project and bootstrap your AWS account to prepare it for deploying resources using AWS CDK.</p>"},{"location":"workshops/github-pipeline/01-create-cdk-project.html#step-1-create-a-cdk-typescript-project","title":"Step 1: Create a CDK TypeScript Project","text":"<p>We will start by initializing a new CDK project in TypeScript.</p> <pre><code>npx -y aws-cdk init --language typescript\n</code></pre>"},{"location":"workshops/github-pipeline/01-create-cdk-project.html#step-2-add-the-cdk-cicd-wrapper","title":"Step 2: Add the CDK CI/CD Wrapper","text":"<p>To add the necessary wrapper for your project, run the following command:</p> <pre><code>npm install --include=dev --save @cdklabs/cdk-cicd-wrapper @cdklabs/cdk-cicd-wrapper-cli\n</code></pre>"},{"location":"workshops/github-pipeline/01-create-cdk-project.html#step-3-bootstrap-the-resourcing-res-account","title":"Step 3: Bootstrap the Resourcing (RES) Account","text":"<p>You need to bootstrap your AWS account so it can manage CDK resources. You can refer to the official AWS CDK Bootstrapping Documentation for more details.</p>"},{"location":"workshops/github-pipeline/01-create-cdk-project.html#optional-modify-cdkjson-configuration","title":"Optional: Modify <code>cdk.json</code> Configuration","text":"<p>Add the following CDK configurations to your <code>cdk.json</code> file for additional control over the bootstrapping process:</p> <ul> <li>toolkitStackName</li> <li>@aws-cdk/core:bootstrapQualifier</li> </ul> <p></p> <p>Bootstrap the Account</p> <pre><code>npm run cdk bootstrap\n</code></pre> <p>If you've configured <code>@aws-cdk-core:bootstrapQualifier</code>, use the following command with the qualifier:</p> <pre><code>npm run cdk bootstrap -- --qualifier cdkcicd\n</code></pre>"},{"location":"workshops/github-pipeline/01-create-cdk-project.html#step-4-verify-the-bootstrap","title":"Step 4: Verify the Bootstrap","text":"<p>After running the bootstrap command, verify that the <code>CDKToolkit</code> or if you've configured <code>toolkitStackName</code> stack is present in the AWS CloudFormation Service.</p>"},{"location":"workshops/github-pipeline/01-create-cdk-project.html#real-life-setup-for-multiple-aws-accounts","title":"Real-Life Setup for Multiple AWS Accounts","text":"<p>For this workshop, we are using a single AWS account. However, in real-world scenarios, each stage (e.g., DEV, INT, PROD) would have its own dedicated AWS account. You\u2019ll need to bootstrap each of these accounts with the same CDK qualifier and establish trust with the resourcing account.</p> <p>Here\u2019s an example command to bootstrap a different account with a trust relationship:</p> <pre><code>npm run cdk bootstrap -- \\\n  --qualifier cdkcicd  \\\n  --profile &lt;my_aws_profile_for_other_account&gt; \\\n  --cloudformation-execution-policies arn:aws:iam::aws:policy/AdministratorAccess \\\n  --trust &lt;resource_account_number&gt; aws://&lt;stage_account_number&gt;/&lt;region&gt;\n</code></pre> \u2713 Congratulations! You have a created a CDK project and bootstrapped your AWS account for CDK development.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html","title":"Define the Quality Gates and Continuous Integration","text":"<p>In this section, we will guide you through setting up quality gates and continuous integration (CI) in your workflow. You\u2019ll learn how to configure checkpoints to ensure your code meets standards and how to automate integration and testing using CI tools.</p> <p>The setup of quality gates and CI may vary depending on the technologies and tools used in the project, but at a high level, they follow these key steps: code style checking or static code analysis (linting), vulnerability scanning for dependencies and the codebase, project building, and executing various tests.</p> <p>We will mainly edit the <code>package.json</code> file in this section. Open that file and follow the steps below.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#build-test-steps","title":"Build &amp; Test Steps","text":"<p>The build and test steps are already included in this workshop\u2019s setup. Let\u2019s test them.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-1-run-the-build-command-to-transpile-the-typescript-code-to-javascript","title":"Step 1: Run the build command to transpile the TypeScript code to JavaScript.","text":"<pre><code>npm run build\n</code></pre> <p>Congratulations! You\u2019ve successfully compiled the project. Your code is now transpiled from TypeScript to JavaScript.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-2-run-the-test-command-to-execute-the-unit-tests","title":"Step 2: Run the test command to execute the Unit tests.","text":"<pre><code>npm run test\n</code></pre> <p>Well done! You\u2019ve completed running the unit tests. These checks ensure that your code behaves as expected.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#unifying-code-style-and-static-code-checks","title":"Unifying Code Style and Static Code Checks","text":""},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-3-install-eslint","title":"Step 3: Install ESLint","text":"<p>For NPM projects, it\u2019s common to use eslint for code styling and static code analysis. To install eslint, run the following command:</p> <pre><code>npm install --save-dev eslint @eslint/core @eslint/js @types/eslint__js typescript typescript-eslint @stylistic/eslint-plugin\n</code></pre>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-4-create-the-eslint-configuration-file","title":"Step 4: Create the ESLint Configuration File","text":"<p>Create a file called <code>eslint.config.mjs</code> in the project root with the following content:</p> <pre><code>import eslint from '@eslint/js';\nimport tseslint from 'typescript-eslint';\nimport stylistic from '@stylistic/eslint-plugin';\n\nexport default tseslint.config(\n  eslint.configs.recommended,\n  ...tseslint.configs.strict,\n  ...tseslint.configs.stylistic,\n  stylistic.configs.customize({\n    indent: 2,\n    quotes: 'single',\n    semi: true,\n  }),\n  {\n    ignores: [\n      'node_modules/**/*',\n      'cdk.out/**/*',\n      '**/*.js',\n      '**/*.d.ts',\n    ],\n  },\n  {\n    rules: {\n      '@stylistic/eol-last': ['off'], // workshop code removes the tailing spaces, that is why this rule disabled\n      '@typescript-eslint/no-useless-constructor': ['warn'], // AWS CDK example code has useless constructor\n    },\n  },\n);\n</code></pre> <p>Great job! You\u2019ve set up your ESLint configuration, which will help maintain code quality and uniformity across the project.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-5-add-the-lint-script-to-packagejson","title":"Step 5: Add the lint script to <code>package.json</code>","text":"<p>Open the <code>package.json</code> file and insert a new script called <code>lint</code> like this: <code>\"lint\": \"eslint .\"</code></p> <p>Your <code>package.json</code> should look like:</p> <pre><code>{\n  \"name\": \"cdk-cicd-wrapper-github\",\n  \"version\": \"0.1.0\",\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"test\": \"jest\",\n    \"lint\": \"eslint .\",\n    \"cdk\": \"cdk\"\n  }\n}\n</code></pre>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-6-run-the-lint-script-to-test-it","title":"Step 6: Run the lint script to test it.","text":"<pre><code>npm run lint\n</code></pre> <p>Congratulations! You\u2019ve successfully run the linter. Your code is now checked for style and potential errors.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#security-scan-of-third-party-dependencies-and-codebase","title":"Security Scan of Third-Party Dependencies and Codebase","text":""},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-7-add-a-third-party-dependency-audit-step","title":"Step 7: Add a Third-Party dependency audit step","text":"<p>Edit the <code>package.json</code> and include the audit step for dependencies:</p> <pre><code>\"audit:deps\": \"cdk-cicd check-dependencies --npm --python\"\n</code></pre> <p>This command will analyze both NPM and Python dependencies and report any known vulnerabilities.</p> <p>Awesome! You\u2019ve added an important step to scan your third-party dependencies for vulnerabilities.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-8-add-a-security-scan-step-for-the-codebase","title":"Step 8: Add a security scan step for the codebase","text":"<p>Include the security scan for the source code in <code>package.json</code>:</p> <pre><code>\"audit:security-scan\": \"cdk-cicd security-scan --bandit --semgrep --shellcheck\"\n</code></pre> <p>This will run scanners (Bandit, Semgrep, Shellcheck) on the codebase to detect security risks.</p> <p>Well done! You\u2019ve set up the security scan to keep your code safe from common vulnerabilities.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#ensure-packagejson-integrity","title":"Ensure <code>package.json</code> Integrity","text":""},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-9-validate-packagejson","title":"Step 9: Validate <code>package.json</code>","text":"<p>Edit the <code>package.json</code> and include the following validation script:</p> <pre><code>\"validate\": \"cdk-cicd validate\"\n</code></pre> <p>To run the validation:</p> <pre><code>npm run validate\n</code></pre> <p>This may fail on the first execution since validation hasn\u2019t been executed before. To fix it, run:</p> <pre><code>npm run validate -- --fix\n</code></pre> Repeat this process anytime you modify the `package.json` file. <p>Fantastic! You\u2019ve ensured that your configuration is now validated, keeping your project secure and consistent.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#verifying-third-party-licenses","title":"Verifying Third-Party Licenses","text":""},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-10-audit-licenses","title":"Step 10: Audit licenses","text":"<p>Edit <code>package.json</code> to include a license audit step:</p> <pre><code>\"audit:license\": \"cdk-cicd license\"\n</code></pre> <p>To run the license audit:</p> <pre><code>npm run audit:license\n</code></pre> <p>It may fail the first time because it verifies the existence of the <code>NOTICE</code> file in your repository. Fix it by running:</p> <pre><code>npm run audit:license -- --fix\n</code></pre> <p>This will generate the <code>NOTICE</code> file and the <code>OSS_License_Summary.csv</code> summarizing the used license types in your project.</p> Repeat this process anytime you modify the package.json, requirement.txt, and / or Pipfile. <p>Congrats! You\u2019ve completed the license audit, ensuring all third-party dependencies are legally valid and accounted for.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#concurrent-execution-of-audits","title":"Concurrent Execution of Audits","text":"<p>Running multiple security checks can take time, so it's beneficial to parallelize them.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#step-10-edit-the-packagejson-to-include","title":"Step 10: Edit the <code>package.json</code> to include:","text":"<pre><code>\"audit\": \"concurrently 'npm:audit:*'\"\n</code></pre> <p>Install the dependency:</p> <pre><code>npm install --save-dev concurrently\n</code></pre> <p>Run the audit command:</p> <pre><code>npm run audit\n</code></pre> <p>If the audit fails due to <code>package.json</code> modifications, run:</p> <pre><code>npm run audit:license -- --fix\nnpm run validate -- --fix\n</code></pre> <p>Then, re-run:</p> <pre><code>npm run audit\n</code></pre> <p>Amazing! You\u2019ve successfully parallelized your audit tasks, saving time while ensuring your code remains safe and compliant.</p>"},{"location":"workshops/github-pipeline/02-define-quality-gates-ci.html#summary","title":"Summary","text":"<p>By the end of this section, we have defined all the necessary steps for a high-quality, robust CI pipeline for an AWS CDK-based project. These include:</p> <ul> <li>validate: Ensures our configuration isn\u2019t tampered with.</li> <li>build: Ensures our code compiles correctly.</li> <li>test: Ensures tests are executed.</li> <li>lint: Ensures code style and quality.</li> <li>audit: Ensures dependencies are vulnerability-free and legally valid, and the codebase doesn't introduce security risks.</li> </ul> Show Solution <p>The <code>package.json</code> file should look like this: <pre><code>{\n  \"name\": \"cdk-cicd-example\",\n  \"version\": \"0.1.0\",\n  \"bin\": {\n    \"cdk-cicd-example\": \"bin/cdk-cicd-example.js\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc\",\n    \"watch\": \"tsc -w\",\n    \"test\": \"jest\",\n    \"lint\": \"eslint .\",\n    \"audit\": \"concurrently 'npm:audit:*'\",\n    \"audit:deps\": \"cdk-cicd check-dependencies --npm --python\",\n    \"audit:security-scan\": \"cdk-cicd security-scan --bandit --semgrep --shellcheck\",\n    \"audit:license\": \"cdk-cicd license\",\n    \"validate\": \"cdk-cicd validate\",\n    \"cdk\": \"cdk\"\n  },\n  \"devDependencies\": {\n    \"@eslint/js\": \"^9.10.0\",\n    \"@stylistic/eslint-plugin\": \"^2.8.0\",\n    \"@types/eslint__js\": \"^8.42.3\",\n    \"@types/jest\": \"^29.5.12\",\n    \"@types/node\": \"22.5.4\",\n    \"aws-cdk\": \"2.158.0\",\n    \"concurrently\": \"^9.0.1\",\n    \"eslint\": \"^9.10.0\",\n    \"jest\": \"^29.7.0\",\n    \"ts-jest\": \"^29.2.5\",\n    \"ts-node\": \"^10.9.2\",\n    \"typescript\": \"~5.6.2\",\n    \"typescript-eslint\": \"^8.6.0\"\n  },\n  \"dependencies\": {\n    \"@cdklabs/cdk-cicd-wrapper\": \"^0.2.12\",\n    \"@cdklabs/cdk-cicd-wrapper-cli\": \"^0.2.10\",\n    \"aws-cdk-lib\": \"2.158.0\",\n    \"constructs\": \"^10.0.0\",\n    \"source-map-support\": \"^0.5.21\"\n  }\n}\n</code></pre></p> \u2713 Congratulations! You\u2019ve completed setting up all your quality gates and continuous integration steps. You now have a strong foundation for building, testing, and securing your AWS CDK project!  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html","title":"Creating a Pipeline and Enabling GitOps","text":"<p>In this section, we are going to create the AWS CodePipeline and the required resources with the help of the CDK CI/CD Wrapper.</p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#clean-up-the-example-stack","title":"Clean up the Example Stack","text":""},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-1-open-the-example-file","title":"Step 1: Open the Example File","text":"<p>First, open your <code>bin/cdk-cicd-wrapper-github.ts</code> file. It should look like this:</p> <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport { CdkCicdWrapperGithubStack } from '../lib/cdk-cicd-wrapper-github-stack';\n\nconst app = new cdk.App();\nnew CdkCicdWrapperGithubStack(app, 'CdkCicdWrapperGithubStack', {\n  /* If you don't specify 'env', this stack will be environment-agnostic.\n   * Account/Region-dependent features and context lookups will not work,\n   * but a single synthesized template can be deployed anywhere. */\n\n  /* Uncomment the next line to specialize this stack for the AWS Account\n   * and Region that are implied by the current CLI configuration. */\n  // env: { account: process.env.CDK_DEFAULT_ACCOUNT, region: process.env.CDK_DEFAULT_REGION },\n\n  /* Uncomment the next line if you know exactly what Account and Region you\n   * want to deploy the stack to. */\n  // env: { account: '123456789012', region: 'us-east-1' },\n\n  /* For more information, see https://docs.aws.amazon.com/cdk/latest/guide/environments.html */\n});\n</code></pre>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-2-remove-the-example-stack","title":"Step 2: Remove the Example Stack","text":"<p>Let\u2019s remove the example stack by deleting the following blocks:</p> <pre><code>import { CdkCicdWrapperGithubStack } from '../lib/cdk-cicd-wrapper-github-stack';\n</code></pre> <p>and</p> <pre><code>new CdkCicdWrapperGithubStack(app, 'CdkCicdWrapperGithubStack', {\n  /* Account/Region environment configuration */\n});\n</code></pre>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-3-remove-the-unnecessary-file","title":"Step 3: Remove the unnecessary File","text":"<p>Delete the <code>lib/cdk-cicd-wrapper-github-stack.ts</code> file, as it\u2019s no longer needed.</p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-4-verify-the-clean-up","title":"Step 4: Verify the Clean Up","text":"<p>Your <code>bin/cdk-cicd-wrapper-github.ts</code> file should now look like this:</p> <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\n\nconst app = new cdk.App();\n</code></pre>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#create-the-pipeline","title":"Create the Pipeline","text":""},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-5-import-the-cdk-cicd-wrapper","title":"Step 5: Import the CDK CI/CD Wrapper","text":"<p>Now, let\u2019s import the CDK CI/CD Wrapper. Add the following import statement after the <code>aws-cdk-lib</code> import:</p> <pre><code>import * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n</code></pre> <p>The updated <code>bin/cdk-cicd-wrapper-github.ts</code> file should now look like:</p> <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\n</code></pre>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-6-define-the-pipeline-with-builder","title":"Step 6: Define the Pipeline with Builder","text":"<p>Next, we will create the pipeline using the CDK CI/CD Wrapper. Before proceeding, you need to replace the placeholders in the code with your own AWS account ID and GitHub repository name.</p> <ol> <li>Replace  with your actual AWS account ID. <p>You can find your AWS account ID in the AWS Management Console by selecting My Account from the account dropdown (upper-right corner of the console).</p> You must use the explicit AWS account ID here. The usual environment variables such as <code>ACCOUNT_RES</code>, <code>ACCOUNT_DEV</code>, or <code>ACCOUNT_INT</code> cannot be used in this case. <ol> <li>Replace  with the name of your GitHub repository. <p>This should be the repository name where you have your AWS CDK application. You can find this name directly in your GitHub repository's URL: https://github.com//. <pre><code>wrapper.PipelineBlueprint.builder()\n  .region('eu-central-1')\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: '&lt;your AWS account id&gt;' },\n  ])\n  .plugin(new wrapper.GitHubPipelinePlugin({\n    repositoryName: '&lt;your GitHub repository&gt;',\n  }))\n  .synth(app);\n</code></pre> <p>Congratulations! Your code is ready to deploy the pipeline.</p> Show Solution <p>The <code>bin/cdk-cicd-wrapper-github.ts</code> file should look like this: <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\n\nconst app = new cdk.App();\nwrapper.PipelineBlueprint.builder()\n  .region('eu-central-1')\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: '&lt;your AWS account id&gt;' },\n  ])\n  .plugin(new wrapper.GitHubPipelinePlugin({\n    repositoryName: '&lt;your GitHub repository&gt;',\n  }))\n  .synth(app);\n</code></pre></p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#deploy-the-pipeline","title":"Deploy the Pipeline","text":""},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-7-verify-the-code-can-be-synthesized","title":"Step 7: Verify the Code Can Be Synthesized","text":"<p>Run the following command to synthesize the pipeline:</p> <pre><code>npm run cdk synth\n</code></pre> <p>When you run this command, the pipeline will generate a .github folder in your project. This folder contains a GitHub Actions workflow that automates the deployment of your AWS CDK application.</p> <p>The workflow includes steps to build, test, and synthesize your CDK code, ensuring it is ready for deployment. It triggers on every push to the main branch, using GitHub Actions to automatically deploy the application to your AWS environment. You can manually trigger the deployment or let it run automatically on code changes.</p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-8-set-up-the-aws-side-of-the-pipeline","title":"Step 8: Set Up the AWS Side of the Pipeline","text":"<p>To deploy the AWS account-side components of the pipeline, run the following command:</p> <pre><code>npm run cdk deploy -- --all\n</code></pre> <p>During the deployment process, you will be prompted to review the AWS IAM policies that will be created. Once you've reviewed them, confirm by typing 'y'.</p> \u2713 Congratulations! Your AWS account is now ready to interact with the GitHub repository."},{"location":"workshops/github-pipeline/03-create-pipeline.html#optional-review-the-infrastructure","title":"(Optional) Review the Infrastructure","text":"<p>Let\u2019s review the infrastructure that was deployed. Go to the AWS CloudFormation service and check the following stacks:</p> Stack Description Resources <code>cdk-cicd-wrapper-github</code> The core stack containing the IAM Role and Policy to interact with the AWS accoutn from GitHub Actions. <code>cdk-cicd-wrapper-githubRepository</code> The core stack containing the IAM Role and Policy to interact with the AWS accoutn from GitHub Actions <code>cdk-cicd-wrapper-githubSSMParameterStack</code> AWS SSM Parameters for environment variable mirroring. SSM Parameters <code>cdk-cicd-wrapper-githubEncryptionStack</code> AWS KMS Key used for data encryption at rest. KMS Key <code>cdk-cicd-wrapper-githubComplianceLogBucket</code> This stack ensures that an Amazon S3 Bucket exists for logging. S3 Bucket"},{"location":"workshops/github-pipeline/03-create-pipeline.html#enabling-gitops","title":"Enabling GitOps","text":"<p>Now that our repository and pipeline are in place, we can start pushing changes to the repository.</p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-9-add-the-github-repository-as-a-remote","title":"Step 9: Add the GitHub repository as a remote","text":"<pre><code>git remote add origin &lt;GitHub repository clone url&gt;\n</code></pre>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-10-commit-and-push-the-changes","title":"Step 10: Commit and push the changes","text":"<pre><code>git add .\ngit commit -m \"feat: initialize pipeline\"\ngit push -u origin main\n</code></pre> <p>After pushing the changes, you can check the repository in the AWS Management Console.</p> <p></p> <p>Congratulations! Your changes have been committed and pushed to the repository.</p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#observe-the-pipeline","title":"Observe the Pipeline","text":"<p>After pushing the changes to the repository, it's important to observe the progress of the pipeline in AWS CodePipeline to ensure everything is working as expected.</p>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-11-access-github-actions","title":"Step 11: Access GitHub Actions","text":"<ol> <li> <p>Navigate to your GitHub repository.</p> </li> <li> <p>Click on the Actions tab at the top of the repository page.</p> </li> </ol> <p></p> <ol> <li>In the CodePipeline dashboard, find the pipeline named <code>cdk-cicd-example</code> (or the name you've given your pipeline).</li> </ol>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-12-view-workflow-stages","title":"Step 12: View Workflow Stages","text":"<ol> <li> <p>Click on the deploy workflow to open its details.</p> </li> <li> <p>You will see the different stages of the workflow, such as Checkout, Build, Test, and Synthesize.</p> </li> </ol>"},{"location":"workshops/github-pipeline/03-create-pipeline.html#step-13-monitor-the-workflow-execution","title":"Step 13: Monitor the Workflow Execution","text":"<p>Each stage of the workflow will display its current status. You can monitor the progress of each steps in real-time.</p> <ul> <li>Checkout Step: This step retrieves the latest commit from your GitHub repository.</li> <li>Build Step: During this step, the workflow will run the commands defined in your npm scripts, compiling the code, running tests, ensuring the code quality, and AWS CDK to generate and prepare your CloudFormation templates for deployment</li> <li>Upload Step: Finally, the upload step uploads the cdk.out folder as artifact.</li> </ul> <p></p> <p>If the pipeline succeeds, all stages will be marked as Succeeded.</p> \u2713 Congratulations! Your CI/CD pipeline is ready to be used.  <p>Click Next to continue to the next section.</p> <p>Next</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html","title":"Deploy stack with CDK CI/CD Wrapper","text":"<p>In this section, we\u2019ll deploy our infrastructure stack using the CDK CI/CD Wrapper integrated with GitHub Actions. This will guide you through the process of creating an AWS infrastructure stack, integrating it into the pipeline, and deploying it across stages. The stack we are deploying is designed to be flexible, modular, and ready for deployment in multiple AWS accounts.</p> <p>You will:</p> <ul> <li>Create an infrastructure stack (HelloWorldStack) in your CDK project.</li> <li>Extend the CDK pipeline with a DEV stage for deployment.</li> <li>Add and manage the stack using the DefaultStackProvider.</li> <li>Deploy and observe the CI/CD pipeline using GitHub Actions.</li> </ul> <p>By the end of this section, you\u2019ll have a complete understanding of how to define, manage, and deploy infrastructure using the CDK CI/CD Wrapper, powered by GitHub Actions for continuous integration and deployment.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#create-a-stack","title":"Create a Stack","text":""},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-1-create-the-infrastructure-stack","title":"Step 1: Create the Infrastructure Stack","text":"<p>We\u2019ll begin by defining our demo stack.</p> <ol> <li>Create a file in <code>lib/hello-world-stack.ts</code> and add the following content:</li> </ol> <pre><code>import * as lambda from 'aws-cdk-lib/aws-lambda';\nimport * as nag from 'cdk-nag';\nimport { Stack, StackProps } from 'aws-cdk-lib';\nimport { Construct } from 'constructs';\n\nexport class HelloWorldStack extends Stack {\n  constructor(scope: Construct, id: string, props?: StackProps) {\n    super(scope, id, props);\n\n    // Define the inline Python code\n    const inlinePythonCode = `\ndef handler(event, context):\n    return {\n        'statusCode': 200,\n        'body': 'Hello CDK CI/CD Wrapper'\n    }\n`;\n\n    // Create the Lambda function\n    const pythonLambda = new lambda.Function(this, 'InlinePythonLambda', {\n      runtime: lambda.Runtime.PYTHON_3_12, // Specify the Python runtime\n      handler: 'index.handler', // Define the handler method\n      code: lambda.Code.fromInline(inlinePythonCode), // Inline Python code\n    });\n\n    nag.NagSuppressions.addResourceSuppressions(\n      pythonLambda,\n      [\n        {\n          id: 'AwsSolutions-IAM4',\n          reason: 'AWSLambdaBasicExecutionRole managed policy is used.',\n        },\n      ],\n      true,\n    );\n  }\n}\n</code></pre> <p>Congratulations! You\u2019ve successfully created the infrastructure definition.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-2-extend-the-pipeline-with-a-dev-stage","title":"Step 2: Extend the Pipeline with a DEV Stage","text":"<ol> <li>Open the <code>bin/cdk-cicd-wrapper-github.ts</code> file and modify the pipeline to add a DEV stage.</li> <li>Replace the <code>.defineStages</code> block with the following:<ul> <li>Replace <code>&lt;your AWS account id&gt;</code> with your actual AWS account ID.</li> </ul> </li> </ol> You can find your AWS account ID in the AWS Management Console by selecting My Account from the account dropdown (upper-right corner of the console). <pre><code>.defineStages([\n  { stage: wrapper.Stage.RES, account: '&lt;your AWS account&gt;' },\n  { stage: wrapper.Stage.DEV, account: '&lt;your AWS account&gt;' },\n])\n</code></pre> <p>Well done! You\u2019ve extended the pipeline to include a DEV stage.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#update-the-pipeline-to-include-the-helloworldstack","title":"Update the Pipeline to Include the HelloWorldStack","text":"<p>This time, we will use the DefaultStackProvider class, which helps maintain cleaner and more manageable code.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-3-create-the-helloworldprovider-class","title":"Step 3: Create the HelloWorldProvider Class","text":"<p>We\u2019ll begin by creating a <code>bin/hello-world-provider.ts</code> file that will use the <code>DefaultStackProvider</code> class to provide the HelloWorldStack.</p> <ol> <li>Create a file named <code>bin/hello-world-provider.ts</code>.</li> <li>Add the following content to the file:</li> </ol> <pre><code>import * as wrapper from '@cdklabs/cdk-cicd-wrapper';\nimport { HelloWorldStack } from '../lib/hello-world-stack';\n\nexport class HelloWorldProvider extends wrapper.DefaultStackProvider {\n  stacks(): void {\n    new HelloWorldStack(this.scope, 'HelloWorldStack', { env: this.env });\n  }\n}\n</code></pre> <p>Congratulations! You\u2019ve successfully created the <code>HelloWorldProvider</code> class to manage the deployment of the <code>HelloWorldStack</code>.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-4-add-the-helloworldprovider-to-the-pipeline","title":"Step 4: Add the HelloWorldProvider to the Pipeline","text":"<p>Next, we will modify the <code>bin/cdk-cicd-wrapper-github.ts</code> file to include the HelloWorldProvider.</p> <ol> <li>Open the <code>bin/cdk-cicd-wrapper-github.ts</code> file.</li> <li> <p>Add the following line to include the HelloWorldProvider class:</p> <p><pre><code>.addStack(new HelloWorldProvider())\n</code></pre> 3. Import the <code>HelloWorldProvider</code> class at the top of the file:</p> <pre><code>import { HelloWorldProvider } from './hello-world-provider';\n</code></pre> </li> </ol> <p>Great work! You\u2019ve successfully updated the pipeline to include the DemoProvider class.</p> Show Solution <p>The <code>bin/cdk-cicd-wrapper-github.ts</code> file should look like this: <pre><code>#!/usr/bin/env node\nimport 'source-map-support/register';\nimport * as cdk from 'aws-cdk-lib';\nimport * as wrapper from '@cdklabs/cdk-cicd-wrapper';\nimport { HelloWorldProvider } from './hello-world-provider';\n\nconst app = new cdk.App();\nwrapper.PipelineBlueprint.builder()\n  .region('eu-central-1')\n  .defineStages([\n    { stage: wrapper.Stage.RES, account: '&lt;your AWS account id&gt;' },\n    { stage: wrapper.Stage.DEV, account: '&lt;your AWS account id&gt;' },\n  ])\n  .plugin(new wrapper.GitHubPipelinePlugin({\n    repositoryName: '&lt;your GitHub repository&gt;',\n  }))\n  .addStack(new HelloWorldProvider())\n  .synth(app);\n</code></pre></p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-5-update-the-pipeline","title":"Step 5: Update the pipeline","text":"<p>Since we\u2019ve defined a new stage (DEV) and introduced new AWS CDK stacks, it's essential to update the GitHub Actions pipeline to ensure that the new stack is correctly included in the deployment process. This allows the new HelloWorldStack to be synthesized and deployed across the pipeline stages. Without updating, the pipeline would not recognize the new infrastructure changes.</p> <ol> <li> <p>Run the following command to deploy the new stage:</p> <pre><code>npm run cdk deploy -- --all\n</code></pre> </li> </ol> <p>Great! The DEV stage has been successfully deployed.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#commit-the-changes","title":"Commit the changes","text":""},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-6-commit-and-push-the-changes","title":"Step 6: Commit and Push the Changes","text":"<ol> <li> <p>Run the following commands to validate and commit the changes:</p> <pre><code>git add .\ngit commit -m \"feat: helloWorld Stack added to DEV\"\ngit push\n</code></pre> </li> </ol> <p>Congratulations! You\u2019ve successfully committed your changes and pushed them to the repository.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#observe-the-pipeline","title":"Observe the Pipeline","text":"<p>After pushing the changes to the repository, it's important to observe the progress of the pipeline in GitHub Actions to ensure everything is working as expected.</p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-7-access-github-actions","title":"Step 7: Access GitHub Actions","text":"<ol> <li> <p>Navigate to your GitHub repository.</p> </li> <li> <p>Click on the Actions tab at the top of the repository page. This lists the executed workflows.</p> </li> </ol> <p></p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-8-view-workflow-pipeline","title":"Step 8: View Workflow Pipeline","text":"<ol> <li> <p>Click on the <code>feat: helloWorld Stack added to DEV</code> workflow to open its details.</p> </li> <li> </li> </ol> <p></p>"},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-8-view-workflow-pipeline_1","title":"Step 8: View Workflow Pipeline","text":""},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-9-github-environments","title":"Step 9: GitHub Environments","text":"<p>The CDK CI/CD Wrapper integrates seamlessly with GitHub\u2019s Environment feature, allowing you to track and manage deployments to different stages (such as DEV, INT, and PROD) directly from your GitHub repository.</p> <p>Your environments and their latest deployments are listed in the sidebar of your GitHub repository.</p> <p>Your environments and latests deployments are listed on side bar of your repository.</p> <ol> <li>Navigate to your GitHub repository.</li> </ol> <p></p> <ol> <li>Click on the DEV environment to review the deployment history and applied changes for this stage.</li> </ol> <p></p> You may notice multiple entries connected to the same commit message. This is because we deployed multiple stacks (in this case, 5 stacks) to the DEV environment at the same time."},{"location":"workshops/github-pipeline/04-deploy-stack.html#step-10-verify-the-deployed-stack-in-aws-cloudformation","title":"Step 10: Verify the Deployed Stack in AWS CloudFormation","text":"<ol> <li> <p>Open your AWS account used for the DEV stage.</p> </li> <li> <p>In the AWS Management Console, navigate to CloudFormation.</p> </li> <li> <p>You will see that the HelloWorldStack has been successfully deployed to your account.</p> </li> </ol> <p></p> \u2713 Congratulations! You've deployed the HelloWorldStack with the CDK CI/CD Wrapper  <p>Click Next to continue to the next section.</p> <p>Finish</p>"},{"location":"workshops/github-pipeline/05-summary.html","title":"Summary: Achievements &amp; Strengths of the GitHub Pipeline Plugin with CDK CI/CD Wrapper","text":"<p>Throughout this workshop, we demonstrated how the GitHub Pipeline Plugin enhances the functionality of the CDK CI/CD Wrapper by allowing seamless integration with GitHub Actions. By connecting your GitHub repository to AWS, you can fully automate your CI/CD workflows for AWS CDK applications. Let's recap what we achieved and highlight the benefits of using this plugin.</p>"},{"location":"workshops/github-pipeline/05-summary.html#key-achievements","title":"Key Achievements","text":"<ol> <li> <p>Built a GitHub Actions-Based CI/CD Pipeline:    Using the GitHub Pipeline Plugin, we created a multi-stage pipeline within GitHub Actions to automate the deployment of AWS CDK applications. This streamlined the process of continuous integration and deployment for AWS infrastructure, directly from GitHub.</p> </li> <li> <p>Integrated Quality Gates and Automated Tests:    By incorporating build, test, and lint steps in the pipeline, we ensured the quality and security of our code. The automated testing process allowed for seamless quality checks before each deployment.</p> </li> <li> <p>Deployed Multi-Account AWS CDK Applications:    With the CDK CI/CD Wrapper and GitHub Actions, we deployed applications to multiple AWS accounts (such as DEV and PROD). This demonstrated the tool\u2019s flexibility for managing complex multi-account AWS environments with ease.</p> </li> <li> <p>Used GitHub Actions for Infrastructure as Code (IaC):    We harnessed GitHub Actions to automate the synthesis and deployment of AWS CloudFormation templates generated by AWS CDK. This integration simplified the infrastructure lifecycle from development to production.</p> </li> <li> <p>Extended and Deployed the HelloWorldStack:    We successfully extended the pipeline by introducing the HelloWorldStack, managing it through the DefaultStackProvider. This showed how easily infrastructure changes can be added, managed, and deployed through the GitHub Actions workflow.</p> </li> </ol>"},{"location":"workshops/github-pipeline/05-summary.html#strengths-of-the-github-pipeline-plugin-with-cdk-cicd-wrapper","title":"Strengths of the GitHub Pipeline Plugin with CDK CI/CD Wrapper","text":"<ol> <li> <p>Seamless GitHub Integration:    The GitHub Pipeline Plugin simplifies the process of connecting your GitHub repository with AWS CDK applications. With native GitHub Actions support, it empowers teams to manage their pipelines entirely within GitHub, eliminating the need for external CI/CD tools.</p> </li> <li> <p>Continuous Integration and Testing:    By integrating essential quality checks into GitHub Actions (e.g., linting, building, testing), teams can ensure code quality and security before deployment. The CDK CI/CD Wrapper makes these steps easy to configure and manage within the pipeline.</p> </li> <li> <p>Effortless Multi-Account Deployments:    The CDK CI/CD Wrapper allows teams to handle complex AWS environments, deploying across multiple stages (DEV, PROD) and AWS accounts. This eliminates friction when managing multi-account setups, ensuring that deployments happen securely and consistently.</p> </li> <li> <p>Flexibility with GitHub Actions:    GitHub Actions provides a powerful automation platform, enabling flexible workflows that support complex tasks like synthesizing CloudFormation templates and deploying AWS infrastructure. The GitHub Pipeline Plugin taps into this flexibility, making it easy to extend or customize your pipeline as needed.</p> </li> <li> <p>Developer-Friendly:    Built with developers in mind, the CDK CI/CD Wrapper and its integration with GitHub allow for a smooth workflow. By leveraging GitHub Actions, developers can stay within their preferred environment, utilizing familiar tools to manage the entire CI/CD process.</p> </li> </ol>"},{"location":"workshops/github-pipeline/05-summary.html#final-thoughts","title":"Final Thoughts","text":"<p>By using the GitHub Pipeline Plugin with the CDK CI/CD Wrapper, teams can streamline the process of deploying AWS CDK applications directly from their GitHub repositories. The plugin simplifies the management of multi-stage, multi-account AWS deployments while ensuring the integrity and quality of the code through integrated testing and security scans.</p> <p>By adopting these tools, you are now well-equipped to handle more advanced CI/CD workflows, enabling faster, safer, and more efficient deployments in the cloud.</p> Congratulations! You've completed the workshop and mastered the fundamentals of integrating GitHub Actions with the CDK CI/CD Wrapper, creating seamless, automated CI/CD pipelines for AWS CDK applications."},{"location":"workshops/github-pipeline/06-clean-up.html","title":"Clean Up","text":"<p>Congratulations! You have successfully completed the workshop. You can now clean up the resources created in this workshop.</p> <p>To clean up the resources, follow these steps:</p>"},{"location":"workshops/github-pipeline/06-clean-up.html#step-1-delete-the-cloudformation-stacks","title":"Step 1: Delete the CloudFormation Stacks","text":"<ol> <li>Delete all the CloudFormation stacks created during the workshop. 1.1. Ensure that you delete CDKToolkit stack at the last!!! 1.2. There are dependencies between the stacks, so you need to delete them in the reverse order of creation.</li> </ol>"},{"location":"workshops/github-pipeline/06-clean-up.html#step-2-delete-the-s3-buckets","title":"Step 2: Delete the S3 Buckets","text":""},{"location":"workshops/github-pipeline/06-clean-up.html#step-3-delete-the-amazon-sagemaker-studio-domain","title":"Step 3: Delete the Amazon SageMaker Studio Domain","text":"<p>Open the Amazon SageMaker Studio. </p> <p>Click on the <code>Domains</code>. </p> <p>Select the <code>cdk-cicd-example</code> domain. Go to the Space management tab, select the <code>my-space</code> and click on the <code>Delete</code> button. </p> <p>It will show a pop-up to confirm the deletion. Click on the <code>Yes, delete space</code> button, then type in the <code>delete</code> to the input field than click the <code>Delete space</code> button to delete the user space. </p> <p>Then go to the <code>User profiles</code> tab. </p> <p>Select the user profile and click on the <code>Delete</code> button. </p> <p>There will be a pop-up to confirm the deletion. Click on the <code>Yes, delete user profile</code> button, then type in the <code>delete</code> to the input field than click the <code>Delete user profile</code> button to delete the user profile.</p> <p>Then go to the <code>Domain settings</code> tab. Scroll down to the <code>Delete Domain</code> section. Click on the <code>Delete Domain</code> button. </p> <p>There will be a pop-up to confirm the deletion. Click on the <code>Yes, delete my domain</code> button, then type in the <code>delete</code> to the input field than click the <code>Delete domain</code> button to delete the domain.</p>"},{"location":"workshops/github-pipeline/faq.html","title":"FAQ","text":""},{"location":"workshops/github-pipeline/faq.html#how-to-open-the-terminal-in-amazon-sagemaker-studio-code-editor","title":"How to open the terminal in Amazon SageMaker Studio - Code Editor?","text":"<p>To open the terminal in Amazon SageMaker Studio - Code Editor, follow these steps: - Click on the <code>Menu</code> icon on the top left corner of the Code Editor. - Select <code>Terminal</code> from the dropdown menu. - Select <code>New Terminal</code> to open a new terminal window.</p>"},{"location":"workshops/github-pipeline/faq.html#what-to-do-if-the-cdk-init-cannot-be-run-in-a-non-empty-directory-error-occurs","title":"What to do if the \"<code>cdk init</code> cannot be run in a non-empty directory!\" error occurs?","text":"<p>If you encounter the \"<code>cdk init</code> cannot be run in a non-empty directory!\" error, it means that the directory you are trying to initialize is not empty. Most likely your terminal is not in the correct directory. To resolve this issue, make sure you are in the <code>/home/sagemaker-user/cdk-cicd-example</code> directory where you want to initialize the CDK project.</p>"},{"location":"workshops/github-pipeline/faq.html#i-am-getting-a-prompt-to-studioregionsagemeakeraws-wants-to-see-text-and-images-copied-to-the-clipboard-what-should-i-do","title":"I am getting a prompt to <code>*.studio.&lt;region&gt;.sagemeaker.aws</code> wants to \"See text and images copied to the clipboard\", what should I do?","text":"<p>Amazon SageMaker Studio uses the clipboard to copy and paste text and images between the local machine and the Studio environment. If you see this prompt, you can allow the clipboard access by clicking on the <code>Allow</code> button.</p>"},{"location":"workshops/github-pipeline/faq.html#how-to-clean-the-npm-cache","title":"How to clean the npm cache?","text":"<p>In case you have get to an npm notarget error during any <code>npm install</code> command, you can try to clean the npm cache with the following command:</p> <pre><code>npm cache clean --force\n</code></pre>"}]}